{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import json\n",
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import DataCollatorForLanguageModeling, AutoTokenizer, TFAutoModelForCausalLM, AdamWeightDecay\n",
    "from os.path import join, exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.BBData import character_dict, model_name\n",
    "from lib.BBDataLoad import dialogpt_preprocess_function, load_char_df, get_chatbot_predictions, merge_df_for_metrics\n",
    "\n",
    "from lib.wip.frequency_v2 import sentence_preprocess, freq_pairwise_sim, filter_by_weights, get_word_frequency, get_tfidfs, FrequencyChatbotClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = list(character_dict.keys())\n",
    "# characters.remove('Default')\n",
    "\n",
    "mass_value = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount google drive, if in Colaboratory environment\n",
    "import os\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive',force_remount=True)\n",
    "    base_folder = '/content/drive/My Drive/unibo/NLP_project/BarneyBot'\n",
    "    os.system(\"pip install datasets\")\n",
    "    os.system(\"pip install transformers\")\n",
    "    os.system(\"pip install rouge_score\")\n",
    "    os.system(\"pip install -U sentence-transformers\")\n",
    "else:\n",
    "    # base_folder = os.getcwd()\n",
    "    base_folder = '..'\n",
    "\n",
    "out_folder = os.path.join(base_folder, 'Data', 'Characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_docs = dict()\n",
    "class_docs = [[], []]\n",
    "for character in characters:\n",
    "    if character == 'Default':\n",
    "        df = pd.read_csv(os.path.join(out_folder, character, f'{character}.tsv'), \n",
    "                         names=[character, 'response'], sep='\\t')\n",
    "        df['response'] = df['response'].apply(lambda x: x[3:])\n",
    "        df[character] = df[character].apply(lambda x: x[3:])\n",
    "    else:\n",
    "        df = pd.read_csv(os.path.join(out_folder, character, f'{character}.csv'))\n",
    "    tmp_list = df['response'].tolist()\n",
    "    character_docs[character] = tmp_list\n",
    "    class_docs[0] += tmp_list\n",
    "    class_docs[1] += [character for _ in tmp_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5194/5194 [00:02<00:00, 2305.45it/s]\n",
      "100%|██████████| 11642/11642 [00:05<00:00, 2098.18it/s]\n",
      "100%|██████████| 1037/1037 [00:00<00:00, 2965.47it/s]\n",
      "100%|██████████| 2716/2716 [00:01<00:00, 1776.76it/s]\n",
      "100%|██████████| 2388/2388 [00:01<00:00, 2266.87it/s]\n",
      "100%|██████████| 160/160 [00:00<00:00, 2911.37it/s]\n",
      "100%|██████████| 8229/8229 [00:04<00:00, 1773.89it/s]\n",
      "100%|██████████| 7476/7476 [00:03<00:00, 2010.30it/s]\n",
      "100%|██████████| 737332/737332 [05:50<00:00, 2105.64it/s]\n"
     ]
    }
   ],
   "source": [
    "for character in characters:\n",
    "    for i in tqdm(range(len(character_docs[character]))):\n",
    "        sentence, relevant = sentence_preprocess(character_docs[character][i])\n",
    "        if relevant:\n",
    "            character_docs[character][i] = sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.33\n",
    "character_docs_train = {}\n",
    "character_docs_test = {}\n",
    "for c in characters:\n",
    "    shuffle(character_docs[c])\n",
    "    end_idx = int(len(character_docs[c]) * test_size)\n",
    "    character_docs_train[c] = character_docs[c][end_idx:]\n",
    "    character_docs_test[c] = character_docs[c][:end_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"wordfreqs_train = dict()\\nfor character in tqdm(characters):\\n    wordfreqs_train[character] = get_word_frequency(' '.join(character_docs_train[character]), f_sorted=True)\\n\\nwordfreqs_test = dict()\\nfor character in tqdm(characters):\\n    wordfreqs_test[character] = get_word_frequency(' '.join(character_docs_test[character]), f_sorted=True)\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"wordfreqs_train = dict()\n",
    "for character in tqdm(characters):\n",
    "    wordfreqs_train[character] = get_word_frequency(' '.join(character_docs_train[character]), f_sorted=True)\n",
    "\n",
    "wordfreqs_test = dict()\n",
    "for character in tqdm(characters):\n",
    "    wordfreqs_test[character] = get_word_frequency(' '.join(character_docs_test[character]), f_sorted=True)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wordfreqs_reduced_train = dict()\\nfor character in characters:\\n    wordfreqs_reduced_train[character] = filter_by_weights(wordfreqs_train[character], mass=0.3)\\n\\nwordfreqs_reduced_test = dict()\\nfor character in characters:\\n    wordfreqs_reduced_test[character] = filter_by_weights(wordfreqs_test[character], mass=0.3)'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"wordfreqs_reduced_train = dict()\n",
    "for character in characters:\n",
    "    wordfreqs_reduced_train[character] = filter_by_weights(wordfreqs_train[character], mass=0.3)\n",
    "\n",
    "wordfreqs_reduced_test = dict()\n",
    "for character in characters:\n",
    "    wordfreqs_reduced_test[character] = filter_by_weights(wordfreqs_test[character], mass=0.3)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading TF-IDF matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"tfidf_vectorizer = TfidfVectorizer(input='content', stop_words='english')\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"tfidf_vectorizer = TfidfVectorizer(input='content', stop_words='english')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"tfidfs_train = get_tfidfs([' '.join(character_docs_train[character]) for character in characters], characters, tfidf_vectorizer)\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"tfidfs_train = get_tfidfs([' '.join(character_docs_train[character]) for character in characters], characters, tfidf_vectorizer)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tfidfs_reduced_train = dict()\\nfor character in characters:\\n    tfidfs_reduced_train[character] = filter_by_weights(tfidfs_train[character], mass=mass_value)'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"tfidfs_reduced_train = dict()\n",
    "for character in characters:\n",
    "    tfidfs_reduced_train[character] = filter_by_weights(tfidfs_train[character], mass=mass_value)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordCloud Plot (Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from lib.BBVisualizations import BBVisualization\\nBBVisualization.load_visualization(\"wordcloud\").plot(freqdict=tfidfs_reduced_train[\\'Barney\\'])'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from lib.BBVisualizations import BBVisualization\n",
    "BBVisualization.load_visualization(\"wordcloud\").plot(freqdict=tfidfs_reduced_train['Barney'])\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency Pairwise Similarity (Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"freq_pairwise_sim(wordfreqs_reduced_train['Fry'], wordfreqs_reduced_test['Fry'])\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"freq_pairwise_sim(wordfreqs_reduced_train['Fry'], wordfreqs_reduced_test['Fry'])\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Classifier Performances Against Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"wf_classifier = FrequencyChatbotClassifier(characters, mode='word frequency')\\nwf_classifier.train(list(character_docs_train.values()))\\n\\ny_true = range(0, len(characters))\\ny_pred = [np.argmax(list(wf_classifier.predict(character_docs_test[character], mass=0.3).values()))\\n          for character in characters]\\n\\nprint('Word Frequency classifier test accuracy: {:.2f}'.format(\\n             sum([y_pred[i] == y_true[i] for i in range(len(y_true))]) / len(y_true)))\\nconfusion_matrix(y_true, y_pred)\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"wf_classifier = FrequencyChatbotClassifier(characters, mode='word frequency')\n",
    "wf_classifier.train(list(character_docs_train.values()))\n",
    "\n",
    "y_true = range(0, len(characters))\n",
    "y_pred = [np.argmax(list(wf_classifier.predict(character_docs_test[character], mass=0.3).values()))\n",
    "          for character in characters]\n",
    "\n",
    "print('Word Frequency classifier test accuracy: {:.2f}'.format(\n",
    "             sum([y_pred[i] == y_true[i] for i in range(len(y_true))]) / len(y_true)))\n",
    "confusion_matrix(y_true, y_pred)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [04:40<00:00, 31.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF classifier test accuracy: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_classifier = FrequencyChatbotClassifier(characters, mode='tf-idf')\n",
    "tfidf_classifier.train(list(character_docs_train.values()))\n",
    "\n",
    "y_true = range(0, len(characters))\n",
    "y_pred = []\n",
    "raw_predictions = {c:[] for c in characters}\n",
    "msw_predictions = {c:[] for c in characters}\n",
    "for c in tqdm(range(len(characters))):\n",
    "    prediction = tfidf_classifier.predict(character_docs_test[characters[c]], mass=0.3)\n",
    "    msws = tfidf_classifier.get_MSW(character_docs_test[characters[c]], mass=0.3)\n",
    "    raw_predictions[characters[c]].append(prediction)\n",
    "    msw_predictions[characters[c]].append(msws)\n",
    "    y_pred.append(np.argmax(list(prediction.values())))\n",
    "\n",
    "print('TF-IDF classifier test accuracy: {:.2f}'.format(\n",
    "             sum([y_pred[i] == y_true[i] for i in range(len(y_true))]) / len(y_true)))\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# msw_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c-TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:04<00:00,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF classifier test accuracy: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctfidf_classifier = FrequencyChatbotClassifier(characters, mode='c-tf-idf')\n",
    "ctfidf_classifier.train(list(character_docs_train.values()))\n",
    "\n",
    "y_true = range(0, len(characters))\n",
    "y_pred = []\n",
    "raw_predictions = {c:[] for c in characters}\n",
    "# msw_predictions = {c:[] for c in characters}\n",
    "for c in tqdm(range(len(characters))):\n",
    "    prediction = ctfidf_classifier.predict(character_docs_test[characters[c]], mass=0.3)\n",
    "    # msws = ctfidf_classifier.get_MSW(character_docs_test[characters[c]], mass=0.3)\n",
    "    raw_predictions[characters[c]].append(prediction)\n",
    "    # msw_predictions[characters[c]].append(msws)\n",
    "    # print(prediction)\n",
    "    y_pred.append(np.argmax(prediction))\n",
    "\n",
    "print('TF-IDF classifier test accuracy: {:.2f}'.format(\n",
    "             sum([y_pred[i] == y_true[i] for i in range(len(y_true))]) / len(y_true)))\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Barney': [array([0.99617002, 0.95629725, 0.94193125, 0.98012821, 0.97783672,\n",
       "         0.88733131, 0.96534351, 0.95859173, 0.9230213 ])],\n",
       " 'Sheldon': [array([0.95906242, 0.99856711, 0.88759811, 0.93746857, 0.94623484,\n",
       "         0.89946734, 0.92078986, 0.91341358, 0.94372555])],\n",
       " 'Harry': [array([0.95425066, 0.8984451 , 0.96260125, 0.95624752, 0.94756437,\n",
       "         0.82543339, 0.93725922, 0.92891611, 0.86317837])],\n",
       " 'Fry': [array([0.97656237, 0.92699509, 0.95475201, 0.99176699, 0.98475479,\n",
       "         0.84249239, 0.96418706, 0.95417869, 0.90986188])],\n",
       " 'Bender': [array([0.97701121, 0.94257317, 0.94570096, 0.98707818, 0.99232888,\n",
       "         0.85880576, 0.96061848, 0.94764694, 0.92220425])],\n",
       " 'Vader': [array([0.87145794, 0.89458761, 0.81617367, 0.84789941, 0.85536314,\n",
       "         0.94279504, 0.78275262, 0.7699793 , 0.91107325])],\n",
       " 'Joey': [array([0.96410748, 0.92616945, 0.92820502, 0.967309  , 0.96183399,\n",
       "         0.82336805, 0.99708326, 0.9850087 , 0.87827135])],\n",
       " 'Phoebe': [array([0.94824368, 0.90980805, 0.9041956 , 0.94983908, 0.94269821,\n",
       "         0.80841643, 0.98337351, 0.99718248, 0.84759207])],\n",
       " 'Default': [array([0.93759169, 0.94822159, 0.89814133, 0.92598218, 0.92723041,\n",
       "         0.88348141, 0.86608284, 0.85202282, 0.99997187])]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Classifiers On Chatbots (Not Cached!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_classifier = FrequencyChatbotClassifier(characters, mode='c-tf-idf')\n",
    "tfidf_classifier.train(list(character_docs.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=join(\"..\", \"cache\"))\n",
    "tokenizer.pad_token = '#'\n",
    "data_collator = DataCollatorForLanguageModeling(mlm=False, tokenizer=tokenizer, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_noDefault = characters.copy()\n",
    "characters_noDefault.remove('Default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset...\n",
      "Run 0/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]Using custom data configuration default-d78476db32c8db98\n",
      "Reusing dataset csv (cache\\csv\\default-d78476db32c8db98\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n",
      "100%|██████████| 1/1 [00:00<00:00, 126.10it/s]\n",
      "Loading cached split indices for dataset at cache\\csv\\default-d78476db32c8db98\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-651037d43e5e3dbd.arrow and cache\\csv\\default-d78476db32c8db98\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-7e4903d85e508b43.arrow\n",
      "Loading cached split indices for dataset at cache\\csv\\default-d78476db32c8db98\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-1b018c4ce0c1ed8c.arrow and cache\\csv\\default-d78476db32c8db98\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-2cfa4b0ef22c9ad5.arrow\n",
      "Loading cached processed dataset at cache\\csv\\default-d78476db32c8db98\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-89f9b92b2a083af0.arrow\n",
      "Loading cached processed dataset at cache\\csv\\default-d78476db32c8db98\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-f26a814e4e6d10fc.arrow\n",
      "Loading cached processed dataset at cache\\csv\\default-d78476db32c8db98\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-6655d46d8a0182ef.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading predictions from stored file\n",
      "Loaded predictions from stored file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [00:01<00:00, 426.17it/s]\n",
      " 12%|█▎        | 1/8 [00:02<00:19,  2.72s/it]Using custom data configuration default-8207271dc09e0a46\n",
      "Reusing dataset csv (cache\\csv\\default-8207271dc09e0a46\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n",
      "100%|██████████| 1/1 [00:00<00:00, 122.50it/s]\n",
      "Loading cached split indices for dataset at cache\\csv\\default-8207271dc09e0a46\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-46b6cd7566c1d243.arrow and cache\\csv\\default-8207271dc09e0a46\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-e3e40e36f25dded7.arrow\n",
      "Loading cached split indices for dataset at cache\\csv\\default-8207271dc09e0a46\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-1774625d7360210c.arrow and cache\\csv\\default-8207271dc09e0a46\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-ad5b734370182aae.arrow\n",
      "Loading cached processed dataset at cache\\csv\\default-8207271dc09e0a46\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-fed8798d874c65dd.arrow\n",
      "Loading cached processed dataset at cache\\csv\\default-8207271dc09e0a46\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-632156930e5bea85.arrow\n",
      "Loading cached processed dataset at cache\\csv\\default-8207271dc09e0a46\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-448ecc7a6afdd007.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading predictions from stored file\n",
      "Loaded predictions from stored file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1170/1170 [00:03<00:00, 388.14it/s]\n",
      " 25%|██▌       | 2/8 [00:07<00:23,  3.95s/it]Using custom data configuration default-5e8064f57286033a\n",
      "Reusing dataset csv (cache\\csv\\default-5e8064f57286033a\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n",
      "100%|██████████| 1/1 [00:00<00:00, 143.13it/s]\n",
      "Loading cached split indices for dataset at cache\\csv\\default-5e8064f57286033a\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-2b86c587abd47c66.arrow and cache\\csv\\default-5e8064f57286033a\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-8919d70a4bf80eed.arrow\n",
      "Loading cached split indices for dataset at cache\\csv\\default-5e8064f57286033a\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-4099b79485c950ea.arrow and cache\\csv\\default-5e8064f57286033a\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-cecb46b03995ab9b.arrow\n",
      "Loading cached processed dataset at cache\\csv\\default-5e8064f57286033a\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-e80578e3b4f7f025.arrow\n",
      "Loading cached processed dataset at cache\\csv\\default-5e8064f57286033a\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-45cad4fe25e5526e.arrow\n",
      "Loading cached processed dataset at cache\\csv\\default-5e8064f57286033a\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-937d1b7b6a0a1add.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading predictions from stored file\n",
      "Loaded predictions from stored file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104/104 [00:00<00:00, 463.39it/s]\n",
      " 38%|███▊      | 3/8 [00:08<00:13,  2.69s/it]Using custom data configuration default-b35448ec5dd887ec\n",
      "Reusing dataset csv (cache\\csv\\default-b35448ec5dd887ec\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n",
      "100%|██████████| 1/1 [00:00<00:00, 123.67it/s]\n",
      "Loading cached split indices for dataset at cache\\csv\\default-b35448ec5dd887ec\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-667383473c444f25.arrow and cache\\csv\\default-b35448ec5dd887ec\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-c520a8a264854da4.arrow\n",
      "Loading cached split indices for dataset at cache\\csv\\default-b35448ec5dd887ec\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-b072a26900059a04.arrow and cache\\csv\\default-b35448ec5dd887ec\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-885672efcb78500c.arrow\n",
      "Loading cached processed dataset at cache\\csv\\default-b35448ec5dd887ec\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-f2119e5a34f2eb76.arrow\n",
      "Loading cached processed dataset at cache\\csv\\default-b35448ec5dd887ec\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-cb34da498e1e68ed.arrow\n",
      "Loading cached processed dataset at cache\\csv\\default-b35448ec5dd887ec\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-3b065f584f7e66c9.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading predictions from stored file\n",
      "Loaded predictions from stored file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273/273 [00:00<00:00, 303.91it/s]\n",
      " 50%|█████     | 4/8 [00:11<00:10,  2.58s/it]Using custom data configuration default-2a0884da2a86facc\n",
      "Reusing dataset csv (cache\\csv\\default-2a0884da2a86facc\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n",
      "100%|██████████| 1/1 [00:00<00:00, 180.71it/s]\n",
      "Loading cached split indices for dataset at cache\\csv\\default-2a0884da2a86facc\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-4c59c8594ee83881.arrow and cache\\csv\\default-2a0884da2a86facc\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-979ea9e674132025.arrow\n",
      "Loading cached split indices for dataset at cache\\csv\\default-2a0884da2a86facc\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-2cdb39c47142be86.arrow and cache\\csv\\default-2a0884da2a86facc\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-4b32be2eacb5d552.arrow\n",
      "Loading cached processed dataset at cache\\csv\\default-2a0884da2a86facc\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-6647fe37f40ed616.arrow\n",
      "Loading cached processed dataset at cache\\csv\\default-2a0884da2a86facc\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-98b2463bec0fd009.arrow\n",
      "Loading cached processed dataset at cache\\csv\\default-2a0884da2a86facc\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-015ae8852bcf3fa4.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading predictions from stored file\n",
      "Loaded predictions from stored file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:00<00:00, 286.98it/s]\n",
      " 62%|██████▎   | 5/8 [00:13<00:07,  2.57s/it]Using custom data configuration default-3bee7e44262edb7f\n",
      "Reusing dataset csv (cache\\csv\\default-3bee7e44262edb7f\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n",
      "100%|██████████| 1/1 [00:00<00:00, 149.55it/s]\n",
      "Loading cached split indices for dataset at cache\\csv\\default-3bee7e44262edb7f\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-96d0a5ba5e8fec42.arrow and cache\\csv\\default-3bee7e44262edb7f\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-1443283cf78ecd8c.arrow\n",
      "Loading cached split indices for dataset at cache\\csv\\default-3bee7e44262edb7f\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-fe15dac5f93d7344.arrow and cache\\csv\\default-3bee7e44262edb7f\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-c4745ad835a23735.arrow\n",
      "Loading cached processed dataset at cache\\csv\\default-3bee7e44262edb7f\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-52e19da7533330c8.arrow\n",
      "Loading cached processed dataset at cache\\csv\\default-3bee7e44262edb7f\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-979822d41ccd7a4a.arrow\n",
      "Loading cached processed dataset at cache\\csv\\default-3bee7e44262edb7f\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-d486cd416c29c441.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading predictions from stored file\n",
      "Loaded predictions from stored file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 468.33it/s]\n",
      " 75%|███████▌  | 6/8 [00:14<00:04,  2.07s/it]Using custom data configuration default-b81141adc87b87bf\n",
      "Reusing dataset csv (cache\\csv\\default-b81141adc87b87bf\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n",
      "100%|██████████| 1/1 [00:00<00:00, 123.68it/s]\n",
      "Loading cached split indices for dataset at cache\\csv\\default-b81141adc87b87bf\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-e2d3926d0ffd0fd3.arrow and cache\\csv\\default-b81141adc87b87bf\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-f888d4a055d9f5e2.arrow\n",
      "Loading cached split indices for dataset at cache\\csv\\default-b81141adc87b87bf\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-682a04a266efce80.arrow and cache\\csv\\default-b81141adc87b87bf\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-13fca5dad2d5247a.arrow\n",
      "Loading cached processed dataset at cache\\csv\\default-b81141adc87b87bf\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-7662390b0e4f3793.arrow\n",
      "Loading cached processed dataset at cache\\csv\\default-b81141adc87b87bf\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-4379f0323f83a3bd.arrow\n",
      "Loading cached processed dataset at cache\\csv\\default-b81141adc87b87bf\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-ff90937c11e9e756.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading predictions from stored file\n",
      "Loaded predictions from stored file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:03<00:00, 242.10it/s]\n",
      " 88%|████████▊ | 7/8 [00:20<00:03,  3.22s/it]Using custom data configuration default-48cc5f719001fd3a\n",
      "Reusing dataset csv (cache\\csv\\default-48cc5f719001fd3a\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n",
      "100%|██████████| 1/1 [00:00<00:00, 124.20it/s]\n",
      "Loading cached split indices for dataset at cache\\csv\\default-48cc5f719001fd3a\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-16c140b5da191e7c.arrow and cache\\csv\\default-48cc5f719001fd3a\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-ed121df269d87298.arrow\n",
      "Loading cached split indices for dataset at cache\\csv\\default-48cc5f719001fd3a\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-f4f26cbce3ecb27c.arrow and cache\\csv\\default-48cc5f719001fd3a\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-186da54849d8ccad.arrow\n",
      "Loading cached processed dataset at cache\\csv\\default-48cc5f719001fd3a\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-7c5b176b39e0048e.arrow\n",
      "Loading cached processed dataset at cache\\csv\\default-48cc5f719001fd3a\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-5221c27b06394c28.arrow\n",
      "Loading cached processed dataset at cache\\csv\\default-48cc5f719001fd3a\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-20bada48da47c9c4.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading predictions from stored file\n",
      "Loaded predictions from stored file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 751/751 [00:02<00:00, 344.13it/s]\n",
      "100%|██████████| 8/8 [00:24<00:00,  3.01s/it]\n"
     ]
    }
   ],
   "source": [
    "### create dataset\n",
    "n_tests = 1\n",
    "doc_test = []\n",
    "batch_size = 8\n",
    "override_predictions = False\n",
    "predictions = {c:[] for c in characters}\n",
    "raw_predictions = {c:[] for c in characters}\n",
    "msw_predictions = {c:[] for c in characters}\n",
    "print('Creating dataset...')\n",
    "if n_tests > 1 and not override_predictions:\n",
    "    raise Exception('must override previous predictions if you need more tests')\n",
    "\n",
    "for i in range(n_tests):\n",
    "    print(f'Run {i}/{n_tests}')\n",
    "    for character in tqdm(characters_noDefault):\n",
    "        character_checkpoint = join(out_folder, character, character_dict[character]['checkpoint_folder'])\n",
    "        model_chatbot = TFAutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=character_checkpoint) if override_predictions else None\n",
    "        if model_chatbot:\n",
    "            model_chatbot.compile(optimizer=AdamWeightDecay(learning_rate=2e-5))\n",
    "\n",
    "        character_hg = load_char_df(character, base_folder)\n",
    "        # This transform in a sequence of tokens ours dataset\n",
    "        tokenized_character_hg = character_hg.map(lambda row: dialogpt_preprocess_function(row, tokenizer), batched=False)\n",
    "\n",
    "        # Define tensorflow datasets\n",
    "        encoded_test_set = tokenized_character_hg[\"test\"].to_tf_dataset(\n",
    "            columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    "            shuffle=False,\n",
    "            batch_size=batch_size,\n",
    "            collate_fn=data_collator,\n",
    "        )\n",
    "\n",
    "        # Takes the testset as sample question \n",
    "        sample_questions = character_hg['test']['context/0']\n",
    "\n",
    "        # Sampling generation method\n",
    "        predictions_sampling = get_chatbot_predictions(\n",
    "            sample_questions,\n",
    "            model_chatbot,\n",
    "            character_dict[character]['prediction_filename'] + '_sampling.json',\n",
    "            \"Sampling\",\n",
    "            character,\n",
    "            tokenizer,\n",
    "            base_folder,\n",
    "            override_predictions=override_predictions\n",
    "        )\n",
    "                                                    \n",
    "        sentences = merge_df_for_metrics(character_hg['test'], None, None, predictions_sampling, tokenizer)['prd_sampling'].tolist()\n",
    "        sentences = [sentence_preprocess(s) for s in sentences]\n",
    "        doc_test.append([s[0] for s in sentences if s[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 23.19it/s]\n"
     ]
    }
   ],
   "source": [
    "### prediction on last test\n",
    "print('Classification...')\n",
    "y_pred = []\n",
    "# raw_predictions = []\n",
    "for c in tqdm(range(len(characters_noDefault))):\n",
    "    prediction = tfidf_classifier.predict(character_docs_test[characters[c]], mass=0.3)\n",
    "    # msws = tfidf_classifier.get_MSW(character_docs_test[characters[c]], mass=0.3)    \n",
    "    raw_predictions[characters[c]].append(prediction)\n",
    "    # msw_predictions[characters[c]].append(msws)\n",
    "    # predictions[characters[c]].append(\n",
    "    #     int(max(prediction, key=prediction.get) == characters[c])\n",
    "    # )\n",
    "    y_pred.append(np.argmax(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Barney': [],\n",
       " 'Sheldon': [],\n",
       " 'Harry': [],\n",
       " 'Fry': [],\n",
       " 'Bender': [],\n",
       " 'Vader': [],\n",
       " 'Joey': [],\n",
       " 'Phoebe': [],\n",
       " 'Default': []}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF classifier test accuracy: 1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print('TF-IDF classifier test accuracy: {:.2f}'.format(sum([char_pred[-1] for char_pred in predictions.values()])/len(predictions)))\n",
    "print('TF-IDF classifier test accuracy: {:.2f}'.format(\n",
    "             sum([y_pred[i] == y_true[i] for i in range(len(y_true))]) / len(y_true)))\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save predictions\n",
    "append_predictions = True\n",
    "override_predictions = False\n",
    "predictions_file = join('..', 'metrics', 'tfidf_predictions.json')\n",
    "\n",
    "if append_predictions and exists(predictions_file):\n",
    "    with open(predictions_file, 'r', encoding='utf-8') as file:\n",
    "        predictions_dict = json.load(file)\n",
    "elif override_predictions or not exists(predictions_file):\n",
    "    predictions_dict = {'one_hot':{c:[] for c in characters}, 'raw_predictions': {c:[] for c in characters}}\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "    \n",
    "for c in characters_noDefault:\n",
    "    predictions_dict['one_hot'][c] += predictions[c]\n",
    "    predictions_dict['raw_predictions'][c] += raw_predictions[c]\n",
    "\n",
    "with open(predictions_file, 'w', encoding='utf-8') as file:\n",
    "    json.dump(predictions_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'one_hot': {'Barney': [1, 1, 1, 1, 1],\n",
       "  'Sheldon': [1, 1, 1, 1, 1],\n",
       "  'Harry': [1, 0, 0, 0, 1],\n",
       "  'Fry': [0, 0, 0, 0, 1],\n",
       "  'Bender': [0, 1, 1, 1, 1],\n",
       "  'Vader': [1, 0, 0, 0, 1],\n",
       "  'Joey': [0, 0, 0, 0, 1],\n",
       "  'Phoebe': [1, 1, 1, 1, 1]},\n",
       " 'raw_predictions': {'Barney': [{'Barney': 0.7427531645309138,\n",
       "    'Sheldon': 0.3409307888725184,\n",
       "    'Harry': 0.24635663538513103,\n",
       "    'Fry': 0.4365837899414391,\n",
       "    'Bender': 0.4690792107496431,\n",
       "    'Vader': 0.016606825033575093,\n",
       "    'Joey': 0.5216851304420018,\n",
       "    'Phoebe': 0.5625899764181352},\n",
       "   {'Barney': 0.78300635943899,\n",
       "    'Sheldon': 0.3970594438761256,\n",
       "    'Harry': 0.30613045222591173,\n",
       "    'Fry': 0.47947848053595993,\n",
       "    'Bender': 0.5279603147782952,\n",
       "    'Vader': 0.024668276074521298,\n",
       "    'Joey': 0.5775909062067571,\n",
       "    'Phoebe': 0.6605154960250631,\n",
       "    'Default': 0.46163274137594223},\n",
       "   {'Barney': 0.78300635943899,\n",
       "    'Sheldon': 0.3970594438761256,\n",
       "    'Harry': 0.30613045222591173,\n",
       "    'Fry': 0.47947848053595993,\n",
       "    'Bender': 0.5279603147782952,\n",
       "    'Vader': 0.024668276074521298,\n",
       "    'Joey': 0.5775909062067571,\n",
       "    'Phoebe': 0.6605154960250631,\n",
       "    'Default': 0.46163274137594223},\n",
       "   {'Barney': 0.78300635943899,\n",
       "    'Sheldon': 0.39705944387612546,\n",
       "    'Harry': 0.30613045222591173,\n",
       "    'Fry': 0.47947848053595993,\n",
       "    'Bender': 0.5279603147782953,\n",
       "    'Vader': 0.024668276074521295,\n",
       "    'Joey': 0.5775909062067572,\n",
       "    'Phoebe': 0.6605154960250631,\n",
       "    'Default': 0.4616327413759421},\n",
       "   {'Barney': 0.9843136112234488,\n",
       "    'Sheldon': 0.36444610612277495,\n",
       "    'Harry': 0.24531582676987218,\n",
       "    'Fry': 0.4604939107940712,\n",
       "    'Bender': 0.5190646982596167,\n",
       "    'Vader': 0.034052167960930545,\n",
       "    'Joey': 0.4744999214686352,\n",
       "    'Phoebe': 0.4866977782246999,\n",
       "    'Default': 0.49052258798002246}],\n",
       "  'Sheldon': [{'Barney': 0.29552048170798195,\n",
       "    'Sheldon': 0.8748050590880759,\n",
       "    'Harry': 0.1306224005663966,\n",
       "    'Fry': 0.2695591085297738,\n",
       "    'Bender': 0.30709255228832,\n",
       "    'Vader': 0.020533804570629623,\n",
       "    'Joey': 0.608423101094607,\n",
       "    'Phoebe': 0.6441744575129131},\n",
       "   {'Barney': 0.3064556830728792,\n",
       "    'Sheldon': 0.8369550711934085,\n",
       "    'Harry': 0.16794739987903903,\n",
       "    'Fry': 0.2642218635623028,\n",
       "    'Bender': 0.2980988663300735,\n",
       "    'Vader': 0.016033823172964937,\n",
       "    'Joey': 0.5787529705161286,\n",
       "    'Phoebe': 0.6301987900135654,\n",
       "    'Default': 0.31470459843172777},\n",
       "   {'Barney': 0.3064556830728792,\n",
       "    'Sheldon': 0.8369550711934085,\n",
       "    'Harry': 0.16794739987903903,\n",
       "    'Fry': 0.2642218635623028,\n",
       "    'Bender': 0.2980988663300735,\n",
       "    'Vader': 0.016033823172964937,\n",
       "    'Joey': 0.5787529705161286,\n",
       "    'Phoebe': 0.6301987900135654,\n",
       "    'Default': 0.31470459843172777},\n",
       "   {'Barney': 0.30645568307287907,\n",
       "    'Sheldon': 0.8369550711934086,\n",
       "    'Harry': 0.167947399879039,\n",
       "    'Fry': 0.2642218635623028,\n",
       "    'Bender': 0.29809886633007343,\n",
       "    'Vader': 0.016033823172964937,\n",
       "    'Joey': 0.5787529705161285,\n",
       "    'Phoebe': 0.6301987900135654,\n",
       "    'Default': 0.3147045984317278},\n",
       "   {'Barney': 0.38010526223652247,\n",
       "    'Sheldon': 0.9862045157129304,\n",
       "    'Harry': 0.15192716949881702,\n",
       "    'Fry': 0.3459762070077256,\n",
       "    'Bender': 0.3850561502063944,\n",
       "    'Vader': 0.023129757668111588,\n",
       "    'Joey': 0.5740196877940097,\n",
       "    'Phoebe': 0.6025927785311398,\n",
       "    'Default': 0.4220450251593255}],\n",
       "  'Harry': [{'Barney': 0.13683884120253376,\n",
       "    'Sheldon': 0.06708883841954372,\n",
       "    'Harry': 0.4388141369757705,\n",
       "    'Fry': 0.15212110308362184,\n",
       "    'Bender': 0.16716525062758003,\n",
       "    'Vader': 0.013066370832524083,\n",
       "    'Joey': 0.08060438623076482,\n",
       "    'Phoebe': 0.10256730982359805},\n",
       "   {'Barney': 0.38736237828119413,\n",
       "    'Sheldon': 0.24794704702849085,\n",
       "    'Harry': 0.41660221218810667,\n",
       "    'Fry': 0.4243958864858144,\n",
       "    'Bender': 0.44081647210136055,\n",
       "    'Vader': 0.0,\n",
       "    'Joey': 0.27909861337183983,\n",
       "    'Phoebe': 0.28639545275119727,\n",
       "    'Default': 0.4348371755120003},\n",
       "   {'Barney': 0.38736237828119413,\n",
       "    'Sheldon': 0.24794704702849085,\n",
       "    'Harry': 0.41660221218810667,\n",
       "    'Fry': 0.4243958864858144,\n",
       "    'Bender': 0.44081647210136055,\n",
       "    'Vader': 0.0,\n",
       "    'Joey': 0.27909861337183983,\n",
       "    'Phoebe': 0.28639545275119727,\n",
       "    'Default': 0.4348371755120003},\n",
       "   {'Barney': 0.38736237828119413,\n",
       "    'Sheldon': 0.2479470470284908,\n",
       "    'Harry': 0.41660221218810667,\n",
       "    'Fry': 0.42439588648581433,\n",
       "    'Bender': 0.44081647210136055,\n",
       "    'Vader': 0.0,\n",
       "    'Joey': 0.27909861337183983,\n",
       "    'Phoebe': 0.2863954527511974,\n",
       "    'Default': 0.4348371755120003},\n",
       "   {'Barney': 0.17074081668302854,\n",
       "    'Sheldon': 0.0952754225645556,\n",
       "    'Harry': 0.8999410127464901,\n",
       "    'Fry': 0.19521455962601592,\n",
       "    'Bender': 0.19435370160900306,\n",
       "    'Vader': 0.01749967579680032,\n",
       "    'Joey': 0.14407755251567383,\n",
       "    'Phoebe': 0.11928582613785259,\n",
       "    'Default': 0.2115801892964435}],\n",
       "  'Fry': [{'Barney': 0.35169663305805593,\n",
       "    'Sheldon': 0.24824790888954318,\n",
       "    'Harry': 0.20998110563777206,\n",
       "    'Fry': 0.7156238718161495,\n",
       "    'Bender': 0.7945278179373744,\n",
       "    'Vader': 0.033204346756280895,\n",
       "    'Joey': 0.39069846108525097,\n",
       "    'Phoebe': 0.37055957374649556},\n",
       "   {'Barney': 0.401968778297223,\n",
       "    'Sheldon': 0.2795776319649571,\n",
       "    'Harry': 0.27949716890456133,\n",
       "    'Fry': 0.664101415677893,\n",
       "    'Bender': 0.7570541277333269,\n",
       "    'Vader': 0.021381730232810522,\n",
       "    'Joey': 0.41421212978750177,\n",
       "    'Phoebe': 0.446501635476636,\n",
       "    'Default': 0.42569065228225866},\n",
       "   {'Barney': 0.401968778297223,\n",
       "    'Sheldon': 0.2795776319649571,\n",
       "    'Harry': 0.27949716890456133,\n",
       "    'Fry': 0.664101415677893,\n",
       "    'Bender': 0.7570541277333269,\n",
       "    'Vader': 0.021381730232810522,\n",
       "    'Joey': 0.41421212978750177,\n",
       "    'Phoebe': 0.446501635476636,\n",
       "    'Default': 0.42569065228225866},\n",
       "   {'Barney': 0.401968778297223,\n",
       "    'Sheldon': 0.2795776319649572,\n",
       "    'Harry': 0.27949716890456144,\n",
       "    'Fry': 0.6641014156778932,\n",
       "    'Bender': 0.7570541277333271,\n",
       "    'Vader': 0.021381730232810522,\n",
       "    'Joey': 0.4142121297875018,\n",
       "    'Phoebe': 0.4465016354766361,\n",
       "    'Default': 0.4256906522822585},\n",
       "   {'Barney': 0.46082742476784766,\n",
       "    'Sheldon': 0.33771958063496754,\n",
       "    'Harry': 0.26579884199534615,\n",
       "    'Fry': 0.9672321028946098,\n",
       "    'Bender': 0.8087786233840873,\n",
       "    'Vader': 0.0340809030798762,\n",
       "    'Joey': 0.49531637063609285,\n",
       "    'Phoebe': 0.46188670677957555,\n",
       "    'Default': 0.5411181554863016}],\n",
       "  'Bender': [{'Barney': 0.3424145386082738,\n",
       "    'Sheldon': 0.24240100221567218,\n",
       "    'Harry': 0.18404303193084004,\n",
       "    'Fry': 0.8152562835756528,\n",
       "    'Bender': 0.7676111183546306,\n",
       "    'Vader': 0.03871266695381227,\n",
       "    'Joey': 0.3717098209714695,\n",
       "    'Phoebe': 0.379811483453546},\n",
       "   {'Barney': 0.4283953543972208,\n",
       "    'Sheldon': 0.27163455064660175,\n",
       "    'Harry': 0.27978963159768855,\n",
       "    'Fry': 0.7451548269550586,\n",
       "    'Bender': 0.7976221633809295,\n",
       "    'Vader': 0.0330764439266346,\n",
       "    'Joey': 0.4973227527724102,\n",
       "    'Phoebe': 0.49794680067026703,\n",
       "    'Default': 0.4391436166733759},\n",
       "   {'Barney': 0.4283953543972208,\n",
       "    'Sheldon': 0.27163455064660175,\n",
       "    'Harry': 0.27978963159768855,\n",
       "    'Fry': 0.7451548269550586,\n",
       "    'Bender': 0.7976221633809295,\n",
       "    'Vader': 0.0330764439266346,\n",
       "    'Joey': 0.4973227527724102,\n",
       "    'Phoebe': 0.49794680067026703,\n",
       "    'Default': 0.4391436166733759},\n",
       "   {'Barney': 0.42839535439722076,\n",
       "    'Sheldon': 0.27163455064660175,\n",
       "    'Harry': 0.27978963159768866,\n",
       "    'Fry': 0.7451548269550585,\n",
       "    'Bender': 0.7976221633809297,\n",
       "    'Vader': 0.03307644392663459,\n",
       "    'Joey': 0.49732275277241034,\n",
       "    'Phoebe': 0.4979468006702669,\n",
       "    'Default': 0.43914361667337587},\n",
       "   {'Barney': 0.4947361597414475,\n",
       "    'Sheldon': 0.3512968015594777,\n",
       "    'Harry': 0.2719250723329603,\n",
       "    'Fry': 0.8260938209989988,\n",
       "    'Bender': 0.959710647355641,\n",
       "    'Vader': 0.02812908411306822,\n",
       "    'Joey': 0.5280871352658583,\n",
       "    'Phoebe': 0.5061530191210438,\n",
       "    'Default': 0.5268801586947932}],\n",
       "  'Vader': [{'Barney': 0.0,\n",
       "    'Sheldon': 0.009217323384470873,\n",
       "    'Harry': 0.0,\n",
       "    'Fry': 0.0,\n",
       "    'Bender': 0.0,\n",
       "    'Vader': 0.25820840612230356,\n",
       "    'Joey': 0.0,\n",
       "    'Phoebe': 0.0},\n",
       "   {'Barney': 0.07576077581178699,\n",
       "    'Sheldon': 0.1239087020007556,\n",
       "    'Harry': 0.0,\n",
       "    'Fry': 0.07214983445488242,\n",
       "    'Bender': 0.11449816409889396,\n",
       "    'Vader': 0.04466106324067262,\n",
       "    'Joey': 0.11335781473850366,\n",
       "    'Phoebe': 0.18813393491399447,\n",
       "    'Default': 0.030290088704505093},\n",
       "   {'Barney': 0.07576077581178699,\n",
       "    'Sheldon': 0.1239087020007556,\n",
       "    'Harry': 0.0,\n",
       "    'Fry': 0.07214983445488242,\n",
       "    'Bender': 0.11449816409889396,\n",
       "    'Vader': 0.04466106324067262,\n",
       "    'Joey': 0.11335781473850366,\n",
       "    'Phoebe': 0.18813393491399447,\n",
       "    'Default': 0.030290088704505093},\n",
       "   {'Barney': 0.07576077581178699,\n",
       "    'Sheldon': 0.12390870200075563,\n",
       "    'Harry': 0.0,\n",
       "    'Fry': 0.07214983445488242,\n",
       "    'Bender': 0.11449816409889398,\n",
       "    'Vader': 0.04466106324067263,\n",
       "    'Joey': 0.11335781473850366,\n",
       "    'Phoebe': 0.18813393491399447,\n",
       "    'Default': 0.030290088704505093},\n",
       "   {'Barney': 0.027009886087582417,\n",
       "    'Sheldon': 0.009772324458065576,\n",
       "    'Harry': 0.027497797854488963,\n",
       "    'Fry': 0.03143693095533886,\n",
       "    'Bender': 0.03414294518427907,\n",
       "    'Vader': 0.8443528934658112,\n",
       "    'Joey': 0.019952308225000603,\n",
       "    'Phoebe': 0.019252412811968003,\n",
       "    'Default': 0.0472728892878711}],\n",
       "  'Joey': [{'Barney': 0.39536747925639515,\n",
       "    'Sheldon': 0.58691746104902,\n",
       "    'Harry': 0.1932663013723321,\n",
       "    'Fry': 0.4181559385647579,\n",
       "    'Bender': 0.47110008420216587,\n",
       "    'Vader': 0.0,\n",
       "    'Joey': 0.8391346139039385,\n",
       "    'Phoebe': 0.8454508759634352},\n",
       "   {'Barney': 0.4107422214620382,\n",
       "    'Sheldon': 0.5074141166287492,\n",
       "    'Harry': 0.2638698870565797,\n",
       "    'Fry': 0.40220708833645064,\n",
       "    'Bender': 0.4351317000712647,\n",
       "    'Vader': 0.0,\n",
       "    'Joey': 0.6798542765142213,\n",
       "    'Phoebe': 0.7628907337123005,\n",
       "    'Default': 0.3847060063455504},\n",
       "   {'Barney': 0.4107422214620382,\n",
       "    'Sheldon': 0.5074141166287492,\n",
       "    'Harry': 0.2638698870565797,\n",
       "    'Fry': 0.40220708833645064,\n",
       "    'Bender': 0.4351317000712647,\n",
       "    'Vader': 0.0,\n",
       "    'Joey': 0.6798542765142213,\n",
       "    'Phoebe': 0.7628907337123005,\n",
       "    'Default': 0.3847060063455504},\n",
       "   {'Barney': 0.41074222146203826,\n",
       "    'Sheldon': 0.5074141166287494,\n",
       "    'Harry': 0.26386988705657977,\n",
       "    'Fry': 0.4022070883364506,\n",
       "    'Bender': 0.4351317000712648,\n",
       "    'Vader': 0.0,\n",
       "    'Joey': 0.6798542765142215,\n",
       "    'Phoebe': 0.7628907337123007,\n",
       "    'Default': 0.3847060063455505},\n",
       "   {'Barney': 0.4716776755447186,\n",
       "    'Sheldon': 0.5648558627028539,\n",
       "    'Harry': 0.2193960438600706,\n",
       "    'Fry': 0.5108708281003848,\n",
       "    'Bender': 0.567798929864713,\n",
       "    'Vader': 0.02578458913779369,\n",
       "    'Joey': 0.9859458918340366,\n",
       "    'Phoebe': 0.8662346344805091,\n",
       "    'Default': 0.4061566845881432}],\n",
       "  'Phoebe': [{'Barney': 0.37585267573313463,\n",
       "    'Sheldon': 0.596322442769732,\n",
       "    'Harry': 0.16098732095323065,\n",
       "    'Fry': 0.36547140807876966,\n",
       "    'Bender': 0.4446212735149107,\n",
       "    'Vader': 0.0,\n",
       "    'Joey': 0.802346757723317,\n",
       "    'Phoebe': 0.8716569369073104},\n",
       "   {'Barney': 0.3823751638286867,\n",
       "    'Sheldon': 0.6135386118250281,\n",
       "    'Harry': 0.18855343083140713,\n",
       "    'Fry': 0.33994026461499866,\n",
       "    'Bender': 0.40791188741683226,\n",
       "    'Vader': 0.0,\n",
       "    'Joey': 0.6840391170733883,\n",
       "    'Phoebe': 0.8674820225367113,\n",
       "    'Default': 0.30325145684324584},\n",
       "   {'Barney': 0.3823751638286867,\n",
       "    'Sheldon': 0.6135386118250281,\n",
       "    'Harry': 0.18855343083140713,\n",
       "    'Fry': 0.33994026461499866,\n",
       "    'Bender': 0.40791188741683226,\n",
       "    'Vader': 0.0,\n",
       "    'Joey': 0.6840391170733883,\n",
       "    'Phoebe': 0.8674820225367113,\n",
       "    'Default': 0.30325145684324584},\n",
       "   {'Barney': 0.3823751638286867,\n",
       "    'Sheldon': 0.6135386118250281,\n",
       "    'Harry': 0.18855343083140708,\n",
       "    'Fry': 0.3399402646149987,\n",
       "    'Bender': 0.4079118874168323,\n",
       "    'Vader': 0.0,\n",
       "    'Joey': 0.6840391170733884,\n",
       "    'Phoebe': 0.8674820225367113,\n",
       "    'Default': 0.3032514568432457},\n",
       "   {'Barney': 0.48274546002699564,\n",
       "    'Sheldon': 0.6019587299326348,\n",
       "    'Harry': 0.22408580711173065,\n",
       "    'Fry': 0.4610008806289888,\n",
       "    'Bender': 0.5221647927046286,\n",
       "    'Vader': 0.014211560472838437,\n",
       "    'Joey': 0.864103693399106,\n",
       "    'Phoebe': 0.9871930694363733,\n",
       "    'Default': 0.41058371809648286}]}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a7c5817727678c332fb9fa5aff0185fec398eda4559a601173fdef72aa27c3a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

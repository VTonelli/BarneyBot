{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import for general utilities\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import character dictionaries, useful to map a character to its data, and a fixed random seed\n",
    "from lib.BBData import character_dict, source_dict, random_state\n",
    "from lib.BBDataLoad import open_char_dataset, process_char_dataset\n",
    "\n",
    "character = 'Phoebe' # 'Barney' | 'Sheldon' | 'Harry' | 'Fry' | 'Vader' | 'Joey' | 'Phoebe' | 'Bender' | 'Default'\n",
    "# Sets the levels of context e.g. level=5 => have a sequance of context [context/0, ..., context/4]\n",
    "level = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the character selected is different from `Default` we extract the source where to find the data\n",
    "if character != 'Default':\n",
    "    source = character_dict[character]['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount google drive (for Colab only)\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive',force_remount=True)\n",
    "    base_folder = '/content/drive/My Drive/unibo/NLP_project/BarneyBot'\n",
    "else:\n",
    "    # base_folder = os.getcwd()\n",
    "    base_folder = '..'\n",
    "\n",
    "out_folder = os.path.join(base_folder, 'data', 'Characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, functions and procedures are set up that make it possible to preprocess the various corpus. These will then be used later to fine tune all chatbots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all let's start from laoding the dataset. This process will be performed by `load_dataset` which performs the loading of the dataset as DataFrame from each of the tv show we selected for our task:\n",
    "* [How I Met Your Mother](https://transcripts.foreverdreaming.org/viewforum.php?f=177)\n",
    "* [Futurama](https://theinfosphere.org/Episode_Transcript_Listing)\n",
    "* [Harry Potter](https://www.kaggle.com/gulsahdemiryurek/harry-potter-dataset)\n",
    "* [Star Wars](https://bulletproofscreenwriting.tv/star-wars-movies-screenplay-download/)\n",
    "* [Friends](https://www.kaggle.com/datasets/blessondensil294/friends-tv-series-screenplay-script)\n",
    "* [The Big Bang Theory](https://bigbangtrans.wordpress.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call the function to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 229/229 [00:02<00:00, 106.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Dataset!\n",
      "\n",
      "    source                                               line\n",
      "0  Friends                            source,line,character\\n\n",
      "1  Friends  Friends,\"30 shiatsu.,Phoebe,S01E12 The Dozen L...\n",
      "2  Friends  Friends,\"the way you play with your hair when ...\n",
      "3  Friends  Friends,\"30 and Miss Somerfield canceled her 5...\n",
      "4  Friends  Friends,\"how much you love your friends. Numbe...\n",
      "source    202260\n",
      "line      202260\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Execute creation of dataset\n",
    "df = open_char_dataset(character, base_folder)\n",
    "if not isinstance(df, type(None)):\n",
    "    print(\"Loaded Dataset!\")\n",
    "    print()\n",
    "    print(df.head())\n",
    "    print(df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we see the definition of the functions that preprocess the datasets. \n",
    "\n",
    "Generally, all the script files share the same structure for all the tv show we selected. Most relevant observation are the following:\n",
    "1. most scripts identify the incipit of an episode with square or round brackets $\\Rightarrow$ discard such lines,\n",
    "2. most scripts put inside round brackets, during the character line, some informations and details regarding some behaviors that character should have in that moment, $\\Rightarrow$ substitute all what there is between brackets with a blank char,\n",
    "3. most scripts identify a character's line with the character's name followed by a colon, $\\Rightarrow$ such lines should be divided into two part (i.e. one for character name and one for his line),\n",
    "4. some documents contains blank rows $\\Rightarrow$ they must be discarded \n",
    "5. some character lines contain blank text $\\Rightarrow$ they must be discarded "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we apply the processing function to the dataset `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Dataset into line-character format!\n",
      "\n",
      "    source                                               line  \\\n",
      "0  Friends  how brave you are for starting your life over....   \n",
      "1  Friends  30 shiatsu.,Phoebe,S01E12 The Dozen Lasagnas,W...   \n",
      "2  Friends  the way you play with your hair when you're ne...   \n",
      "3  Friends  30 and Miss Somerfield canceled her 5:30 shiat...   \n",
      "4  Friends  how much you love your friends. Number three: ...   \n",
      "\n",
      "                                           character  \n",
      "0  Friends,the way you play with your hair when y...  \n",
      "1      Friends,30 and Miss Somerfield canceled her 5  \n",
      "2  Friends,how much you love your friends. Number...  \n",
      "3  Friends,00 herbal massage has been pushed back...  \n",
      "4  Friends,The way you cry at game shows. Number two  \n",
      "61314\n"
     ]
    }
   ],
   "source": [
    "df = process_char_dataset(df, character)\n",
    "if not isinstance(df, type(None)):\n",
    "    print(\"Processed Dataset into line-character format!\\n\")\n",
    "    print(df.head())\n",
    "    print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some errors can be detected after the whole process due to the bad quality of such scripts. In particular it can be noticed that if we provide a search for character name we can notice that there are some character which contains the name of the subject we selected (w.r.t `character`) but wchich instead they refear to other subjects of the show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters contanining Phoebe : {'S10E12 Phoebes Wedding,More back talk. And yes, I may be borrowing a few lines from my recent unsuccessful audition for Family Honor 2', 'S06E14 Chandler Cant Cry,Phoebe Buffay in Buffay', 'RACHEL and PHOEBE', 'Phoebe Sr.', 'S09E07 Rosss Inappropriate Song,Mom, dad, this is Phoebe. Phoebe, these are my parents', 'Phoebe shakes her hand and says', 'MONICA and PHOEBE', 'Past Life Phoebe', 'Phoebe and Leslie', 'Chandler, Phoebe, and Joey', 'S09E05 Phoebes Birthday Dinner,Well, lets see. The first one is', 'Phoebe  Mike', 'S09E05 Phoebes Birthday Dinner,I understand, separation is hard. One time I was about to leave Ross to go to the beauty parlor and he got so upset, he took off all his clothes, tucked his ??? between his legs and cried out', 'Amy turns around to Phoebe', 'Chandler and Phoebe', 'Chandler, Joey, and Phoebe', 'French Phoebe', 'Phoebe and Girl', 'Chandler, Phoebe, and Rachel', 'Phoebe and Ross', 'Phoebe, Joey, and Ross', 'Ross, Rachel, and Phoebe', 'PHOEBE and RYAN', 'Phoebe while cutting a sweet potatoe in the air', 'Rachel and Phoebe', \"Phoebe's Assistant\", 'Phoebe looks down', 'S03E16 The Morning After,Hi, its Phoebe. Listen someones gonna have to take my 9', 'Phoebe, Ross, Chandler, and Joey', 'PHOEBE', 'Phoebe and Monica', 'Phoebe  Joey', 'Phoebe-Estelle', 'Phoebe', 'Phoebe and Joey', 'Phoebe and Rachel', 'Phoebe Sr', 'Phoebe Waitress', \"S02E09 Phoebes Dad,Hey, here's a theme\", 'Phoebe ', 'Monica and Phoebe', 'Monica, Chandler and Phoebe', 'S03E14 Phoebes Ex-Partner,Okay, see now, what I just heard', \"S09E12 Phoebes Rats,Well, it was, and you would have seen it if you didn't showed up at  ... 9\", 'S09E05 Phoebes Birthday Dinner,Oh, uh, again. Can I make a special request', 'S09E05 Phoebes Birthday Dinner,kay, look', 'Phoebe and Gary', 'Monica, Chandler, Phoebe, and Rachel', 'CHANDLER, JOEY, and PHOEBE', 'Phoebe, Ross, Rachel', 'S03E14 Phoebes Ex-Partner,Its okay if it bothers you. Really. I mean the only thing I need to know is', 'S09E05 Phoebes Birthday Dinner,Wha-a how about this', 'S09E05 Phoebes Birthday Dinner,You not gonna believe this', \"Phoebe's Friends\", 'S03E14 Phoebes Ex-Partner,Okay, my next songs called', 'Phoebe, Ross, and Rachel', 'S09E05 Phoebes Birthday Dinner,Well, Ill tell you what were gonna do', 'Joey, Rachel, and Phoebe', 'Monica, Joey, and Phoebe'} 7478\n"
     ]
    }
   ],
   "source": [
    "# if the dataset is not None\n",
    "if not isinstance(df, type(None)):\n",
    "    # extract the list of names which contain the string in `character`\n",
    "    char_names = [c for c in df['character'] if character.lower() in c.lower()]\n",
    "    print(\"Characters contanining\", character, \":\", set(char_names), len(char_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further clean up the data, in order to remove the false aliases of the character, we discard the previously extracted list which contains all the names that also contain `character`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the dataset is not None\n",
    "if not isinstance(df, type(None)):\n",
    "    # subtract to the set of `char_names` the names to delete (`delete_names`)\n",
    "    char_names = set(char_names) - set(character_dict[character]['delete_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the dataset is not None\n",
    "if not isinstance(df, type(None)):\n",
    "    # Replace the in the dataset names, the only names contained in the resulting set after the\n",
    "    # subtruction of the name to delete with `character`\n",
    "    df['character'] = df['character'].apply(lambda x: character if x in char_names else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resulting names character are the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique character names in dataset after name processing: [\"Friends,the way you play with your hair when you're nervous. Number four\"\n",
      " 'Friends,30 and Miss Somerfield canceled her 5'\n",
      " 'Friends,how much you love your friends. Number three' ... 'Passenger  2'\n",
      " 'Passenger  3' 'Gate attendant  2']\n"
     ]
    }
   ],
   "source": [
    "# if the dataset is not None\n",
    "if not isinstance(df, type(None)):\n",
    "    print(\"Unique character names in dataset after name processing:\", df['character'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore the amount of final sentences are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining Phoebe sentences: 7476\n"
     ]
    }
   ],
   "source": [
    "# If the dataset is not None\n",
    "if not isinstance(df, type(None)):\n",
    "    print(\"Remaining\", character, \"sentences:\", len(df[df['character'] == character]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataset at ..\\Data\\Sources\\Friends\\Friends.csv\n"
     ]
    }
   ],
   "source": [
    "# if the dataset is not None\n",
    "if not isinstance(df, type(None)):\n",
    "    source_path = os.path.join(base_folder, \"Data\", \"Sources\", character_dict[character]['source'])\n",
    "    if not os.path.exists(source_path):\n",
    "        os.makedirs(source_path)\n",
    "    df.to_csv(os.path.join(source_path, str(character_dict[character]['source'])+\".csv\"), index=False)\n",
    "    print(\"Saved dataset at\", os.path.join(source_path, str(character_dict[character]['source'])+\".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: May consider feeding one sentence and one Sheldon reply or multiple sentences encoded with one Sheldon reply\n",
    "def get_character(df, level=2):\n",
    "    if character == 'Default':\n",
    "        return None\n",
    "    dataframe_rows = []\n",
    "    idxs_character = df[df['character'] == character].index\n",
    "    dataframe_rows = []\n",
    "    # Formats the column name\n",
    "    columns = ['response'] + ['context/'+str(i) for i in range(level)]\n",
    "    for i in idxs_character:\n",
    "        l = []\n",
    "        l.append(df['line'][i])\n",
    "        for j in range(0,level):\n",
    "            line = max(i-j-1,0)\n",
    "            l.append(df['line'][line])\n",
    "        dataframe_rows.append(l)\n",
    "    df = pd.DataFrame(dataframe_rows, columns=columns)\n",
    "    return df\n",
    "\n",
    "# Call the function\n",
    "df = get_character(df, level=level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can notice the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            response  \\\n",
      "0                  Come on in, live like bacon.,ROSS   \n",
      "1  Phoebe Buffay, What Can I Say. I Really Loved ...   \n",
      "2  blah-blah-blah, blah-blah-blah-blah-blah, blah...   \n",
      "3  How much it bothers you? because I dont like w...   \n",
      "4  00 with Mr. Rehack, cause its like 9:15 now, a...   \n",
      "\n",
      "                                           context/0  \\\n",
      "0                            the way you smell.,ROSS   \n",
      "1  nothing. All right? This is like the scariest ...   \n",
      "2  Phoebe Buffay, What Can I Say. I Really Loved ...   \n",
      "3  blah-blah-blah, blah-blah-blah-blah-blah, blah...   \n",
      "4                                         30.,Rachel   \n",
      "\n",
      "                                           context/1  \\\n",
      "0  The way you cry at game shows. Number two: how...   \n",
      "1  02. We ah, talked for a little while, and then...   \n",
      "2  nothing. All right? This is like the scariest ...   \n",
      "3  Phoebe Buffay, What Can I Say. I Really Loved ...   \n",
      "4                                           30.,Joey   \n",
      "\n",
      "                                           context/2  \\\n",
      "0             Easter, Christmas, what have you.,RTST   \n",
      "1                                          02.,Clerk   \n",
      "2  02. We ah, talked for a little while, and then...   \n",
      "3  nothing. All right? This is like the scariest ...   \n",
      "4                                           30.,Joey   \n",
      "\n",
      "                                           context/3  \\\n",
      "0  30 in the morning. We're not working out, it's...   \n",
      "1                                'Cookie Dude!',Ross   \n",
      "2                                          02.,Clerk   \n",
      "3  02. We ah, talked for a little while, and then...   \n",
      "4  How much it bothers you? because I dont like w...   \n",
      "\n",
      "                                           context/4  \n",
      "0        Sure, sweepin'. You never know.,MR. TREEGER  \n",
      "1  'Run for your life! Get out of the building!',...  \n",
      "2                                'Cookie Dude!',Ross  \n",
      "3                                          02.,Clerk  \n",
      "4  blah-blah-blah, blah-blah-blah-blah-blah, blah...  \n"
     ]
    }
   ],
   "source": [
    "# If the dataset is not None\n",
    "if not isinstance(df, type(None)):\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed dataset length: 7476\n"
     ]
    }
   ],
   "source": [
    "# If the dataset is not None\n",
    "if not isinstance(df, type(None)):\n",
    "    print(\"Preprocessed dataset length:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataset at ..\\Data\\Characters\\Phoebe\\Phoebe.csv\n"
     ]
    }
   ],
   "source": [
    "# If the dataset is not None\n",
    "if not isinstance(df, type(None)):\n",
    "    char_path = os.path.join(base_folder, \"Data\", \"Characters\", character)\n",
    "    if not os.path.exists(char_path):\n",
    "        os.makedirs(char_path)\n",
    "    df.to_csv(os.path.join(char_path, str(character)+\".csv\"), index=False)\n",
    "    print(\"Saved dataset at\", os.path.join(char_path, str(character)+\".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "451812313a2cc9ef7b1a116a2be532c610a0f65ac693e04b1a4edd064a67cb06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

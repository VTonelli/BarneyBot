{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a6f9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run environment setup\n",
    "import os\n",
    "import lib.BBSetup as BBSetup\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    BBSetup.colab_setup(mount_folder=r\"/content/drive/My Drive/unibo/NLP_project/BarneyBot\")\n",
    "except:\n",
    "    BBSetup.anaconda_setup(base_folder=r\"E:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBotGit\",\n",
    "                           env_name=\"nlp\")\n",
    "\n",
    "### Define folders\n",
    "base_folder = BBSetup.BASE_FOLDER\n",
    "out_folder = BBSetup.set_folder(os.path.join(base_folder, 'Data', 'Characters'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28206e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import for general utilities\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045f4655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import character dictionaries, useful to map a character to its data, and a fixed random seed\n",
    "from lib.BBData import character_dict, source_dict, random_state\n",
    "from lib.BBDataLoad import open_char_dataset, process_char_dataset\n",
    "\n",
    "character = 'Phoebe' # 'Barney' | 'Sheldon' | 'Harry' | 'Fry' | 'Vader' | 'Joey' | 'Phoebe' | 'Bender' | 'Default'\n",
    "# Sets the levels of context e.g. level=5 => have a sequance of context [context/0, ..., context/4]\n",
    "level = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1af0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the character selected is different from `Default` we extract the source where to find the data\n",
    "if character != 'Default':\n",
    "    source = character_dict[character]['source']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa6c658",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafca161",
   "metadata": {},
   "source": [
    "In this notebook, functions and procedures are set up that make it possible to preprocess the various corpus. These will then be used later to fine tune all chatbots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f427a8a",
   "metadata": {},
   "source": [
    "First of all let's start from laoding the dataset. This process will be performed by `load_dataset` which performs the loading of the dataset as DataFrame from each of the tv show we selected for our task:\n",
    "* [How I Met Your Mother](https://transcripts.foreverdreaming.org/viewforum.php?f=177)\n",
    "* [Futurama](https://theinfosphere.org/Episode_Transcript_Listing)\n",
    "* [Harry Potter](https://www.kaggle.com/gulsahdemiryurek/harry-potter-dataset)\n",
    "* [Star Wars](https://bulletproofscreenwriting.tv/star-wars-movies-screenplay-download/)\n",
    "* [Friends](https://www.kaggle.com/datasets/blessondensil294/friends-tv-series-screenplay-script)\n",
    "* [The Big Bang Theory](https://bigbangtrans.wordpress.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66771a84",
   "metadata": {},
   "source": [
    "Let's call the function to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a362cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute creation of dataset\n",
    "df = open_char_dataset(character, base_folder)\n",
    "if not isinstance(df, type(None)):\n",
    "    print(\"Loaded Dataset!\")\n",
    "    print()\n",
    "    print(df.head())\n",
    "    print(df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4dc447",
   "metadata": {},
   "source": [
    "Next we see the definition of the functions that preprocess the datasets. \n",
    "\n",
    "Generally, all the script files share the same structure for all the tv show we selected. Most relevant observation are the following:\n",
    "1. most scripts identify the incipit of an episode with square or round brackets $\\Rightarrow$ discard such lines,\n",
    "2. most scripts put inside round brackets, during the character line, some informations and details regarding some behaviors that character should have in that moment, $\\Rightarrow$ substitute all what there is between brackets with a blank char,\n",
    "3. most scripts identify a character's line with the character's name followed by a colon, $\\Rightarrow$ such lines should be divided into two part (i.e. one for character name and one for his line),\n",
    "4. some documents contains blank rows $\\Rightarrow$ they must be discarded \n",
    "5. some character lines contain blank text $\\Rightarrow$ they must be discarded "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1a01f0",
   "metadata": {},
   "source": [
    "Finally we apply the processing function to the dataset `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0730b0cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = process_char_dataset(df, character)\n",
    "if not isinstance(df, type(None)):\n",
    "    print(\"Processed Dataset into line-character format!\\n\")\n",
    "    print(df.head())\n",
    "    print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe23ad2",
   "metadata": {},
   "source": [
    "Some errors can be detected after the whole process due to the bad quality of such scripts. In particular it can be noticed that if we provide a search for character name we can notice that there are some character which contains the name of the subject we selected (w.r.t `character`) but wchich instead they refear to other subjects of the show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7e6f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the dataset is not None\n",
    "if not isinstance(df, type(None)):\n",
    "    # extract the list of names which contain the string in `character`\n",
    "    char_names = [c for c in df['character'] if character.lower() in c.lower()]\n",
    "    print(\"Characters contanining\", character, \":\", set(char_names), len(char_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ece4b0e",
   "metadata": {},
   "source": [
    "To further clean up the data, in order to remove the false aliases of the character, we discard the previously extracted list which contains all the names that also contain `character`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94931ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the dataset is not None\n",
    "if not isinstance(df, type(None)):\n",
    "    # subtract to the set of `char_names` the names to delete (`delete_names`)\n",
    "    char_names = set(char_names) - set(character_dict[character]['delete_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c530ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the dataset is not None\n",
    "if not isinstance(df, type(None)):\n",
    "    # Replace the in the dataset names, the only names contained in the resulting set after the\n",
    "    # subtruction of the name to delete with `character`\n",
    "    df['character'] = df['character'].apply(lambda x: character if x in char_names else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0545aa3",
   "metadata": {},
   "source": [
    "Resulting names character are the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e3f3eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if the dataset is not None\n",
    "if not isinstance(df, type(None)):\n",
    "    print(\"Unique character names in dataset after name processing:\", df['character'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8142f23e",
   "metadata": {},
   "source": [
    "Therefore the amount of final sentences are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6171f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the dataset is not None\n",
    "if not isinstance(df, type(None)):\n",
    "    print(\"Remaining\", character, \"sentences:\", len(df[df['character'] == character]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47f0197",
   "metadata": {},
   "source": [
    "Let's save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e217272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the dataset is not None\n",
    "if not isinstance(df, type(None)):\n",
    "    source_path = os.path.join(base_folder, \"Data\", \"Sources\", character_dict[character]['source'])\n",
    "    if not os.path.exists(source_path):\n",
    "        os.makedirs(source_path)\n",
    "    df.to_csv(os.path.join(source_path, str(character_dict[character]['source'])+\".csv\"), index=False)\n",
    "    print(\"Saved dataset at\", os.path.join(source_path, str(character_dict[character]['source'])+\".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1f4720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: May consider feeding one sentence and one Sheldon reply or multiple sentences encoded with one Sheldon reply\n",
    "def get_character(df, level=2):\n",
    "    if character == 'Default':\n",
    "        return None\n",
    "    dataframe_rows = []\n",
    "    idxs_character = df[df['character'] == character].index\n",
    "    dataframe_rows = []\n",
    "    # Formats the column name\n",
    "    columns = ['response'] + ['context/'+str(i) for i in range(level)]\n",
    "    for i in idxs_character:\n",
    "        l = []\n",
    "        l.append(df['line'][i])\n",
    "        for j in range(0,level):\n",
    "            line = max(i-j-1,0)\n",
    "            l.append(df['line'][line])\n",
    "        dataframe_rows.append(l)\n",
    "    df = pd.DataFrame(dataframe_rows, columns=columns)\n",
    "    return df\n",
    "\n",
    "# Call the function\n",
    "df = get_character(df, level=level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe20e8f",
   "metadata": {},
   "source": [
    "Below you can notice the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582e0824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the dataset is not None\n",
    "if not isinstance(df, type(None)):\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0372c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the dataset is not None\n",
    "if not isinstance(df, type(None)):\n",
    "    print(\"Preprocessed dataset length:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f209c26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the dataset is not None\n",
    "if not isinstance(df, type(None)):\n",
    "    char_path = os.path.join(base_folder, \"Data\", \"Characters\", character)\n",
    "    if not os.path.exists(char_path):\n",
    "        os.makedirs(char_path)\n",
    "    df.to_csv(os.path.join(char_path, str(character)+\".csv\"), index=False)\n",
    "    print(\"Saved dataset at\", os.path.join(char_path, str(character)+\".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f78d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "451812313a2cc9ef7b1a116a2be532c610a0f65ac693e04b1a4edd064a67cb06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

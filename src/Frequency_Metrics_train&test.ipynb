{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import character_dict\n",
    "from data_utils import random_state\n",
    "from frequency_utils import filter_by_weights, get_word_frequency, get_tfidfs, FrequencyChatbotClassifier\n",
    "from metric_utils import freq_pairwise_sim\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = list(character_dict.keys())\n",
    "characters.remove('Default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount google drive, if in Colaboratory environment\n",
    "import os\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive',force_remount=True)\n",
    "    base_folder = '/content/drive/My Drive/unibo/NLP_project/BarneyBot'\n",
    "    os.system(\"pip install datasets\")\n",
    "    os.system(\"pip install transformers\")\n",
    "    os.system(\"pip install rouge_score\")\n",
    "    os.system(\"pip install -U sentence-transformers\")\n",
    "else:\n",
    "    # base_folder = os.getcwd()\n",
    "    base_folder = '..'\n",
    "\n",
    "out_folder = os.path.join(base_folder, 'Data', 'Characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_docs = dict()\n",
    "for character in characters:\n",
    "    df = pd.read_csv(os.path.join(out_folder, character, f'{character}.csv'))\n",
    "    df_train, df_test = train_test_split(df, test_size=0.33, random_state=random_state)\n",
    "    character_docs[character] = {'train': df_train['response'].tolist(), \n",
    "                                 'test':  df_test['response'].tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(character_docs['Vader']['train']), len(character_docs['Vader']['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for character in tqdm(characters):\n",
    "    for i in range(len(character_docs[character]['train'])):\n",
    "        character_docs[character]['train'][i] = re.sub(r'[^A-Za-z\\s]', ' ', character_docs[character]['train'][i])\n",
    "        character_docs[character]['train'][i] = re.sub(r'\\s+', ' ', character_docs[character]['train'][i])\n",
    "    for i in range(len(character_docs[character]['test'])):\n",
    "        character_docs[character]['test'][i] = re.sub(r'[^A-Za-z\\s]', ' ', character_docs[character]['test'][i])\n",
    "        character_docs[character]['test'][i] = re.sub(r'\\s+', ' ', character_docs[character]['test'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordfreqs_train = dict()\n",
    "for character in tqdm(characters):\n",
    "    wordfreqs_train[character] = get_word_frequency(' '.join(character_docs[character]['train']), f_sorted=True)\n",
    "\n",
    "wordfreqs_test = dict()\n",
    "for character in tqdm(characters):\n",
    "    wordfreqs_test[character] = get_word_frequency(' '.join(character_docs[character]['test']), f_sorted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordfreqs_reduced_train = dict()\n",
    "for character in characters:\n",
    "    wordfreqs_reduced_train[character] = filter_by_weights(wordfreqs_train[character], mass=0.3)\n",
    "\n",
    "wordfreqs_reduced_test = dict()\n",
    "for character in characters:\n",
    "    wordfreqs_reduced_test[character] = filter_by_weights(wordfreqs_test[character], mass=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(input='content', stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfs = get_tfidfs([' '.join(character_docs[character]['train']) for character in characters], characters, tfidf_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfs_reduced = dict()\n",
    "for character in characters:\n",
    "    tfidfs_reduced[character] = filter_by_weights(tfidfs[character], mass=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordCloud Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "def plot_word_cloud(freqdict, cmap='viridis', title=None, plot=False):\n",
    "    wordcloud = WordCloud(background_color = 'black', width = 800, height = 400,\n",
    "                      colormap = cmap, max_words = 180, contour_width = 3,\n",
    "                      max_font_size = 80, contour_color = 'steelblue',\n",
    "                      random_state = 0)\n",
    "\n",
    "    wordcloud.generate_from_frequencies(freqdict)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.imshow(wordcloud, interpolation = 'bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_cloud(tfidfs_reduced['Barney'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency Pairwise Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_pairwise_sim(tfidfs_reduced['Fry'], tfidfs_reduced['Barney'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_classifier = FrequencyChatbotClassifier(characters, mode='word frequency')\n",
    "# wf_classifier.train(list(character_docs.values()))\n",
    "wf_classifier.train([character_docs[character]['train'] for character in characters])\n",
    "print(wf_classifier.predict(character_docs['Barney']['test'], mass=0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_classifier = FrequencyChatbotClassifier(characters, mode='tf-idf')\n",
    "tfidf_classifier.train([character_docs[character]['train'] for character in characters])\n",
    "print(tfidf_classifier.predict(character_docs['Barney']['test'], mass=0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_classifier = FrequencyChatbotClassifier(characters, mode='word frequency')\n",
    "# wf_classifier.train(list(character_docs.values()))\n",
    "wf_classifier.train([character_docs[character]['train'] for character in characters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = range(0, len(characters))\n",
    "y_pred = [np.argmax(list(wf_classifier.predict(character_docs[character]['test'], mass=0.3).values())\n",
    "                    ) for character in characters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_classifier = FrequencyChatbotClassifier(characters, mode='tf-idf')\n",
    "# wf_classifier.train(list(character_docs.values()))\n",
    "wf_classifier.train([character_docs[character]['train'] for character in characters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = range(0, len(characters))\n",
    "y_pred = [np.argmax(list(wf_classifier.predict(character_docs[character]['test'], mass=0.3).values())\n",
    "                    ) for character in characters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "451812313a2cc9ef7b1a116a2be532c610a0f65ac693e04b1a4edd064a67cb06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

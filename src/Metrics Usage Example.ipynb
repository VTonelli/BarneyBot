{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will present examples on how to use library BBMetric for evaluate our chatbots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip install -r \"E:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\\requirements.txt\"\n"
     ]
    }
   ],
   "source": [
    "### Run environment setup\n",
    "import os\n",
    "import lib.BBSetup as BBSetup\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    BBSetup.colab_setup(mount_folder=r\"/content/drive/My Drive/unibo/NLP_project/BarneyBot\")\n",
    "except:\n",
    "    try:\n",
    "        BBSetup.anaconda_manual_setup(base_folder=r\"E:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\",\n",
    "                                      env_name=\"barneybot\")\n",
    "    except:\n",
    "        BBSetup.anaconda_auto_setup(base_folder=r\"E:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\")\n",
    "\n",
    "### Define folders\n",
    "base_folder = BBSetup.BASE_FOLDER\n",
    "out_folder = BBSetup.set_folder(os.path.join(base_folder, 'Metrics', 'New'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Valerio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import the metrics library\n",
    "from lib.BBMetrics import BBMetric\n",
    "\n",
    "# Create some basic sentences to feed to the metrics\n",
    "sentences_basic = [\"Hi!\", \"How are you?\", \"I hate you.\"]\n",
    "sentences_basic_2 = [\"Hello!\", \"How are you doing?\", \"I think this is good.\"]\n",
    "sentences_vader = [\"Come to the dark side!\", \"I will kill you!\", \"Luke, I am your father.\"]\n",
    "sentences_barney = [\"Did you get the suit?\", \"Legendary!\", \"I like girls.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretty print module\n",
    "import pprint\n",
    "from lib.BBMetricResults import *\n",
    "\n",
    "printer = pprint.PrettyPrinter(depth=4, width=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BBMetric.metrics_list` show up the list of all the available metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['google bleu',\n",
       " 'mpnet embedding similarity',\n",
       " 'rouge l',\n",
       " 'meteor',\n",
       " 'emotion classifier',\n",
       " 'roberta crossencoding similarity',\n",
       " 'distinct',\n",
       " 'neural chatbot classifier',\n",
       " 'perplexity',\n",
       " 'repetitiveness',\n",
       " 'term error rate',\n",
       " 'bertscore',\n",
       " 'comet',\n",
       " 'bleurt',\n",
       " 'word mover distance',\n",
       " 'bartscore',\n",
       " 'extended edit distance',\n",
       " 't5 grammar correction edit distance',\n",
       " 'distilbert-embedded chatbot classifier']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the available metrics list\n",
    "BBMetric.metrics_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing a metric shows its info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'google bleu', 'args': {'train': {'required': set(), 'optional': set()}, 'compute': {'required': {'predictions', 'references'}, 'optional': set()}}, 'returns': ['score', 'std'], 'description': None, 'paper': None, 'save_actors': ['predictor', 'reference']}\n"
     ]
    }
   ],
   "source": [
    "# Display info for a loaded metric\n",
    "metric = BBMetric.load_metric(\"google bleu\")\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BBMetric.load_metric(metric_name)` load the specified metric with name `metric_name` by loading the respective model or algorithm which computes it. It will return the `metric` asked ready to be compute by invoking `metric.compute`. Some metrics (such as the human ones and the semantic classifier) require training, in which case a method `metric.train` is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.3148148148148148, 'std': 0.15930231976004866}\n"
     ]
    }
   ],
   "source": [
    "# Google BLEU (Variation of BLEU more useful for sentences) on a pair of sets of sentences\n",
    "metric = BBMetric.load_metric(\"google bleu\")\n",
    "\n",
    "print(metric.compute(predictions=sentences_basic, references=sentences_basic_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/14/2022 15:47:42 - INFO - happytransformer.happy_transformer -   Using model: cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.3076923076923077, 'std': 0.3076923076923077}\n"
     ]
    }
   ],
   "source": [
    "# Grammar Correction Distance on of sentences (based on a neural corrector plus a normalized edit distance)\n",
    "metric = BBMetric.load_metric(\"t5 grammar correction edit distance\")\n",
    "\n",
    "print(metric.compute(sentences=[\"this wrong is\", \"This is correct.\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.5964818000793457, 'std': 0.4743334650993347}\n"
     ]
    }
   ],
   "source": [
    "# Symmetric Semantic Similarity on a pair of sets of sentences\n",
    "metric = BBMetric.load_metric(\"mpnet embedding similarity\")\n",
    "\n",
    "print(metric.compute(sentences_a=sentences_basic, sentences_b=sentences_basic_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.36904761904761907, 'std': 0.3599099156626422}\n"
     ]
    }
   ],
   "source": [
    "# Rouge-L on a pair of sets of sentences\n",
    "metric = BBMetric.load_metric(\"rouge l\")\n",
    "\n",
    "print(metric.compute(predictions=sentences_basic, references=sentences_basic_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\tonel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tonel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\tonel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9739583333333334, 'std': 0.025779934730759544}\n"
     ]
    }
   ],
   "source": [
    "# METEOR on a pair of sets of sentences\n",
    "metric = BBMetric.load_metric(\"meteor\")\n",
    "\n",
    "print(metric.compute(predictions=sentences_basic, references=sentences_basic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:89: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': [0.040451311971992254, 0.3372651059180498, 0.0295343438629061, 0.33119263251622516, 0.24915530377378067, 0.012401272969630858], 'std': [0.02466328219141657, 0.3520862192023358, 0.03524458751490872, 0.3607271122098797, 0.31209391813628645, 0.008284036892139822], 'label': ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']}\n"
     ]
    }
   ],
   "source": [
    "# Emotion labeling on a set of sentences\n",
    "metric = BBMetric.load_metric(\"emotion classifier\")\n",
    "\n",
    "'''\n",
    "for char in ['Barney', 'Bender']:\n",
    "    char_hg = load_char_df(char, base_folder)\n",
    "    result = metric.compute(sentences=char_hg['test']['response'])\n",
    "    print(char + \"Emotions\")\n",
    "    printer.pprint({result['label'][i]: result['score'][i] for i in range(len(result['score']))})\n",
    "'''\n",
    "\n",
    "print(metric.compute(sentences=sentences_basic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.6090299487113953, 'std': 0.4026722013950348}\n"
     ]
    }
   ],
   "source": [
    "# Semantic Answer Similarity on a pair of sets of sentences\n",
    "metric = BBMetric.load_metric(\"roberta crossencoding similarity\")\n",
    "\n",
    "print(metric.compute(predictions=sentences_basic, references=sentences_basic_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.1272727272727273, 'std': 0.09030099651970509}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distinct on a set of sentences\n",
    "metric = BBMetric.load_metric(\"distinct\")\n",
    "\n",
    "# ngram_size is optional, defaults to 3\n",
    "metric.compute(sentences=sentences_basic, ngram_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.04097739979624748, 'std': 0.04034863039851189}\n",
      "{'score': 0.641024649143219, 'std': 0.2366839498281479}\n",
      "{'score': 0.10722770541906357, 'std': 0.08116302639245987}\n"
     ]
    }
   ],
   "source": [
    "# Semantic Classifier on a set of sentences\n",
    "metric = BBMetric.load_metric(\"neural chatbot classifier\")\n",
    "\n",
    "from lib.BBData import character_dict\n",
    "\n",
    "# n_shuffles is optional, defaults to 10\n",
    "# Either specify a source_encoded_path to load encoded lines, or specify a source_path and a source_save_path to create them\n",
    "# shutdown_at_end is optional, defaults to False\n",
    "metric.train(character='Vader', random_state=random_state,\n",
    "             source_encoded_path=None,\n",
    "             source_path=os.path.join(base_folder, \"data\", \"Sources\", character_dict[\"Vader\"]['source'], character_dict[\"Vader\"]['source'] + \".csv\"),\n",
    "             source_save_path=os.path.join(base_folder, \"data\", \"Characters\", 'Vader'),\n",
    "             save_path=os.path.join(base_folder, \"data\", \"Characters\", 'Vader'),\n",
    "             n_shuffles=10, shutdown_at_end=False)\n",
    "\n",
    "# Computations for Barney semantic classifier on different sets of sentences\n",
    "print(metric.compute(character='Vader',\n",
    "                     load_path=os.path.join(base_folder, \"Data\", \"Characters\", 'Vader', character_dict[\"Vader\"]['classifier_folder']),\n",
    "                     sentences=sentences_basic))\n",
    "print(metric.compute(character='Vader',\n",
    "                     load_path=os.path.join(base_folder, \"Data\", \"Characters\", 'Vader', character_dict[\"Vader\"]['classifier_folder']),\n",
    "                     sentences=sentences_vader))\n",
    "print(metric.compute(character='Vader',\n",
    "                     load_path=os.path.join(base_folder, \"Data\", \"Characters\", 'Vader', character_dict[\"Vader\"]['classifier_folder']),\n",
    "                     sentences=sentences_barney))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d93bf9405ee4fe996b74cf156b83e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82cd68f178394805b1c7e30af3723f04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdbc9e36c9b746bbb8abf15c3b967400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at E:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\\Data\\Characters\\Vader\\vader_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n",
      "Using custom data configuration default-3e37c23a51e9d556\n",
      "Found cached dataset csv (E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-3e37c23a51e9d556/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2feb93973c5a43c883ae400924095c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-3e37c23a51e9d556/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-6affe80547fc0f38.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-3e37c23a51e9d556/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-6800bd34204a2976.arrow\n",
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-3e37c23a51e9d556/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-78893b2d23cae2d7.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-3e37c23a51e9d556/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-38619cd96763b020.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc545f01a105456a971ca101f4b77028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb08b050fc2f485e91d570cb8173e0d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "545f90801d1b4df69f0cae4d1835f002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:34<00:00, 17.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 20.613982847195594}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Perplexity on an encoded test set (taken from one of our datasets)\n",
    "metric = BBMetric.load_metric(\"perplexity\")\n",
    "\n",
    "# Functions to load a dataset and prepare it, used for perplexity\n",
    "from transformers import TFAutoModelForCausalLM, AutoTokenizer\n",
    "from lib.BBData import character_dict, source_dict, random_state, model_name\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from lib.BBDataLoad import load_char_df, dialogpt_preprocess_function\n",
    "\n",
    "# Get dialogpt tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=os.path.join(base_folder, \"cache\"))\n",
    "tokenizer.pad_token = '#'\n",
    "\n",
    "# Select a batch size, used for perplexity\n",
    "batch_size = 8\n",
    "\n",
    "# Load the Vader dialogpt finetuned model\n",
    "model_vader = TFAutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=\\\n",
    "                    os.path.join(base_folder, 'Data', 'Characters', 'Vader', character_dict['Vader']['checkpoint_folder']))\n",
    "model_vader.compile()\n",
    "data_collator = DataCollatorForLanguageModeling(mlm=False, tokenizer=tokenizer, return_tensors='tf')\n",
    "\n",
    "# Load the Barney dataset and process it as a conversation\n",
    "vader_hg = load_char_df('Vader', base_folder)\n",
    "tokenized_vader_hg = vader_hg.map(lambda row: dialogpt_preprocess_function(row, tokenizer), batched=False)\n",
    "# Transform the HuggingFace dataset as a tensorflow one, ready to be fed to the model\n",
    "vader_test_set = tokenized_vader_hg[\"test\"].to_tf_dataset(\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "print(metric.compute(model=model_vader, encoded_test_set=vader_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.2333333333333333, 'std': 0.09428090415820632}\n"
     ]
    }
   ],
   "source": [
    "# Repetitiveness of sentences\n",
    "metric = BBMetric.load_metric(\"repetitiveness\")\n",
    "\n",
    "print(metric.compute(sentences=sentences_basic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 76.66666666666667, 'std': 20.548046676563256}\n"
     ]
    }
   ],
   "source": [
    "# TER on a pair of sets of sentences\n",
    "metric = BBMetric.load_metric(\"term error rate\")\n",
    "\n",
    "print(metric.compute(predictions=sentences_basic, references=sentences_basic_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.8650024731953939, 'std': 0.09010275421675674}\n"
     ]
    }
   ],
   "source": [
    "# BERTScore on a pair of sets of sentences\n",
    "metric = BBMetric.load_metric(\"bertscore\")\n",
    "\n",
    "print(metric.compute(predictions=sentences_basic, references=sentences_basic_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eamt22-cometinho-da is already in cache.\n",
      "Path lightning_logs/cometinho_part-i/checkpoints/epoch=0-step=899999.ckpt does not exist!\n",
      "E:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=0)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': -1.1263877749443054, 'std': 0.19313412800715013}\n"
     ]
    }
   ],
   "source": [
    "# COMET on a triple of sets of sentences\n",
    "metric = BBMetric.load_metric(\"comet\")\n",
    "\n",
    "print(metric.compute(sources=sentences_basic, predictions=sentences_barney, references=sentences_basic_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default BLEURT-Base checkpoint for sequence maximum length 128. You can use a bigger model for better results with e.g.: evaluate.load('bleurt', 'bleurt-large-512').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint C:\\Users\\tonel\\.cache\\huggingface\\metrics\\bleurt\\default\\downloads\\extracted\\b094b72f3dc7e1712a641ab624024c3b182ff714848ee334f1cc7a628d0b7798\\bleurt-base-128.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading checkpoint C:\\Users\\tonel\\.cache\\huggingface\\metrics\\bleurt\\default\\downloads\\extracted\\b094b72f3dc7e1712a641ab624024c3b182ff714848ee334f1cc7a628d0b7798\\bleurt-base-128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Config file found, reading.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config file found, reading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Will load checkpoint bert_custom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will load checkpoint bert_custom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loads full paths and checks that files exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loads full paths and checks that files exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... name:bert_custom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... name:bert_custom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... vocab_file:vocab.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... vocab_file:vocab.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... bert_config_file:bert_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... bert_config_file:bert_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... do_lower_case:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... do_lower_case:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... max_seq_length:128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... max_seq_length:128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating BLEURT scorer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating BLEURT scorer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating WordPiece tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating WordPiece tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WordPiece tokenizer instantiated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating Eager Mode predictor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Eager Mode predictor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BLEURT initialized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': -1.504532257715861, 'std': 0.18247956505028967}\n"
     ]
    }
   ],
   "source": [
    "# BLEURT on a pair of sets of sentences\n",
    "metric = BBMetric.load_metric(\"bleurt\")\n",
    "\n",
    "print(metric.compute(predictions=sentences_barney, references=sentences_basic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removed 1 and 1 OOV words from document 1 and 2 (respectively).\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "built Dictionary(2 unique tokens: ['come', 'dark']) from 2 documents (total 4 corpus positions)\n",
      "Dictionary lifecycle event {'msg': \"built Dictionary(2 unique tokens: ['come', 'dark']) from 2 documents (total 4 corpus positions)\", 'datetime': '2022-11-14T13:08:04.326902', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "Removed 1 and 1 OOV words from document 1 and 2 (respectively).\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "built Dictionary(1 unique tokens: ['kill']) from 2 documents (total 2 corpus positions)\n",
      "Dictionary lifecycle event {'msg': \"built Dictionary(1 unique tokens: ['kill']) from 2 documents (total 2 corpus positions)\", 'datetime': '2022-11-14T13:08:04.537950', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "Removed 2 and 2 OOV words from document 1 and 2 (respectively).\n",
      "At least one of the documents had no words that were in the vocabulary.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.0, 'std': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# Word Mover Distance on a pair of sets of sentences\n",
    "metric = BBMetric.load_metric(\"word mover distance\")\n",
    "\n",
    "print(metric.compute(predictions=sentences_vader, references=sentences_vader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': -4.447240034739177}\n"
     ]
    }
   ],
   "source": [
    "# BARTScore on a pair of sets of sentences\n",
    "metric = BBMetric.load_metric(\"bartscore\")\n",
    "\n",
    "print(metric.compute(predictions=sentences_barney, references=sentences_basic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.8360909024874369, 'std': 0.05260148578323149}\n"
     ]
    }
   ],
   "source": [
    "# EED on a pair of sets of sentences\n",
    "metric = BBMetric.load_metric(\"extended edit distance\")\n",
    "\n",
    "print(metric.compute(predictions=sentences_barney, references=sentences_basic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[      character                                               line\n",
      "790           0  Ooh, hold on, let me check my personality. Oh,...\n",
      "591           0  Wait a second. Sorry, continues. Yes, exactly,...\n",
      "1076          0  That was close. Read it. Pant, pant... Wait-wa...\n",
      "795           0  No, I said. This is my story. You see, the you...\n",
      "918           0  Well you'll excuse me, I have a date with Bata...\n",
      "...         ...                                                ...\n",
      "279           0  What do you think of this tie? I-I don't take ...\n",
      "353           0  Hundred dollars says when you turn around, I s...\n",
      "1356          0  Yeah, but it's one thing to say it, it's anoth...\n",
      "1135          0  Teddy? Works at every time. Uh, dance. And he ...\n",
      "889           0  Uh... Bless you would have been nice. Oh, that...\n",
      "\n",
      "[1413 rows x 2 columns],       character                                               line\n",
      "790           1  You dont jog. Excuse me. Im recovering from a ...\n",
      "591           1  This is ridiculous. Im a grown man from Texas....\n",
      "1076          1  Thats the wrong box. Put it back. Well, if its...\n",
      "795           1  I want to say no, but its too glorious. Get in...\n",
      "918           1  Well, what a sad state of affairs. That youve ...\n",
      "...         ...                                                ...\n",
      "279           1  Leonard. I wish you could all be inside my hea...\n",
      "353           1  Im sensing things have gotten awkward. No, bec...\n",
      "1356          1  Heres an interesting fact about alcohol. Why n...\n",
      "1135          1  Or Don Quixote is a book about a donkey named ...\n",
      "889           1  All right, youve made your point. A fine prank...\n",
      "\n",
      "[1413 rows x 2 columns],       character                                               line\n",
      "790           2  We'll just go. Nicholas Flamel...where are you...\n",
      "591           2  Expelliarmus! Resigned? Why? But he's a ghost,...\n",
      "1076          2  Whos plotting them? Come with us now. Come on....\n",
      "795           2  Buckbeak. Okay? Tom Riddle's diary is gone. Ke...\n",
      "918           2  Wait! I mean, I'm just Harry. One minute. You ...\n",
      "...         ...                                                ...\n",
      "279           2  Hagrid never opened the Chamber of Secrets. I-...\n",
      "353           2  No. Is that really...? Please be quiet! Yeah. ...\n",
      "1356          2  Get off! we almost get killed by a tree... Wha...\n",
      "1135          2  Arania Exumai! Checkmate. Snoring Some kind of...\n",
      "889           2  That's one nasty dementor. Yeah, sure. Oh, nic...\n",
      "\n",
      "[1413 rows x 2 columns],       character                                               line\n",
      "790           3  Bender? You stole the atom? Almost there. Just...\n",
      "591           3  Good, good, then what? Wow! The Zapp Brannigan...\n",
      "1076          3  Are there really giant birds like that? Does t...\n",
      "795           3  Your Mayorness, if you execute him, you have t...\n",
      "918           3  The moon was like this awesome, romantic, myst...\n",
      "...         ...                                                ...\n",
      "279           3  That's awful Professor. Especially the making ...\n",
      "353           3  Good. Good. Uh, yeah. Look at that exhaust fan...\n",
      "1356          3  Uh, OK. Oh, man! Wow! You're some guy who eats...\n",
      "1135          3  80,000 years? Well? How are they? Oh, they're ...\n",
      "889           3  What happened? Come on! I guess he realised I ...\n",
      "\n",
      "[1413 rows x 2 columns],       character                                               line\n",
      "790           4  As usual! Run away! Hello? Imperial Dragon Res...\n",
      "591           4  Shut the hell up! Yup! Bender is back. I'll sa...\n",
      "1076          4  Yes I am. Having just this minute regained con...\n",
      "795           4  Hey! Yeah, right! Wow. So musicians really Rod...\n",
      "918           4  Where would the Professor be without students ...\n",
      "...         ...                                                ...\n",
      "279           4  Well, aside from causing eye cancer, these thi...\n",
      "353           4  Get the hell off my planet. Wait! What's that?...\n",
      "1356          4  ...You could not foresee... Blackmail is such ...\n",
      "1135          4  Yeah. Now are you gonna come to the squid figh...\n",
      "889           4  I promise nothing! Mom! It's me, Bender. Look ...\n",
      "\n",
      "[1413 rows x 2 columns],       character                                               line\n",
      "790           5  Make ready to land out troops beyond the energ...\n",
      "591           5  As you wish. Darth Vader calmly adjusts his co...\n",
      "1076          5  Vader's ship spins off into space. Her resista...\n",
      "795           5  As you wish. Alert all commands.Calculateevery...\n",
      "918           5  You have learned much, young one. If he could ...\n",
      "...         ...                                                ...\n",
      "279           5  There is no escape. Don't make me destroy you....\n",
      "353           5  No. Leave them to me. I will deal You found so...\n",
      "1356          5  Darth Vader calmly adjusts his control stick a...\n",
      "1135          5  Did you find any droids? You are unwise to low...\n",
      "889           5  You may dispense with thepleasantries, Command...\n",
      "\n",
      "[1413 rows x 2 columns],       character                                               line\n",
      "790           6  Wow! Theres a lot I didnt know about vomit. Wh...\n",
      "591           6  Hey, hey, hey, hey. Look. I take a girl out, s...\n",
      "1076          6  Oh. Well good!  What is this? Did you give you...\n",
      "795           6  Ooh-ooh, Pheebs, you want a strong name? How a...\n",
      "918           6  Nice move. Hmmm, soup!  Hmm, soup! Pretty good...\n",
      "...         ...                                                ...\n",
      "279           6  I do Rach. I do, and I so happy for you. So uh...\n",
      "353           6  A date?! No, no Pheebs you-you must be mistake...\n",
      "1356          6  Seriously, who is this guy? Well it does when ...\n",
      "1135          6  Come on, I'll show you guys where to check in ...\n",
      "889           6  Thats weird! That's what this is about! Oh my ...\n",
      "\n",
      "[1413 rows x 2 columns],       character                                               line\n",
      "790           7  What is that sparkly thing? Oh please, these g...\n",
      "591           7  It's too soon to tell. She's resting, which is...\n",
      "1076          7  What a sad little life she must lead. Okay, oo...\n",
      "795           7  All right, dont freak out! Okay? I-I will help...\n",
      "918           7  Okay, you have 19 questions left. Use them wis...\n",
      "...         ...                                                ...\n",
      "279           7  Yeah, but you always say that. Hi. He doesn't ...\n",
      "353           7  I cant say that didnt hurt. But Ill take you b...\n",
      "1356          7  Ohh, you guys, remember that cute client I tol...\n",
      "1135          7  Not if you were here. Yeah? Oh, Chandler funny...\n",
      "889           7  Oh yeah! I'd let him check out my kitchen floo...\n",
      "\n",
      "[1413 rows x 2 columns]]\n",
      "[      character                                               line\n",
      "1558          0  You know what? I am sick. Sick of you telling ...\n",
      "1417          0  Aw, man! Wait. Which half? Yeah, I'm nervous f...\n",
      "164           0  Whatever you say. No problem. I just need to t...\n",
      "33            0  I love you. The... mmm. Social experiment.  U....\n",
      "1320          0  Hey, this is a chair, but go ahead and drag it...\n",
      "...         ...                                                ...\n",
      "275           0  No reason not to do so. Really? Look. Tyler? T...\n",
      "1530          0  I, yes. Follow me. I... been betrayed by my be...\n",
      "796           0  You're not Lily. Lily is a diabolical puppet m...\n",
      "430           0  Bet held. Well, this isn't going to make it an...\n",
      "673           0  Tell people what? 'Definitely. Great! Dude, th...\n",
      "\n",
      "[157 rows x 2 columns],       character                                               line\n",
      "1558          1  Oh, hello. Im not nearly drunk enough. Okay. D...\n",
      "1417          1  Howard, dont embarrass yourself, the science c...\n",
      "164           1  That game? Excuse me, Penny, but Doodle Jump i...\n",
      "33            1  Keep a lookout. This place is swarming with ca...\n",
      "1320          1  Hes in the laundry room now. Now would be a go...\n",
      "...         ...                                                ...\n",
      "275           1  My apologies. Good night, Amy. Sad. No, Leonar...\n",
      "1530          1  I believe in knowing my enemy, Leonard. Had Tw...\n",
      "796           1  And if they ever come out with a game called W...\n",
      "430           1  Yeah, thats great. Did you bring your puppet? ...\n",
      "673           1  Oh, now Perlmutters shaking the Kings hand. Ye...\n",
      "\n",
      "[157 rows x 2 columns],       character                                               line\n",
      "1558          2  When he does, I'm gonna kill him! I'm... You'r...\n",
      "1417          2  I broke the law. Underage wizards can't use ma...\n",
      "164           2  Brilliant! Where did you get it? And why did y...\n",
      "33            2  They're gonna kill him? Yeah? Try me. Okay. At...\n",
      "1320          2  Really? I meant the match. Who won? He killed ...\n",
      "...         ...                                                ...\n",
      "275           2  Why can't we get through? Hello, can you hear ...\n",
      "1530          2  Hermione, move! One pair of dragon hide gloves...\n",
      "796           2  I've got Dumbledore! But then I remembered tha...\n",
      "430           2  You're wrong! Quickly. Hurry up. Okay? And who...\n",
      "673           2  Can you hear me? Hold on. But have you seen it...\n",
      "\n",
      "[157 rows x 2 columns],       character                                               line\n",
      "1558          3  He could dig up bones. What was your minor? Ma...\n",
      "1417          3  Mmm! The gristle-in-a-blanket isn't half bad. ...\n",
      "164           3  And another thing: You're using an awful lot o...\n",
      "33            3  Damnit, we'll have to fix the engine ourself. ...\n",
      "1320          3  All this prolonged exposure to radiation is ma...\n",
      "...         ...                                                ...\n",
      "275           3  Certainly yes us! Uh-huh, sir! We've gotta bri...\n",
      "1530          3  Yeah yeah yeah keep it comin' put the pot down...\n",
      "796           3  Come on freedom cage! Roll me to safety! Yes! ...\n",
      "430           3  Oh! Yeah, they get around! But I'm afraid we h...\n",
      "673           3  Not big enough. We need something that can tak...\n",
      "\n",
      "[157 rows x 2 columns],       character                                               line\n",
      "1558          4  Fat chance. You can't count on God for jack. H...\n",
      "1417          4  How much more? Hey, that's my last beer, you b...\n",
      "164           4  Never! All right, let's mush some worms! Cater...\n",
      "33            4  Kill all humans...kill all humans...must kill ...\n",
      "1320          4  Nooo! We can hide in here, it's free on Tuesda...\n",
      "...         ...                                                ...\n",
      "275           4  I'd only met the defendant, Fry, once, but I k...\n",
      "1530          4  Bite my colossal metal ass! I'd be cuddly too ...\n",
      "796           4  Well, we're boned! I'm really starting to swel...\n",
      "430           4  Our universe is doomed! No! Huh? I've had it u...\n",
      "673           4  You were looking up curse words in the diction...\n",
      "\n",
      "[157 rows x 2 columns],       character                                               line\n",
      "1558          5  I do not want the Emperor's prizedamaged.We wi...\n",
      "1417          5  He's all yours bounty hunter. Reset the chambe...\n",
      "164           5  Escape is not his plan. I must face him alone....\n",
      "33            5  It is pointless to resist, my son. Don't play ...\n",
      "1320          5  You have failed me for the lasttime, Admiral.C...\n",
      "...         ...                                                ...\n",
      "275           5  What? As you wish. Vader's ship spins off into...\n",
      "1530          5  Vader takes aim on Luke and talks to the wingm...\n",
      "796           5  Your powers are weak, old man. That is correct...\n",
      "430           5  Commence primary ignition. VADERme. Don't be t...\n",
      "673           5  I have felt him, my Master. Your powers are we...\n",
      "\n",
      "[157 rows x 2 columns],       character                                               line\n",
      "1558          6  Wow, really? Well, maybe I can help. Well-well...\n",
      "1417          6  Its all London, baby! Here we go. Come on baby...\n",
      "164           6  Hey and look he brought flowers. Thanks Ross, ...\n",
      "33            6  Need a new table. Yeah! Looks like that no dat...\n",
      "1320          6  Me too, but I guess I do have a couple of more...\n",
      "...         ...                                                ...\n",
      "275           6  Yeah, o-o-o-o-okay anyway, I just wanted to sa...\n",
      "1530          6  I can an A? In-in school?  Hey, Im a dork. Yea...\n",
      "796           6  Food? Uh-huh gimme! Hey, if anybody gets extra...\n",
      "430           6  Where are you going? The vicar wont be home fo...\n",
      "673           6  All that stuff you just said? I want that! Hey...\n",
      "\n",
      "[157 rows x 2 columns],       character                                               line\n",
      "1558          7  Really? What is that? Okay, so now they know t...\n",
      "1417          7  I know, I'm sorry, please forgive me. I don't ...\n",
      "164           7  Duly noted. So youre not homesick yet? Aren't ...\n",
      "33            7  That wouldn't stand in the way of a true piani...\n",
      "1320          7  I knew it, wow!! Oh my God! Yeah, I don't know...\n",
      "...         ...                                                ...\n",
      "275           7  Oh, I wasnt talking about his karma. Come on, ...\n",
      "1530          7  You cant have sex with her! Hey! You were real...\n",
      "796           7  Hey. Okay. What is that? Standing in living ro...\n",
      "430           7  Oh, Pervert Parade? Yeah and I-I found you one...\n",
      "673           7  You heard her too?! You have the gift! Im sorr...\n",
      "\n",
      "[157 rows x 2 columns]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8488\\2260006675.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmetric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBBMetric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"distilbert-embedded chatbot classifier\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m metric.train(characters_path=os.path.join(base_folder, \"Data\", \"Characters\"),\n\u001b[0m\u001b[0;32m      5\u001b[0m              save_path=os.path.join(base_folder, \"Data\", \"Metrics\", \"distilbert-embedder\"))\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\\Src\\lib\\BBMetrics.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    586\u001b[0m                 kwargs['shutdown_at_end'] if 'shutdown_at_end' in kwargs else False)\n\u001b[0;32m    587\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"distilbert-embedded chatbot classifier\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m             self.metric.train(characters_path=kwargs['characters_path'],\n\u001b[0m\u001b[0;32m    589\u001b[0m                               \u001b[0mmodel_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'save_path'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m                               \u001b[0mtrain_embedder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train_embedder'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m'train_embedder'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\\Src\\lib\\metrics\\distil_bert_classifier.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, characters_path, model_path, train_embedder, override_data, merge_sentences, verbose, shutdown_at_end)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m         \u001b[1;31m### get/create dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m         X_train, y_train, _, _ = self.get_data(\n\u001b[0m\u001b[0;32m    245\u001b[0m             \u001b[0msource_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcharacters_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[0moverride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\\Src\\lib\\metrics\\distil_bert_classifier.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self, source_path, override, merge_sentences, n_sentences, verbose)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_list_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_list_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_list_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'line'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m         \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_list_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'character'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_list_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'line'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "# Distilbert classifier on a set of sentences\n",
    "metric = BBMetric.load_metric(\"distilbert-embedded chatbot classifier\")\n",
    "\n",
    "metric.train(characters_path=os.path.join(base_folder, \"Data\", \"Characters\"),\n",
    "             save_path=os.path.join(base_folder, \"Data\", \"Metrics\", \"distilbert-embedder\"))\n",
    "\n",
    "print(metric.compute(sentences=sentences_barney))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency-based classifier on a set of sentences\n",
    "metric = BBMetric.load_metric(\"frequency chatbot classifier\")\n",
    "\n",
    "metric.train(characters_path=os.path.join(base_folder, \"Data\", \"Characters\"),\n",
    "             mode=\"c-tf-idf\")\n",
    "\n",
    "print(metric.compute(sentences=sentences_barney))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving & Loading Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric metadata creation\n",
    "metric_name = 'dummy metric'\n",
    "metric_name_pretty = 'Dummy Metric'\n",
    "metric_version = 1\n",
    "metric_actors = {\n",
    "    \"document\": [\n",
    "        MetricActor.DATASET_CHAR,\n",
    "        \"Barney\"\n",
    "    ],\n",
    "    \"training_set\": [\n",
    "        MetricActor.DATASET_CHAR,\n",
    "        \"Barney\"\n",
    "    ]\n",
    "}\n",
    "metric_result = {\n",
    "    \"score\": 0.9984034299850464,\n",
    "    \"std\": 0.027748608961701393\n",
    "}\n",
    "metric_attempt = 0\n",
    "metric_context = {                          \n",
    "    \"dialogpt_size\": \"small\",\n",
    "    \"dialogpt_context_sentences\": 5,\n",
    "    \"dialogpt_nbeams_beams\": 3,\n",
    "    \"dialogpt_sample_top_p\": 0.92,\n",
    "    \"dialogpt_sample_top_k\": 50\n",
    "}\n",
    "metric_params = {}\n",
    "metric_samples = 'Unknown'\n",
    "metric_hash = dict_hash({'metric_name': metric_name,\n",
    "                                         'metric_version': metric_version,\n",
    "                                         'metric_attempt': metric_attempt,\n",
    "                                         'metric_actors': metric_actors,\n",
    "                                         'context': metric_context,\n",
    "                                         'metric_params': metric_params,\n",
    "                                         'metric_samples': metric_samples})\n",
    "\n",
    "# This is the important one. Each metric should contain all these entries\n",
    "metric_dict = {\n",
    "        \"metric_name\": metric_name,           # Unique name of the metric\n",
    "        \"metric_version\": metric_version,     # Metric version (useful if you change how a metric works and recompute)\n",
    "        \"metric_attempt\": metric_attempt,     # Incremental value for multiple computations of the same metric (e.g. for std)\n",
    "        \"metric_actors\": metric_actors,       # Who this metric is computed on\n",
    "        \"metric_dependency\": get_metric_dependency(metric_name, metric_actors), # Is this metric a function of data or chatbot?\n",
    "        \"metric_params\": metric_params,       # Additional params of the metric (e.g. ngram_size for distinct)\n",
    "        \"context\": metric_context,            # External parameters, such as chatbot characteristics\n",
    "        \"metric_arity\": get_metric_arity(metric_name), # Metric arity\n",
    "        \"metric_samples\": metric_samples,     # Batch size of the metric\n",
    "        \"metric_determinism\": get_metric_determinism(metric_name, metric_version), # Is this metric algorithmic or not?\n",
    "        \"answer\": metric_result,              # Score of the metric, may include std (Any dictionary can go here)\n",
    "        \"hash\": metric_hash                   # Unique hash for this metric, used to not store duplicates\n",
    "    }\n",
    "\n",
    "metric_dict = {\n",
    "    metric_hash: metric_dict\n",
    "}\n",
    "printer.pprint(metric_dict) # Metric is now ready to be saved!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "save_metric_by_name(out_folder, 'Dummy Metric', metric_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metrics\n",
    "metric_dict = load_metric_by_name(out_folder, 'Dummy Metric')\n",
    "printer.pprint(metric_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "451812313a2cc9ef7b1a116a2be532c610a0f65ac693e04b1a4edd064a67cb06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

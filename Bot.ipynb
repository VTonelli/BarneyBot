{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the dataset documents and store their data into a DataFrame\n",
    "def load_himym_dataset():\n",
    "    episodes_folder = os.path.join(os.getcwd(), \"Datasets\", \"Sources\", \"HIMYM\", \"Episodes\")\n",
    "    dataframe_rows = []\n",
    "    # Get number of documents and their names\n",
    "    documents_n = len(os.listdir(episodes_folder))\n",
    "    documents_names = os.listdir(episodes_folder)\n",
    "\n",
    "    # Loop over documents\n",
    "    for i in tqdm(range(documents_n)):\n",
    "        filename = documents_names[i]\n",
    "        # Open document\n",
    "        file = open(os.path.join(episodes_folder, filename))\n",
    "        episode_index = filename[:-4]\n",
    "        # Loop over lines (= words)\n",
    "        for line in file.readlines():\n",
    "                dataframe_row = {\n",
    "                    \"episode\": episode_index,\n",
    "                    \"line\": line,\n",
    "                }\n",
    "                dataframe_rows.append(dataframe_row)\n",
    "    # Build the dataframe from the words\n",
    "    df = pd.DataFrame(dataframe_rows)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:02<00:00, 59.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "episode    39284\n",
       "line       39284\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute creation of dataset\n",
    "himym_df = load_himym_dataset()\n",
    "himym_df.head()\n",
    "himym_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30274\n"
     ]
    }
   ],
   "source": [
    "def process_himym_dataset(df):\n",
    "    df = df[~df['line'].str.startswith(\"[\")]\n",
    "    df = df[~df['line'].str.startswith(\"(\")]\n",
    "    df['line'] = df['line'].str.strip()\n",
    "    df['line'] = df['line'].str.replace(r\"\\(.*\\)\",\"\")\n",
    "    df['line'] = df['line'].str.replace(r\"[\\/(){}\\[\\]\\|@_#]|\\\\t|\\\\n\",\" \")\n",
    "    df['line'] = df['line'].str.replace(r\"[^.\\',;:?!0-9a-zA-Z \\-]\",\"\")\n",
    "    df = df[~df['line'].isnull()]\n",
    "    df[['character', 'line']] = df['line'].str.split(\":\", 1, expand=True)\n",
    "    df = df.dropna()\n",
    "    df['line'] = df['line'].str.strip()\n",
    "    df['line'] = df['line'][df['line'].str.len() >= 2]\n",
    "    df = df[~df['line'].isnull()]\n",
    "    df = df.dropna()\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "    \n",
    "himym_df = process_himym_dataset(himym_df)\n",
    "print(len(himym_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode</th>\n",
       "      <th>line</th>\n",
       "      <th>character</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01x01</td>\n",
       "      <td>Kids, I'm going to tell you an incredible stor...</td>\n",
       "      <td>Narrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01x01</td>\n",
       "      <td>Are we being punished for something?</td>\n",
       "      <td>Son</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01x01</td>\n",
       "      <td>No</td>\n",
       "      <td>Narrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01x01</td>\n",
       "      <td>Yeah, is this going to take a while?</td>\n",
       "      <td>Daughter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01x01</td>\n",
       "      <td>Yes.  Twenty-five years ago, before I was dad,...</td>\n",
       "      <td>Narrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01x01</td>\n",
       "      <td>It was way back in 2005. I was twenty-seven ju...</td>\n",
       "      <td>Narrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>01x01</td>\n",
       "      <td>Will you marry me.</td>\n",
       "      <td>Marshall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>01x01</td>\n",
       "      <td>Yes, perfect! And then you're engaged, you pop...</td>\n",
       "      <td>Ted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>01x01</td>\n",
       "      <td>Got it. Thanks for helping me plan this out, Ted.</td>\n",
       "      <td>Marshall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>01x01</td>\n",
       "      <td>Dude, are you kidding? It's you and Lily! I've...</td>\n",
       "      <td>Ted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>01x01</td>\n",
       "      <td>yeah, sorry. We thought you were asleep.</td>\n",
       "      <td>Marshall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>01x01</td>\n",
       "      <td>It's physics Marshall, if the bottom bunk move...</td>\n",
       "      <td>Ted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>01x01</td>\n",
       "      <td>Yeah, what are you doing tonight?</td>\n",
       "      <td>Marshall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>01x01</td>\n",
       "      <td>What was I doing? Your Uncle Marshall was taki...</td>\n",
       "      <td>Narrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>01x01</td>\n",
       "      <td>hey, so you know how I've always had a thing f...</td>\n",
       "      <td>Barney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>01x01</td>\n",
       "      <td>Hey, you wanna do something tonight?</td>\n",
       "      <td>Ted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>01x01</td>\n",
       "      <td>Okay, meet me at the bar in fifteen minutes, a...</td>\n",
       "      <td>Barney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>01x01</td>\n",
       "      <td>Hey.</td>\n",
       "      <td>Ted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>01x01</td>\n",
       "      <td>Where's your suit!? Just once when I say suit ...</td>\n",
       "      <td>Barney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>01x01</td>\n",
       "      <td>I did that one time.</td>\n",
       "      <td>Ted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode                                               line character\n",
       "0    01x01  Kids, I'm going to tell you an incredible stor...  Narrator\n",
       "1    01x01               Are we being punished for something?       Son\n",
       "2    01x01                                                 No  Narrator\n",
       "3    01x01               Yeah, is this going to take a while?  Daughter\n",
       "4    01x01  Yes.  Twenty-five years ago, before I was dad,...  Narrator\n",
       "5    01x01  It was way back in 2005. I was twenty-seven ju...  Narrator\n",
       "6    01x01                                 Will you marry me.  Marshall\n",
       "7    01x01  Yes, perfect! And then you're engaged, you pop...       Ted\n",
       "8    01x01  Got it. Thanks for helping me plan this out, Ted.  Marshall\n",
       "9    01x01  Dude, are you kidding? It's you and Lily! I've...       Ted\n",
       "10   01x01           yeah, sorry. We thought you were asleep.  Marshall\n",
       "11   01x01  It's physics Marshall, if the bottom bunk move...       Ted\n",
       "12   01x01                  Yeah, what are you doing tonight?  Marshall\n",
       "13   01x01  What was I doing? Your Uncle Marshall was taki...  Narrator\n",
       "14   01x01  hey, so you know how I've always had a thing f...    Barney\n",
       "15   01x01               Hey, you wanna do something tonight?       Ted\n",
       "16   01x01  Okay, meet me at the bar in fifteen minutes, a...    Barney\n",
       "17   01x01                                               Hey.       Ted\n",
       "18   01x01  Where's your suit!? Just once when I say suit ...    Barney\n",
       "19   01x01                               I did that one time.       Ted"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "himym_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Narrator', 'Son', 'Daughter', 'Marshall', 'Ted', 'Barney',\n",
       "       'Yasmine', 'Lily', 'Robin', 'Cabdriver', \"Robin's Dumped Friend\",\n",
       "       'Producer', 'Waitor', 'Ranjit', 'Lily, Marshall and Barney',\n",
       "       'Son and Daughter', 'Rangit', 'Marshal', 'Carl', 'Cameraman',\n",
       "       'Leroy', 'Lily and Marshall', 'Fantasy Girl', 'Tatiana',\n",
       "       'Lily and Ted', 'Crowd', 'Carlos', 'Barney and Ted',\n",
       "       'Marshall, Lily and Ted', 'Mashall, Lily and Ted', 'Guy 1',\n",
       "       'Laura', 'Fight Attendant', 'Guy 2', 'Guy 3', 'Officer McNeil',\n",
       "       'bmb Squad Guy', 'Derrick', 'Dana', 'Sascha', 'Cabdriver 2',\n",
       "       'Cute Girl', 'Stefanie', 'Marshall and Ted', 'Mr. Adams',\n",
       "       'Natalie', 'One Guest', 'All', 'Henry', 'Waiter', 'Claire',\n",
       "       'Bradley', 'Chris', 'Austin', 'Kelly', 'Bartender', 'Phil',\n",
       "       'Man on Street', 'Doorman 2', 'Woman', 'Coat Check Girl',\n",
       "       'Barney, Ted and Robin', 'Future Ted', 'Lily ', 'Barney ',\n",
       "       'Marshall, Lily, Barney', 'Lily, Marshall, Barney', 'Mike',\n",
       "       'Marshall ', 'King Costume Guy', 'Shagarats', 'Lily, Robin',\n",
       "       'Hula Girl', 'Angel Guy', 'Future Ted VO', 'Hula girl', 'Ellen',\n",
       "       'Sarah', 'Ted ', 'Sarah ', 'Sudeep', 'Lily, Marshall',\n",
       "       'Mr. Madsen', 'Waitress', 'Katie', 'Delivery guy', 'Girl  2',\n",
       "       'Kevin', 'Jackie', 'Doctor', 'Marshall, Ted', 'Everyone',\n",
       "       'Robin, Ted', 'Mr. Ericksen', 'Ericksens', 'Marcus',\n",
       "       'Mrs. Ericksen', 'Kendall', 'Pregnant Mrs. Ericksen', 'Marvin',\n",
       "       'Amanda', 'Clerk', 'Judy', 'Pete', 'Walter', 'Dancer',\n",
       "       'Daughter, Son', 'Marshall, Barney', 'Marshall, Lily', 'Guy',\n",
       "       'Trudy', \"Trudy's friend\", 'Ted from 2030', 'Mary Beth', 'Natalya',\n",
       "       'Moby', 'Not-Moby', 'Ted and Robin', 'Derek', 'Natalia', 'Claudia',\n",
       "       'Ted, Marshall', 'Stuart', 'Tanya', 'Victoria', 'Nirvana',\n",
       "       'Shannon', 'Man', 'Robin and Lily', 'Victoria and Robin',\n",
       "       'Dr. Birnholz', 'Voice', 'Man  1', 'Man  2', 'Bilson', 'Blauman',\n",
       "       \"Victoria's voice\", 'Barney, singing', 'Little Girl', 'Little Boy',\n",
       "       'Director', 'Cab driver', 'Marshall amp; Lily', 'Korean Elvis',\n",
       "       'Mary', 'Sandy', 'Vampire Lou', 'Lily, waking up', 'Todd',\n",
       "       'Scooter', 'Security guard', 'Boy', 'Singer', 'Boy  1', 'Boy  2',\n",
       "       'Andrew', 'Giant Turtle', 'Security guard  1', 'Security guard  2',\n",
       "       'Security guards', 'Paramedic', 'Tracy', 'Bob', 'Weather man',\n",
       "       'Musician', 'Voice mail', 'Penelope', 'Veterinary', 'Waiters',\n",
       "       \"Ted's daughter\", \"Ted's son\", 'Robin ', 'George Clinton',\n",
       "       'Stripper', 'Waiter Joey Adalian',\n",
       "       'DAY FIFTY-SEVEN, at the apartment.Ted from 2030',\n",
       "       \"At MacLaren's.Ted from 2030\", 'In San Francisco, in a bus.Man 1',\n",
       "       'Man 2', 'Girl', 'Amy', 'In a building.Ted from 2030',\n",
       "       'In a snack-bar.Ted from 2030', 'Twin 1', 'Twin 2', \"Ted's mother\",\n",
       "       'The previous day, at the apartment.Ted from 2030', \"Ted's father\",\n",
       "       'The waitress ',\n",
       "       \"At Casa a pezzi. Barney is playing the piano.Ted's father\",\n",
       "       \"Ted's father \", \"Ted's mother \", \"Outside.Ted's father\",\n",
       "       \"Back inside, later.Ted's mother\", 'Both Marshall and Barney',\n",
       "       'A girl', 'Girl 1', 'Girls', 'Guy 2 ', 'Girl 2', 'Kara', 'Bouncer',\n",
       "       'Girl ', 'Anna',\n",
       "       \"Anna's apartment. Anna's reading the letter Barney left.Barney's voice\",\n",
       "       'Head waiter', 'Brad', 'Mr Druthers ', 'Mr Druthers', 'Pr Lewis',\n",
       "       'Client', 'Chinese 1', 'Chinese 2', 'Woman 2', 'Judge', 'Captain',\n",
       "       'Both Marshall and Lily', 'Girl  1', 'Girl  3', 'Priest',\n",
       "       'Robin Sparkles', 'Robot', 'Marshall, lily, Robin', 'Tous',\n",
       "       'James', 'Barney and James', 'Mere', 'Tes ', 'Women',\n",
       "       'James and Barney', 'Charles', 'Rosa', 'Ted to Robin',\n",
       "       'His mother', 'Clint', 'Truck driver', 'A kid', 'Kid', 'Stacy',\n",
       "       'Charity', 'Both kids', 'Kyle', 'fact number one', 'Sylvia',\n",
       "       'Brian', 'Ted  ', 'His kids', 'The girl', 'Molly', 'Mr. Druthers',\n",
       "       'Co-worker', 'MP', 'Employees', 'Mr Druters', 'Men ',\n",
       "       'The waitress', 'Lou', 'Sid', 'Doug', 'Emmitt Smith', 'Barman',\n",
       "       'Man 1', 'Trish Sanchez', 'Rubin', 'Old lady', 'Policeman',\n",
       "       'Ex-girlfriend 1', 'Ex-girlfriend 2', 'Ex-girlfriend 3',\n",
       "       'Brother 1', 'Brother 2', 'Ted and Marshall singing', 'Mechanic',\n",
       "       'Robibn', '.Barney', 'Maechanic', 'Brother',\n",
       "       'So, I can have the moving truck here by 8',\n",
       "       'Hey, hypothetical question', 'The category', 'Tes', 'Bareney',\n",
       "       \"Barney's mom\", 'Bareny ', 'Rich', 'At the apartment, all',\n",
       "       'At the apartment, Barney', 'At the apartment, Lily',\n",
       "       'At the apartment, Ted', 'At the apartement, Lily',\n",
       "       'At the apartment, Robin', 'Millie', 'At the apartment, Marshall',\n",
       "       'Andrea', 'Bill', 'Cousin', 'Ben', 'Marshall and Lily',\n",
       "       \"Lily's grandma\", 'Janna', 'Gael', 'The Girl', 'Tyler',\n",
       "       \"Amy's friend\", 'Narrtor', 'Colleen', 'Lindsay', 'A guy ',\n",
       "       'Collee', 'Robin  2', 'Barney, Marshall', 'Rachel',\n",
       "       'Rachel, Trudy', \"Robin's date\", 'Blonde Girl', 'Brunette Girl',\n",
       "       'Trudy, Rachel', 'Trucy', \"Robins' date\", 'Little Robin', 'George',\n",
       "       'Little Barney', 'Brooke', 'Stacy, Barney', 'Blah-blah',\n",
       "       'Marshall VO', 'Lily VO', 'Marshall, Lily VO', 'College Marshall',\n",
       "       'College Lily', 'College Guy', 'College Ted', 'Audrey',\n",
       "       'College students', 'Warrior Avatar', 'Female Avatar', 'Alexa',\n",
       "       'Wendy', 'Leonard', 'Jefferson', 'Jeff', 'Meg', 'NArrator',\n",
       "       'The estate agent', 'Boys', 'Marshall, Ted, Barney', 'The girl ',\n",
       "       'Bank employee', 'Lilly', 'Robiin', 'Phone Voice', 'ted',\n",
       "       'Wendy, upset, with a black eye', 'The others', 'Together',\n",
       "       'Now, months later, the results of that exam were scheduled to post online at 10',\n",
       "       \"It's true what they say\", 'Ted amp; Robin',\n",
       "       'Marshall, on the phone with Barney',\n",
       "       'Barney, with a funny accent', 'Marhall', 'Lily and Marshall ',\n",
       "       'wendy', 'A man', 'A women', 'The host', 'Curt', 'Michael',\n",
       "       'Productor', 'Marshallamp;Lily ',\n",
       "       \"In fairness, I did call Ted's butt at, like, 2\",\n",
       "       \"So on March 17, 2008, I went to a big St. Patrick's Day party. And it's a good thing I did, because, funny story\",\n",
       "       \"Okay, it's official\", 'First skipped message', 'Next message',\n",
       "       'Stella', 'Woman 1, to Ted', 'Woman 2, to Woman 1',\n",
       "       'Woman 1, to Woman 2', 'Woman 2, to Woman 3', 'Woman 3, to Stella',\n",
       "       'Stella, to Woman 3', 'Woman 3, to Woman 2', 'Abby',\n",
       "       'Abby, laughing', 'Stella, laughing', 'Cleaner',\n",
       "       'Woman, slapping him', 'Mystery woman', 'Marshal, Lily and Ted',\n",
       "       'Kate', 'Holly', 'Mark', 'Arthur', 'Ferguson',\n",
       "       'Barney, pouring some water in a glass', 'Simon',\n",
       "       'Robin, giggling', 'Michelle', 'Punchy', 'Robin, laughing',\n",
       "       'Benjamin', 'Frank', 'Randy', 'Pitt', 'Starry', 'Willie', 'All ',\n",
       "       'Lawrence', 'Dr Greer', 'Lily amp; Marshall', \"It's 10\",\n",
       "       'I know what he saw', 'Mark Johnson', 'Marshall to lily',\n",
       "       'Marshall to Barney', 'Marshall to himself', 'Marshall to Robin',\n",
       "       'April', 'Wendy ', 'Everybody', 'Man in the street ',\n",
       "       'Marshall voiceover', 'Regis Philbin ', 'Regis Philbin',\n",
       "       'Million Dollar', 'Man in the streets', 'Regis', 'Lucy', 'Stella ',\n",
       "       'Joel', 'Biran',\n",
       "       'She leaves home and takes Stella the bike that is on the porch. It is 10',\n",
       "       '10', 'Matisse', 'Cindy', 'Stewart', 'Female', 'Sister Stella',\n",
       "       'Nora', 'Tony', 'Server', 'Purifier', 'Host', 'Father of Robin',\n",
       "       'Father',\n",
       "       'Then a woman walks with a dog and a child on his stomach, followed by several puppies Marshall',\n",
       "       'Men', 'Mr. Li', 'Driver', 'Jillian', 'Woman ', 'Sven', 'Misty',\n",
       "       'Vicky', 'Ike', 'Mitch', 'Boy 1', 'Boy 2', 'A brother', 'Woman 1',\n",
       "       'Male 2', 'Doug ', 'Children', 'Heather', 'Male', 'Man 3', 'Man ',\n",
       "       'Magazine', 'Leader', 'Seller',\n",
       "       'Marshall turns his sign which says', 'Melissa',\n",
       "       'Marshall at the office', 'Presenter', 'Rochelle', 'Radio',\n",
       "       'Referee', 'Loretta', 'Betty', 'Grant', 'Ted and Betty', '1',\n",
       "       'Karen', 'Nicole', 'Friday, 3', 'Lily, old', 'Ted, old',\n",
       "       'Marshall, old', 'Karen, old', 'Barney by nightdress',\n",
       "       'Robin, entering', 'Robin, old', 'Marshall and Barney', 'Roy',\n",
       "       'Louisa', 'Arty', 'Marshall, Lily and Barney', 'Snowshoeing',\n",
       "       'Pattern', 'McCracken',\n",
       "       'Ted  Then one day, in the suffering of the worst hangover of my life, I realized that one person in the world understood me',\n",
       "       'Roger Murtaugh', 'Robin and Barney', 'Kenny',\n",
       "       'Robin, out of the room', 'Toy-Man',\n",
       "       'Massage man, massaging the shoulders of Marshall', 'Douglas',\n",
       "       'Douglas, Barney', 'PJ', 'Ted, by phone at PJ interposed',\n",
       "       'Grub-man', 'Toy-man', 'Chow-Man', 'Stan', 'Clown',\n",
       "       'Barney, entering', 'Matthew', 'Woman 3', 'Pauline', 'Fran',\n",
       "       'Milt', 'Ted, crying', 'Ted, with a lookalike Stella',\n",
       "       'Lookalike Stella', 'Police', 'Woman, leaving her', 'Ms. Matsen',\n",
       "       'Stella, shouting', 'Tracey', 'Barney and Robin', 'Blond Girl',\n",
       "       'A boy', 'Another boy', 'Another girl', 'Blond girl', 'Student',\n",
       "       'Other professor', 'Professor', 'Jen', 'Delivery girl', 'Marsahll',\n",
       "       'Ted and Jen', 'All the other', 'The other', 'Marhsall',\n",
       "       'Ted imagines', 'Girl 3', 'Shin-Ya', 'fighting', 'All singing',\n",
       "       'Ted, joining them', 'Marshall, in bar with Lily',\n",
       "       'Marshall, entering with a hat with drink', 'Lily, fighting Ted',\n",
       "       'Marshall and Ted, singing', 'Lily, on the roof of the car',\n",
       "       'Ted and Marshall', 'Alan',\n",
       "       'Barney, seeing himself in the window of the restaurant',\n",
       "       'Alan Thicke', 'Meg-the-crazy', 'Meg-the-insane', 'Ms. Stinsfire',\n",
       "       'Shelly', 'Ted, with chicken fingers in the mouth',\n",
       "       'All, making the chorus', 'Robin and Ted', 'Lily Young', 'Mickey',\n",
       "       'Rita', 'Grandfather', 'Neighbor', 'Whitney', 'Grocer', 'Mother',\n",
       "       'Marshall, in video on the computer',\n",
       "       'Mickey, sitting on the floor', 'Marshall, tapping on a glass',\n",
       "       'Voices', 'Older woman', 'Elderly Woman', 'Maggie', 'Lily, a man',\n",
       "       'Student 2', 'Luis', 'Jamie', 'Jim', 'Ted, always current',\n",
       "       'Robin, Jim', 'Ted, in front of Maggie', 'Adam',\n",
       "       'Waitress at the old Marshall', 'Old Marshall', 'Children of Ted',\n",
       "       'Don', 'Chief', 'Ted and Barney', 'Lily, with a deep voice',\n",
       "       'Don, who arrive without pants', 'Young Marshall',\n",
       "       'Marshall Young', 'Barmaid', 'Barney conscience',\n",
       "       'Barney, running down the street', 'Tim',\n",
       "       'Barney, singing and dancing in the street',\n",
       "       'Marshall, doing the same', 'Ted, Marshall, Lily',\n",
       "       'Barney, joining them', 'Jenkins', 'Scotty',\n",
       "       'All, the student bar', 'Ted, from seeing Barney', 'Overall',\n",
       "       'Nick', 'Mr Donovan', 'TV anchor', 'Red-sweater girl',\n",
       "       'All of them', 'All the them', 'Hot Chick', 'Tiffany', 'Lisa',\n",
       "       'Henrietta', 'Mother of Henrietta', 'Jack',\n",
       "       'Marshall, with the phone in the kitchen', 'Anita', 'Ted singing',\n",
       "       'Ted, still singing', 'Anita, Ted', 'The alarm goes off at 12',\n",
       "       'The clock shows 9', 'Marshall Robin. Your part is this',\n",
       "       'Raspberry', 'Mayor', 'Robin, out of his room', 'Delivery Man',\n",
       "       'Robin, who happens', 'Lily, what happens', 'Clint, singing',\n",
       "       'Man going', 'Virginia', 'Ted, leaving her room', 'Ted, an apron',\n",
       "       'Lily, thinking', 'Marshall, thinking', 'Robin, at the window',\n",
       "       'Robin, on the phone', 'Marissa', 'Lily, holding Barney',\n",
       "       'Marshall, laughing', 'Will Shortz', 'Will', 'Ted wrestler',\n",
       "       'Royce', 'Jed Mosley', 'Jed', 'Man and woman', 'Ted stood up',\n",
       "       'Child', 'Robin, on TV', 'Robin, thinking', 'Ted, thinking',\n",
       "       'Barney lookalike', 'Barney, thinking', 'Sosie', 'Sosia',\n",
       "       'Lookalike', \"Ted's wife\", 'Ted amp; Barney',\n",
       "       'The Girl who was reading', \"Marshall's dad\", 'The man',\n",
       "       'Lauretta', 'Sam Gibbs', 'Sam', 'Basketball coatch', 'TV Speaker',\n",
       "       'Chrissy', 'Marsall', 'Folk singer', 'Speaker', 'Medic', 'Becky',\n",
       "       'Maury Povich', 'Man, in a calculator display', 'Max',\n",
       "       'trnsvstite', \"Barney's Secretary\", 'Zoey', 'Rob',\n",
       "       'Marshall and his friends, singing', 'Announcer',\n",
       "       \"Marshall's daughter\", 'ANNOUNCER', 'Student  1', 'Student  2',\n",
       "       'GNB announcer', 'Randy, thinking', 'Randy, wailing',\n",
       "       'Arthur, entering the room', 'Russel', 'Ted, whispering',\n",
       "       'Museum guard', \"Ted's voice \", 'Guard', 'Jessica Glitter',\n",
       "       'Jessica, singing', 'Robin and Jessica', 'Jessica', 'Blitz',\n",
       "       'Bar Tender', 'Mysterious voice', 'Everyone, chanting', 'Steve',\n",
       "       'Babaka', 'Barney, laughing', 'Barney, crying', 'Liy',\n",
       "       'Robin, slurring', 'Sailor  1', 'Sailor  2', 'Animator', 'Jordan',\n",
       "       'Jordin', 'Ted, yelling', 'Barney, singsongy', 'Robin, stuttering',\n",
       "       'Stangel', 'Strangel', 'Man  3', 'Man  4', 'Robin, hushing',\n",
       "       'Reverend', 'Trey', 'Barney amp; Ted', \"Marshall's brother  1\",\n",
       "       \"Marshall's brother  2\", 'Nathan Hale', \"Ted's dad\", \"Lily's dad\",\n",
       "       \"Robin's dad\", 'Barney, his voice breaking', \"Marvin's voice\",\n",
       "       'Barney, coughing', 'Honey', 'Robin, with a Minnesotan accent',\n",
       "       'Honey, whispering', 'Barney, whispering', 'Ted, laughing',\n",
       "       'Honey, giggling', 'Barney, sobbing', 'Neighbour',\n",
       "       'ARNOLD SCHWARZENEGGER', 'Saint Desperatius', 'Saint Valentine',\n",
       "       'Marshall, whispers', 'Bev', 'Ted amp; Marshall', 'MARVIN',\n",
       "       'SCHWARZENEGGER ', 'Tv', 'Meeker', 'Nate', 'The cardiologist',\n",
       "       'Ted, on the phone with Robin', 'Jerry', 'Scott', 'Jerry ', 'Both',\n",
       "       'Cherryl', 'JJ', 'Prof. Rodriguez', 'Barney, weakly',\n",
       "       'Barney, with a mean laugh', 'Jerry, laughing', 'ROBIN',\n",
       "       'Ted, whispering to Robin', 'Jerry, looking horrified',\n",
       "       'Ted, loudly', 'Jerry, to a big tattoed biker',\n",
       "       'Jerry, to a dummy wearing a biker outfit', 'Ted, chuckling',\n",
       "       'Man, on the phone', 'Head of the environmental Organization',\n",
       "       'Assistant', 'Delivery Guy', 'Robin, in a high-pitched voice',\n",
       "       'Marshall, to the girl Barney is talking to',\n",
       "       'Marshall, talking to a mirror', 'Robin amp; Lily', 'Chairman',\n",
       "       'Audience', 'Ghost', 'Ghost, shouting dramatically',\n",
       "       'Ted, panting', 'Ted, on recorder',\n",
       "       'Both Ted and Barney, at the same time', 'Foreman', 'Rod',\n",
       "       'Ted, while texting on his phone',\n",
       "       'Marshall, picking up his phone', 'announcer', \"Ted's voice\",\n",
       "       'voice', 'Jake', \"Ted, leaving the florist's shop\", 'Norah',\n",
       "       'Marshall, lifting the shirt of Lily', 'Kelly and Punchy', 'Clay',\n",
       "       'Ted, Barney and Robin', \"Kelly's father\", \"Punchy's father\",\n",
       "       'Garrison', 'Barney, turning', 'Lily, slapping him',\n",
       "       'Lily and Robin', \"Marshall's voice\"], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "himym_df['character'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: May consider feeding one sentence and one Barney reply or multiple sentences encoded with one Barney reply\n",
    "def get_barney(himym_df, level=2):\n",
    "    dataframe_rows = []\n",
    "    idxs_barney = himym_df[himym_df['character'] == 'Barney'].index\n",
    "    dataframe_rows = []\n",
    "    for i in idxs_barney:\n",
    "        l = []\n",
    "        l.append(himym_df['line'][i])\n",
    "        for j in range(0,level):\n",
    "            l.append(himym_df['line'][i-j-1])\n",
    "        dataframe_rows.append(l)\n",
    "    df = pd.DataFrame(dataframe_rows, columns=['response', 'context', 'context/0'])\n",
    "    return df\n",
    "\n",
    "barney_df = get_barney(himym_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>context</th>\n",
       "      <th>context/0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hey, so you know how I've always had a thing f...</td>\n",
       "      <td>What was I doing? Your Uncle Marshall was taki...</td>\n",
       "      <td>Yeah, what are you doing tonight?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Okay, meet me at the bar in fifteen minutes, a...</td>\n",
       "      <td>Hey, you wanna do something tonight?</td>\n",
       "      <td>hey, so you know how I've always had a thing f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Where's your suit!? Just once when I say suit ...</td>\n",
       "      <td>Hey.</td>\n",
       "      <td>Okay, meet me at the bar in fifteen minutes, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It was a blazer!</td>\n",
       "      <td>I did that one time.</td>\n",
       "      <td>Where's your suit!? Just once when I say suit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I see what this is about. Have you forgotten w...</td>\n",
       "      <td>You know, ever since college it's been Marshal...</td>\n",
       "      <td>It was a blazer!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            response  \\\n",
       "0  hey, so you know how I've always had a thing f...   \n",
       "1  Okay, meet me at the bar in fifteen minutes, a...   \n",
       "2  Where's your suit!? Just once when I say suit ...   \n",
       "3                                   It was a blazer!   \n",
       "4  I see what this is about. Have you forgotten w...   \n",
       "\n",
       "                                             context  \\\n",
       "0  What was I doing? Your Uncle Marshall was taki...   \n",
       "1               Hey, you wanna do something tonight?   \n",
       "2                                               Hey.   \n",
       "3                               I did that one time.   \n",
       "4  You know, ever since college it's been Marshal...   \n",
       "\n",
       "                                           context/0  \n",
       "0                  Yeah, what are you doing tonight?  \n",
       "1  hey, so you know how I've always had a thing f...  \n",
       "2  Okay, meet me at the bar in fifteen minutes, a...  \n",
       "3  Where's your suit!? Just once when I say suit ...  \n",
       "4                                   It was a blazer!  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "barney_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "barney_path = os.path.join(os.getcwd(), \"Datasets\", \"Characters\", \"Barney\")\n",
    "if not os.path.exists(barney_path):\n",
    "    os.makedirs(barney_path)\n",
    "barney_df.to_csv(os.path.join(barney_path, \"Barney.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-86f70c1791bbdd2c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:\\Users\\tonel\\.cache\\huggingface\\datasets\\csv\\default-86f70c1791bbdd2c\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84494ae9f34b4caaba8ad7b2977f054e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ec5fe0a95640b2a3aa586ed1b7831e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:\\Users\\tonel\\.cache\\huggingface\\datasets\\csv\\default-86f70c1791bbdd2c\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be504f5e2dd745b9bae9ab8186853416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "barney_hg = load_dataset('csv', data_files=os.path.join(barney_path, \"Barney.csv\"))\n",
    "barney_hg = barney_hg[\"train\"].train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at microsoft/DialoGPT-medium.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
    "model = TFAutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> User:Hello\n",
      "DialoGPT: Hello! :D\n",
      ">> User:How are you?\n",
      "DialoGPT: I'm good, how are you?\n",
      ">> User:I'm fine\n",
      "DialoGPT: That's good!\n"
     ]
    }
   ],
   "source": [
    "# Let's chat for 3 lines\n",
    "for step in range(3):\n",
    "    # encode the new user input, add the eos_token and return a tensor\n",
    "    new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='tf')\n",
    "    # append the new user input tokens to the chat history\n",
    "    bot_input_ids = tf.concat([chat_history_ids, new_user_input_ids], axis=-1) if step > 0 else new_user_input_ids\n",
    "    # generated a response while limiting the total chat history to 1000 tokens, \n",
    "    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
    "    # pretty print last ouput tokens from bot\n",
    "    print(\"DialoGPT: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['response', 'context', 'context/0'],\n",
      "        num_rows: 4465\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['response', 'context', 'context/0'],\n",
      "        num_rows: 497\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(barney_hg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b59d5a4844204b8dba6ae867abaec61b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7611534d3f9c4a0eb5db643e90e9460d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def construct_conv(row, tokenizer):\n",
    "    row = list(reversed(list(row.values())))\n",
    "    model_inputs = tokenizer(row, padding=\"max_length\", max_length=64, truncation=True)\n",
    "    for i in range(len(model_inputs['input_ids'])):\n",
    "        model_inputs['input_ids'][i].append(tokenizer.eos_token_id)\n",
    "    for i in range(1, len(model_inputs['input_ids'])):\n",
    "        model_inputs['input_ids'][0].extend(model_inputs['input_ids'][i])\n",
    "        model_inputs['attention_mask'][0].extend(model_inputs['attention_mask'][i])\n",
    "    model_inputs['input_ids'] = [item for sublist in model_inputs['input_ids'] for item in sublist]\n",
    "    model_inputs['attention_mask'] = [item for sublist in model_inputs['attention_mask'] for item in sublist]\n",
    "    return model_inputs\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model_inputs = construct_conv(examples, tokenizer)\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_barney_hg = barney_hg.map(preprocess_function, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['response', 'context', 'context/0', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 4465\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['response', 'context', 'context/0', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 497\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, return_tensors='tf')\n",
    "\n",
    "print(tokenized_barney_hg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf_train_set = tokenized_barney_hg[\"train\"].to_tf_dataset(\n",
    "    columns=[\"input_ids\", \"attention_mask\"],\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "tf_test_set = tokenized_barney_hg[\"test\"].to_tf_dataset(\n",
    "    columns=[\"input_ids\", \"attention_mask\"],\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! Please ensure your labels are passed as keys in the input dict so that they are accessible to the model during the forward pass. To disable this behaviour, please pass a loss argument, or explicitly pass loss=None if you do not want your model to compute a loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfgpt2lm_head_model_1/transformer/h_._0/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._0/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._0/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._0/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._0/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._0/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._0/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._0/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._1/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._1/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._1/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._1/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._1/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._1/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._1/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._1/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._1/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._1/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._1/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._1/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._2/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._2/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._2/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._2/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._2/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._2/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._2/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._2/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._2/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._2/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._2/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._2/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._3/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._3/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._3/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._3/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._3/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._3/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._3/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._3/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._3/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._3/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._3/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._3/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._4/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._4/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._4/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._4/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._4/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._4/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._4/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._4/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._4/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._4/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._4/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._4/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._5/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._5/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._5/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._5/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._5/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._5/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._5/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._5/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._5/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._5/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._5/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._5/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._6/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._6/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._6/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._6/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._6/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._6/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._6/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._6/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._6/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._6/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._6/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._6/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._7/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._7/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._7/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._7/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._7/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._7/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._7/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._7/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._7/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._7/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._7/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._7/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._8/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._8/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._8/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._8/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._8/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._8/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._8/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._8/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._8/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._8/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._8/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._8/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._9/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._9/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._9/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._9/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._9/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._9/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._9/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._9/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._9/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._9/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._9/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._9/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._10/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._10/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._10/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._10/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._10/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._10/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._10/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._10/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._10/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._10/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._10/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._10/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._11/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._11/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._11/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._11/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._11/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._11/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._11/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._11/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._11/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._11/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._11/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._11/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._12/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._12/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._12/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._12/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._12/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._12/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._12/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._12/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._12/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._12/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._12/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._12/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._13/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._13/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._13/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._13/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._13/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._13/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._13/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._13/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._13/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._13/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._13/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._13/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._14/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._14/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._14/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._14/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._14/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._14/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._14/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._14/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._14/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._14/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._14/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._14/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._15/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._15/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._15/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._15/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._15/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._15/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._15/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._15/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._15/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._15/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._15/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._15/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._16/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._16/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._16/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._16/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._16/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._16/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._16/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._16/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._16/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._16/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._16/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._16/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._17/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._17/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._17/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._17/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._17/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._17/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._17/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._17/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._17/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._17/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._17/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._17/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._18/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._18/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._18/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._18/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._18/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._18/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._18/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._18/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._18/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._18/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._18/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._18/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._19/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._19/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._19/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._19/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._19/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._19/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._19/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._19/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._19/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._19/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._19/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._19/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._20/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._20/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._20/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._20/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._20/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._20/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._20/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._20/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._20/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._20/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._20/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._20/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._21/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._21/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._21/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._21/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._21/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._21/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._21/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._21/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._21/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._21/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._21/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._21/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._22/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._22/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._22/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._22/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._22/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._22/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._22/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._22/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._22/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._22/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._22/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._22/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._23/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._23/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._23/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._23/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._23/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._23/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._23/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._23/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._23/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._23/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._23/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._23/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/ln_f/gamma:0', 'tfgpt2lm_head_model_1/transformer/ln_f/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tfgpt2lm_head_model_1/transformer/h_._0/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._0/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._0/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._0/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._0/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._0/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._0/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._0/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._1/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._1/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._1/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._1/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._1/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._1/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._1/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._1/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._1/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._1/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._1/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._1/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._2/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._2/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._2/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._2/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._2/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._2/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._2/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._2/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._2/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._2/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._2/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._2/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._3/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._3/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._3/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._3/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._3/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._3/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._3/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._3/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._3/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._3/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._3/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._3/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._4/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._4/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._4/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._4/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._4/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._4/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._4/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._4/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._4/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._4/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._4/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._4/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._5/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._5/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._5/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._5/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._5/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._5/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._5/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._5/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._5/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._5/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._5/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._5/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._6/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._6/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._6/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._6/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._6/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._6/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._6/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._6/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._6/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._6/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._6/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._6/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._7/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._7/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._7/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._7/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._7/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._7/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._7/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._7/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._7/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._7/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._7/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._7/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._8/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._8/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._8/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._8/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._8/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._8/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._8/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._8/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._8/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._8/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._8/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._8/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._9/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._9/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._9/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._9/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._9/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._9/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._9/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._9/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._9/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._9/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._9/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._9/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._10/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._10/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._10/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._10/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._10/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._10/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._10/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._10/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._10/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._10/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._10/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._10/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._11/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._11/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._11/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._11/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._11/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._11/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._11/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._11/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._11/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._11/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._11/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._11/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._12/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._12/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._12/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._12/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._12/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._12/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._12/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._12/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._12/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._12/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._12/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._12/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._13/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._13/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._13/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._13/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._13/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._13/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._13/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._13/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._13/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._13/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._13/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._13/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._14/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._14/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._14/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._14/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._14/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._14/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._14/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._14/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._14/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._14/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._14/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._14/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._15/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._15/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._15/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._15/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._15/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._15/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._15/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._15/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._15/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._15/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._15/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._15/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._16/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._16/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._16/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._16/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._16/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._16/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._16/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._16/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._16/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._16/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._16/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._16/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._17/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._17/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._17/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._17/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._17/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._17/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._17/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._17/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._17/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._17/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._17/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._17/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._18/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._18/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._18/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._18/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._18/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._18/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._18/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._18/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._18/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._18/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._18/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._18/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._19/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._19/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._19/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._19/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._19/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._19/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._19/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._19/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._19/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._19/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._19/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._19/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._20/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._20/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._20/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._20/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._20/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._20/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._20/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._20/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._20/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._20/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._20/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._20/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._21/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._21/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._21/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._21/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._21/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._21/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._21/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._21/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._21/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._21/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._21/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._21/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._22/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._22/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._22/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._22/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._22/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._22/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._22/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._22/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._22/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._22/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._22/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._22/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._23/ln_1/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._23/ln_1/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._23/attn/c_attn/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._23/attn/c_attn/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._23/attn/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._23/attn/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._23/ln_2/gamma:0', 'tfgpt2lm_head_model_1/transformer/h_._23/ln_2/beta:0', 'tfgpt2lm_head_model_1/transformer/h_._23/mlp/c_fc/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._23/mlp/c_fc/bias:0', 'tfgpt2lm_head_model_1/transformer/h_._23/mlp/c_proj/weight:0', 'tfgpt2lm_head_model_1/transformer/h_._23/mlp/c_proj/bias:0', 'tfgpt2lm_head_model_1/transformer/ln_f/gamma:0', 'tfgpt2lm_head_model_1/transformer/ln_f/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 17/279 [>.............................] - ETA: 10:44 - loss: -0.0114 - past_key_values_1_loss: -0.0114"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-a63daccf8e6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2e-5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf_train_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf_test_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5))\n",
    "model.fit(x=tf_train_set, validation_data=tf_test_set, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

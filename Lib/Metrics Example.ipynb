{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Lib.BBMetrics import BBMetric\n",
    "from transformers import TFAutoModelForCausalLM, AutoTokenizer\n",
    "import os\n",
    "from Data.data_dicts import character_dict, source_dict, random_state\n",
    "\n",
    "import os\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive',force_remount=True)\n",
    "    base_folder = '/content/drive/My Drive/unibo/NLP_project/BarneyBot'\n",
    "    os.system(\"pip install datasets\")\n",
    "    os.system(\"pip install transformers\")\n",
    "    os.system(\"pip install rouge_score\")\n",
    "    os.system(\"pip install -U sentence-transformers\")\n",
    "else:\n",
    "    base_folder = os.getcwd()\n",
    "\n",
    "sentences_basic = [\"Hi!\", \"How are you?\", \"I hate you.\"]\n",
    "sentences_basic_2 = [\"Hello!\", \"How are you doing?\", \"I think this is good.\"]\n",
    "sentences_vader = [\"Come to the dark side!\", \"I will kill you!\", \"Luke, I am your father.\"]\n",
    "sentences_barney = [\"Did you get the suit?\", \"Legendary!\", \"I like girls.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at microsoft/DialoGPT-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForCausalLM.from_pretrained('microsoft/DialoGPT-small', cache_dir=os.path.join(os.getcwd(), \"cache\"))\n",
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/DialoGPT-small', cache_dir=os.path.join(os.getcwd(), \"cache\"))\n",
    "tokenizer.pad_token = '#'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bleu',\n",
       " 'semantic similarity',\n",
       " 'rouge l',\n",
       " 'emotion',\n",
       " 'semantic answer similarity',\n",
       " 'distinct',\n",
       " 'semantic classifier',\n",
       " 'perplexity',\n",
       " 'human - coherence',\n",
       " 'human - consistency',\n",
       " 'human - style']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BBMetric.metrics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.0, 'std': 0.0}\n"
     ]
    }
   ],
   "source": [
    "metric = BBMetric.load_metric(\"bleu\")\n",
    "\n",
    "print(metric.compute(predictions=sentences_basic, references=sentences_basic_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.36904761904761907, 'std': 0.3599099156626422}\n"
     ]
    }
   ],
   "source": [
    "metric = BBMetric.load_metric(\"rouge l\")\n",
    "\n",
    "print(metric.compute(predictions=sentences_basic, references=sentences_basic_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.11616161616161617, 'std': 0.0823712445974752}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = BBMetric.load_metric(\"distinct\")\n",
    "\n",
    "# ngram_size is optional, defaults to 3\n",
    "metric.compute(sentences=sentences_basic, ngram_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': [0.04045128605018059, 0.3372649804999431, 0.029534351934368413, 0.33119267721970874, 0.24915542546659708, 0.012401290975200633], 'std': [0.0246632631447857, 0.3520860938584187, 0.03524459240387796, 0.360727083374811, 0.31209396368681236, 0.008284051185361898], 'label': ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']}\n"
     ]
    }
   ],
   "source": [
    "metric = BBMetric.load_metric(\"emotion\")\n",
    "\n",
    "print(metric.compute(sentences=sentences_basic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.60903007, 'std': 0.40267226}\n"
     ]
    }
   ],
   "source": [
    "metric = BBMetric.load_metric(\"semantic similarity\")\n",
    "\n",
    "print(metric.compute(sentences_a=sentences_basic, sentences_b=sentences_basic_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.59648186, 'std': 0.4743335}\n"
     ]
    }
   ],
   "source": [
    "metric = BBMetric.load_metric(\"semantic answer similarity\")\n",
    "\n",
    "print(metric.compute(predictions=sentences_basic, references=sentences_basic_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using classifier at D:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBot\\BarneyBot\\Data\\Characters\\Barney\\barney_classifier\n",
      "{'score': 0.9999995, 'std': 0.0}\n"
     ]
    }
   ],
   "source": [
    "metric = BBMetric.load_metric(\"semantic classifier\")\n",
    "\n",
    "# n_shuffles is optional, defaults to 10\n",
    "# from_saved_embeddings is optional, defaults to True\n",
    "# shutdown_at_end is optional, defaults to False\n",
    "metric.train(character='Barney', character_dict=character_dict, source_dict=source_dict, random_state=random_state,\n",
    "             base_folder=base_folder, n_shuffles=10, from_saved_embeddings=True, shutdown_at_end=False)\n",
    "\n",
    "# n_draws is optional, defaults to len(sentences)-2\n",
    "print(metric.compute(character='Barney', character_dict=character_dict, base_folder=base_folder,\n",
    "               sentences=sentences_basic))\n",
    "print(metric.compute(character='Barney', character_dict=character_dict, base_folder=base_folder,\n",
    "               sentences=sentences_vader))\n",
    "print(metric.compute(character='Barney', character_dict=character_dict, base_folder=base_folder,\n",
    "               sentences=sentences_barney))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score_concat': 40623438.20342068}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metric = BBMetric.load_metric(\"perplexity\")\n",
    "\n",
    "# stride is optional, defaults to 64\n",
    "print(metric.compute(model=model, tokenizer=tokenizer, sentences=sentences_basic, stride=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = BBMetric.load_metric(\"human - coherence\")\n",
    "\n",
    "# length is optional, defaults to 5\n",
    "metric.train(model=model, tokenizer=tokenizer,\n",
    "             filepath=os.path.join(os.getcwd(), \"Datasets\", \"Characters\", \"Default\", \"humancoherence.csv\"),\n",
    "             length=2)\n",
    "\n",
    "metric.compute(filepath=os.path.join(os.getcwd(), \"Datasets\", \"Characters\", \"Default\", \"humancoherence.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = BBMetric.load_metric(\"human - consistency\")\n",
    "\n",
    "metric.train(model=model, tokenizer=tokenizer,\n",
    "             filepath=os.path.join(os.getcwd(), \"Datasets\", \"Characters\", \"Default\", \"humanconsistency.csv\"))\n",
    "\n",
    "metric.compute(filepath=os.path.join(os.getcwd(), \"Datasets\", \"Characters\", \"Default\", \"humanconsistency.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metric = BBMetric.load_metric(\"human - style\")\n",
    "\n",
    "metric.train(model=model, tokenizer=tokenizer,\n",
    "             filepath=os.path.join(os.getcwd(), \"Datasets\", \"Characters\", \"Default\", \"humanstyle.csv\"),\n",
    "             questions=barney_sentences)\n",
    "\n",
    "metric.compute(filepath=os.path.join(os.getcwd(), \"Datasets\", \"Characters\", \"Default\", \"humanstyle.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

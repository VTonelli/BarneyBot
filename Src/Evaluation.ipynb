{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dde1bf5a",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46f38c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True\n",
    "use_cuda = False\n",
    "\n",
    "do_metric_training = False\n",
    "do_predictions = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aaa0c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip install -r \"E:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\\requirements.txt\"\n"
     ]
    }
   ],
   "source": [
    "### Run environment setup\n",
    "import os\n",
    "import lib.BBSetup as BBSetup\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    BBSetup.colab_setup(mount_folder=r\"/content/drive/My Drive/unibo/NLP_project/BarneyBot\")\n",
    "except:\n",
    "    try:\n",
    "        BBSetup.anaconda_manual_setup(base_folder=r\"E:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\",\n",
    "                                      env_name=\"barneybot\")\n",
    "    except:\n",
    "        BBSetup.anaconda_auto_setup(base_folder=r\"E:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\")\n",
    "\n",
    "### Define folders\n",
    "base_folder = BBSetup.BASE_FOLDER\n",
    "in_folder = BBSetup.set_folder(os.path.join(base_folder, 'Data', 'Characters'))\n",
    "out_folder = BBSetup.set_folder(os.path.join(base_folder, 'Metrics', 'New'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64468996",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "E:\\Programs\\Anaconda\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tonel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "### load_char_df() (hg dataset) ['test'] to get testset, containing contexts and response\n",
    "### get_chatbot_predictions() to get a type of predictions for a model\n",
    "from lib.BBDataLoad import load_char_df, get_chatbot_predictions, dialogpt_preprocess_function\n",
    "from datasets import load_dataset\n",
    "from transformers import TFAutoModelForCausalLM\n",
    "from lib.BBMetrics import BBMetric\n",
    "from lib.BBMetricResults import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lib.BBData import character_dict, model_name, random_state\n",
    "characters = list(character_dict.keys())\n",
    "characters.remove('Default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96c27ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import structures from HuggingFace\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
    "                                          cache_dir=os.path.join(base_folder, \"cache\"))\n",
    "tokenizer.pad_token = '#'\n",
    "data_collator = DataCollatorForLanguageModeling(mlm=False, tokenizer=tokenizer, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57b98f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(S):\n",
    "    if S == []:\n",
    "        return S\n",
    "    if isinstance(S[0], list):\n",
    "        return flatten(S[0]) + flatten(S[1:])\n",
    "    return S[:1] + flatten(S[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55849736",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_predictions:\n",
    "    print(\"Saving predictions to file\")\n",
    "    with tqdm(total=len(characters)*4) as pbar:\n",
    "        # Chatbot of a character on their own dataset\n",
    "        for char in characters:\n",
    "            checkpoint_folder = os.path.join(in_folder, char,\n",
    "                                             character_dict[char]['checkpoint_folder'])\n",
    "            model = TFAutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=checkpoint_folder)\n",
    "            model.compile()\n",
    "            samples = load_char_df(char)\n",
    "            for gen_type in ['greedy', 'nbeams', 'sampling']:\n",
    "                get_chatbot_predictions(samples['test']['context/0'], model,\n",
    "                              character_dict[char]['prediction_filename'] + '_' + gen_type + '.json',\n",
    "                              gen_type, char, cache.tokenizer, base_folder, override_predictions=True)\n",
    "                pbar.update(1)\n",
    "        # Base chatbot on each character's dataset\n",
    "        for char in characters:\n",
    "            model = TFAutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                                           cache_dir=os.path.join(base_folder, \"cache\"))\n",
    "            model.compile()\n",
    "            samples = load_char_df(char)\n",
    "            get_chatbot_predictions(samples['test']['context/0'], model,\n",
    "                              'from_' + char + \"_df__sampling.json\", gen_type,\n",
    "                              \"Default\", cache.tokenizer, base_folder, override_predictions=True)\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17d247a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Metrics training.\n"
     ]
    }
   ],
   "source": [
    "if do_metric_training:\n",
    "    print(\"Training metrics\")\n",
    "    # Neural Chatbot Classifier\n",
    "    with tqdm(total=len(characters) + 2) as pbar:\n",
    "        for char in tqdm(characters):\n",
    "            neural_classifier = BBMetric.load_metric(\"neural chatbot classifier\")\n",
    "            neural_classifier.train(character=char, random_state=random_state,\n",
    "                     source_encoded_path=None,\n",
    "                     source_path=os.path.join(base_folder, \"Data\", \"Sources\",\n",
    "                                              character_dict[char]['source'],\n",
    "                                              character_dict[char]['source'] + \".csv\"),\n",
    "                     source_save_path=os.path.join(base_folder, \"Data\", \"Characters\", char),\n",
    "                     save_path=os.path.join(base_folder, \"Data\", \"Characters\", char))\n",
    "            pbar.update(1)\n",
    "        # Distilbert-Embedded Chatbot Classifier\n",
    "        bertembedded_classifier = BBMetric.load_metric(\"distilbert-embedded chatbot classifier\")\n",
    "        bertembedded_classifier.train(characters_path=os.path.join(base_folder, \"Data\", \"Characters\"),\n",
    "                                      save_path=os.path.join(base_folder, \"Data\", \"Metrics\", \n",
    "                                                             \"distilbert_embedder\"),\n",
    "                                      train_embedder=True,\n",
    "                                      verbose=True)\n",
    "        pbar.update(1)\n",
    "        characters_no_barney = characters.copy()\n",
    "        characters_no_barney.remove(\"Barney\")\n",
    "        bertembedded_classifier = BBMetric.load_metric(\"distilbert-embedded chatbot classifier\")\n",
    "        bertembedded_classifier.metric.set_characters(characters_no_barney)\n",
    "        bertembedded_classifier.train(characters_path=os.path.join(base_folder, \"Data\", \"Characters\"),\n",
    "                                      save_path=os.path.join(base_folder, \"Data\", \"Metrics\", \n",
    "                                                             \"distilbert_embedder_nobarney\"),\n",
    "                                      train_embedder=True,\n",
    "                                      verbose=True)\n",
    "        pbar.update(1)\n",
    "else:\n",
    "    print(\"Skipping Metrics training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea2ce54",
   "metadata": {},
   "source": [
    "# Cache System Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8285eb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a cache structure to avoid reloading stuff\n",
    "from types import SimpleNamespace\n",
    "\n",
    "cache = {\n",
    "    'dialogpt': {char: None for char in characters + [\"Base\"]},\n",
    "    'tokenizer': None,\n",
    "    'datacollator': None,\n",
    "    'trained_metric': {\n",
    "        'neural chatbot classifier': {char: None for char in characters},\n",
    "        'frequency chatbot classifier': None,\n",
    "        'distilbert-embedded chatbot classifier': {'Full': None, 'No Barney': None}\n",
    "    },\n",
    "    'testset': {char + \"_df\": None for char in characters + [\"Common\"]},\n",
    "    'concat_and_encoded_testset': {char + \"_df\": None for char in characters + [\"Common\"]},\n",
    "    'predictions': {\n",
    "        char + \"_df\": { # Dataset\n",
    "            char: { # Chatbot\n",
    "                'greedy': None,\n",
    "                'nbeams': None,\n",
    "                'sampling': None\n",
    "            } for char in characters + [\"Base\"]\n",
    "        } for char in characters + [\"Common\"]\n",
    "    },\n",
    "}\n",
    "cache = SimpleNamespace(**cache)\n",
    "\n",
    "def load_cache_entry(value, entry):\n",
    "    pointer = cache\n",
    "    for i in range(len(entry)-1):\n",
    "        val = entry[i]\n",
    "        if isinstance(pointer, dict):\n",
    "            pointer = pointer[val]\n",
    "        elif isinstance(pointer, SimpleNamespace):\n",
    "            pointer = pointer.__dict__[val]\n",
    "        else:\n",
    "            raise Exception()\n",
    "    if not pointer[entry[-1]]:\n",
    "        pointer[entry[-1]] = value\n",
    "        if verbose:\n",
    "            print(\"Loaded cache at \" + str(entry))\n",
    "    return pointer[entry[-1]]\n",
    "\n",
    "def flush_cache_entries(entries):\n",
    "    for entry in entries:\n",
    "        pointer = cache\n",
    "        for i in range(len(entry)-1):\n",
    "            val = entry[i]\n",
    "            if isinstance(pointer, dict):\n",
    "                pointer = pointer[val]\n",
    "            elif isinstance(pointer, SimpleNamespace):\n",
    "                pointer = pointer.__dict__[val]\n",
    "            else:\n",
    "                raise Exception()\n",
    "        pointer[entry[-1]] = None\n",
    "        if verbose:\n",
    "            print(\"Flushed cache at \" + str(entry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96df347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cache_testset(character, base_folder):\n",
    "    if not cache.testset[character + \"_df\"]:\n",
    "        if character != \"Common\":\n",
    "            df = load_char_df(character, base_folder)['test']\n",
    "        else: \n",
    "            df = load_dataset('csv',\n",
    "                     data_files=os.path.join(base_folder, 'Data', 'common_dataset.csv'), \n",
    "                     cache_dir=os.path.join(base_folder, \"cache\"))['train']\n",
    "        load_cache_entry(df, ['testset', character + \"_df\"])\n",
    "    return cache.testset[character + \"_df\"]\n",
    "\n",
    "# For perplexity\n",
    "def get_cache_concat_and_encoded_testset(character, base_folder):\n",
    "    if not cache.concat_and_encoded_testset[character + \"_df\"]:\n",
    "        testset = get_cache_testset(character, base_folder)\n",
    "        concat_encoded_testset = testset.map(lambda row: dialogpt_preprocess_function(row,\n",
    "                                                                            cache.tokenizer),\n",
    "                                             batched=False)\n",
    "        concat_encoded_testset = concat_encoded_testset.to_tf_dataset(\n",
    "            columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    "            shuffle=False,\n",
    "            batch_size=8,\n",
    "            collate_fn=cache.datacollator,\n",
    "        )\n",
    "        load_cache_entry(concat_encoded_testset, ['concat_and_encoded_testset', character + \"_df\"])\n",
    "    return cache.concat_and_encoded_testset[character + \"_df\"]\n",
    "\n",
    "def get_cache_predictions(dataset_from, character, base_folder, gen_type):\n",
    "    if not cache.predictions[dataset_from][character][gen_type]:\n",
    "        if dataset_from == character + \"_df\":\n",
    "            predictions_tk = get_chatbot_predictions(None, None,\n",
    "                  character_dict[character]['prediction_filename'] + '_' + gen_type + '.json',\n",
    "                  None, character, None, base_folder, override_predictions=False)\n",
    "        elif character == \"Base\":\n",
    "            predictions_tk = get_chatbot_predictions(None, None,\n",
    "                  'from_' + dataset_from + '__' + gen_type + '.json',\n",
    "                  None, 'Default', None, base_folder, override_predictions=False)\n",
    "        elif dataset_from == \"Common_df\" and character != \"Base\":\n",
    "            df = load_dataset('csv',\n",
    "                         data_files=os.path.join(base_folder, 'Data', 'common_dataset.csv'), \n",
    "                         cache_dir=os.path.join(base_folder, \"cache\"))\n",
    "            df = df.remove_columns(['source'])\n",
    "            model = get_cache_model(character)\n",
    "            predictions_tk = get_chatbot_predictions(df['train']['context/0'], model,\n",
    "                  \"\", gen_type, character, cache.tokenizer, base_folder, file_caching=False, override_predictions=False)            \n",
    "        else:\n",
    "            raise NotImplementedError(\"Unexpected predictions to load!\")\n",
    "        predictions = []\n",
    "        for line in predictions_tk:\n",
    "            predictions.append(cache.tokenizer.decode(line, skip_special_tokens=True))\n",
    "        load_cache_entry(predictions, ['predictions', dataset_from, character, gen_type])\n",
    "    return cache.predictions[dataset_from][character][gen_type]\n",
    "\n",
    "# For metrics worth caching, in particular the chatbot classifiers\n",
    "def get_cache_metric(metric_name, **kwargs):\n",
    "    classifier_char = None if 'classifier_char' not in kwargs else kwargs['classifier_char']\n",
    "    mode = None if 'mode' not in kwargs else kwargs['mode']\n",
    "    with_barney = None if 'with_barney' not in kwargs else kwargs['with_barney']\n",
    "    if metric_name in cache.trained_metric:\n",
    "        if metric_name == \"neural chatbot classifier\":\n",
    "            if not cache.trained_metric[metric_name][classifier_char]:\n",
    "                cache.trained_metric[metric_name][classifier_char] = BBMetric.load_metric(metric_name)\n",
    "                cache.trained_metric[metric_name][classifier_char].compute( # Dummy round for caching\n",
    "                    character=classifier_char,\n",
    "                    load_path=os.path.join(base_folder, \"Data\", \"Characters\",\n",
    "                              classifier_char, character_dict[classifier_char]['classifier_folder']),\n",
    "                    sentences=[\"Hi\", \"Hello\", \"How\"])\n",
    "            return cache.trained_metric[metric_name][classifier_char]\n",
    "        elif metric_name == \"frequency chatbot classifier\":\n",
    "            if not cache.trained_metric[metric_name]:\n",
    "                cache.trained_metric[metric_name] = BBMetric.load_metric(metric_name)\n",
    "                cache.trained_metric[metric_name].train(\n",
    "                    characters_path=os.path.join(base_folder, \"Data\", \"Characters\"),\n",
    "                    mode=mode)\n",
    "            return cache.trained_metric[metric_name]\n",
    "        elif metric_name == \"distilbert-embedded chatbot classifier\":\n",
    "            if not cache.trained_metric[metric_name][with_barney]:\n",
    "                if with_barney == \"Full\":\n",
    "                    cache.trained_metric[metric_name][with_barney] = BBMetric.load_metric(metric_name,\n",
    "                                embedder_path=os.path.join(base_folder, \"Data\", \"Metrics\", \n",
    "                                                           \"distilbert_embedder\"),\n",
    "                                from_pretrained=True, use_cuda=use_cuda)\n",
    "                elif with_barney == \"No Barney\":\n",
    "                    cache.trained_metric[metric_name][with_barney] = BBMetric.load_metric(metric_name,\n",
    "                                embedder_path=os.path.join(base_folder, \"Data\", \"Metrics\", \n",
    "                                                           \"distilbert_embedder\"),\n",
    "                                from_pretrained=True, use_cuda=use_cuda)\n",
    "    else:\n",
    "        return BBMetric.load_metric(metric_name)\n",
    "\n",
    "def get_cache_model(character):\n",
    "    if character == \"Base\":\n",
    "        model = TFAutoModelForCausalLM.from_pretrained(model_name, cache_dir=os.path.join(base_folder, \"cache\"))\n",
    "    else:\n",
    "        checkpoint_folder = os.path.join(in_folder, character, character_dict[character]['checkpoint_folder'])\n",
    "        model = TFAutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=checkpoint_folder)\n",
    "    model.compile()\n",
    "    cache.dialogpt[character] = model\n",
    "    return cache.dialogpt[character]\n",
    "\n",
    "cache.tokenizer = tokenizer\n",
    "cache.datacollator = data_collator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc3e480",
   "metadata": {},
   "source": [
    "# Evaluation Process Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8dba10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_callable(reference_set, character, column):\n",
    "    if column == \"context/0\" or column == \"response\":\n",
    "        assert(reference_set == character + \"_df\")\n",
    "        return get_cache_testset(character, base_folder)[column]\n",
    "    else:\n",
    "        assert(reference_set == character + \"_df\" or \\\n",
    "               reference_set == \"Common_df\" or \\\n",
    "               (character == \"Base\" and column == \"sampling\"))\n",
    "        return get_cache_predictions(reference_set, character, base_folder, column)\n",
    "\n",
    "def perplexity_callable(reference_set, character):\n",
    "    return {\n",
    "        'model': get_cache_model(character),\n",
    "        'encoded_test_set': get_cache_concat_and_encoded_testset(reference_set.replace(\"_df\", \"\"),\n",
    "                                                                 base_folder)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15b49468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_round(queries):\n",
    "    actors_pprint_map = {\n",
    "        MetricActor.DATASET_CHAR: \"dataset\",\n",
    "        MetricActor.DATASET_CHARCONTEXT: \"dataset labels\",\n",
    "        MetricActor.DIALOGPT_GREEDY: \"dialogpt (greedy)\",\n",
    "        MetricActor.DIALOGPT_NBEAMS: \"dialogpt (nbeamns)\",\n",
    "        MetricActor.DIALOGPT_SAMPLE: \"dialogpt (sampling)\"\n",
    "    }\n",
    "    actor_to_column_map = {\n",
    "        MetricActor.DATASET_CHARCONTEXT: 'context/0',\n",
    "        MetricActor.DATASET_CHAR: 'response',\n",
    "        MetricActor.DIALOGPT_GREEDY: 'greedy',\n",
    "        MetricActor.DIALOGPT_NBEAMS: 'nbeams',\n",
    "        MetricActor.DIALOGPT_SAMPLE: 'sampling'\n",
    "    }\n",
    "    results = dict()\n",
    "    for i in range(len(queries)):\n",
    "        try:\n",
    "            query = queries[i].copy() # Since there are destructive operations\n",
    "            print(\"#### Running Query \" + str(i+1) + \"/\" + str(len(queries)) + \" ####\")\n",
    "            if 'run' in query:\n",
    "                query['run'](**query['run_args'])\n",
    "            else:\n",
    "                print(\"Evaluating \" + query['metric_name'] + \\\n",
    "                      \" on reference set \" + query['reference_set'] + \" with:\")\n",
    "                for actor_type, actor in query['metric_actors'].items():\n",
    "                    print(\"\\t\" + actor[1] + \" \" + actors_pprint_map[actor[0]] + \" as \" + actor_type)\n",
    "                # Get metric metadata data for outputting\n",
    "                query_output = dict()\n",
    "                query_output['metric_name'] = query['metric_name']\n",
    "                query_output['metric_version'] = 1 # It's 1 for all metrics we use, anyway\n",
    "                query_output['metric_attempt'] = 0 if 'metric_attempt' not in query \\\n",
    "                                                   else query['metric_attempt']\n",
    "                query_output['metric_actors'] = query['metric_actors']\n",
    "                query_output['metric_params'] = query['metric_params']\n",
    "                query_output['context'] = {\n",
    "                    \"dialogpt_size\": \"small\",\n",
    "                    \"dialogpt_context_sentences\": 5,\n",
    "                    \"dialogpt_nbeams_beams\": 3,\n",
    "                    \"dialogpt_sample_top_p\": 0.92,\n",
    "                    \"dialogpt_sample_top_k\": 50\n",
    "                }\n",
    "                query_output['metric_arity'] = get_metric_arity(query['metric_name'])\n",
    "                query_output['metric_determinism'] = get_metric_determinism(query['metric_name'],\n",
    "                                                                            query_output['metric_version'])\n",
    "                query_output['reference_set'] = query['reference_set']\n",
    "                query_hash = dict_hash({'metric_name': query_output['metric_name'],\n",
    "                                        'metric_version': query_output['metric_version'],\n",
    "                                        'reference_set': query_output['reference_set'],\n",
    "                                        'metric_attempt': query_output['metric_attempt'],\n",
    "                                        'metric_actors': query_output['metric_actors'],\n",
    "                                        'context': query_output['context'],\n",
    "                                        'metric_params': query_output['metric_params']})\n",
    "                for key in query['metric_actors'].keys(): # Lazy fix for \"_df\" suffix\n",
    "                    if query['metric_actors'][key][0] == MetricActor.DATASET_CHARCONTEXT or \\\n",
    "                        query['metric_actors'][key][0] == MetricActor.DATASET_CHAR:\n",
    "                        query['metric_actors'][key] = (query['metric_actors'][key][0],\n",
    "                                                       query['metric_actors'][key][1].replace(\"_df\", \"\"))\n",
    "                # Compute the actual metric\n",
    "                if query['metric_name'] in ['google bleu', 'meteor', 'rouge l', 'mpnet embedding similarity',\n",
    "                                'emotion classifier', 'distinct', 'roberta crossencoding similarity',\n",
    "                                'repetitiveness', 'term error rate', 'bertscore', 'bleurt', 'bartscore',\n",
    "                                'word mover distance', 't5 grammar correction edit distance',\n",
    "                                'extended edit distance']:\n",
    "                    args_map = {\n",
    "                        'predictor': 'predictions', 'reference': 'references', 'document': 'sentences',\n",
    "                        'document0': 'sentences_a', 'document1': 'sentences_b'\n",
    "                    }\n",
    "                    metric = get_cache_metric(query['metric_name'])\n",
    "                    args_dict = {}\n",
    "                    for actor_key, actor_pair in query['metric_actors'].items():\n",
    "                        args_dict[args_map[actor_key]] = sentence_callable(query['reference_set'],\n",
    "                                                                           actor_pair[1],\n",
    "                                                                           actor_to_column_map[actor_pair[0]])\n",
    "                elif query['metric_name'] == 'comet':\n",
    "                    args_map = {\n",
    "                        'predictor': 'predictions', 'reference': 'references', 'document': 'sources'\n",
    "                    }\n",
    "                    metric = get_cache_metric(query['metric_name'])\n",
    "                    args_dict = {}\n",
    "                    for actor_key, actor_pair in query['metric_actors'].items():    \n",
    "                        args_dict[args_map[actor_key]] = sentence_callable(query['reference_set'],\n",
    "                                                                           actor_pair[1],\n",
    "                                                                           actor_to_column_map[actor_pair[0]])\n",
    "                elif query['metric_name'] in ['perplexity']:\n",
    "                    actor_pair = list(query['metric_actors'].values())[0]\n",
    "                    metric = get_cache_metric(query['metric_name'])\n",
    "                    args_dict = perplexity_callable(query['reference_set'],\n",
    "                                                    actor_pair[1])\n",
    "                elif query['metric_name'] in ['frequency chatbot classifier']:\n",
    "                    actor_pair = list(query['metric_actors'].values())[0]\n",
    "                    metric = get_cache_metric(query['metric_name'],\n",
    "                                              mode=query['metric_params']['mode'])\n",
    "                    del query['metric_params']['mode']\n",
    "                    args_dict = {\n",
    "                        'sentences': sentence_callable(query['reference_set'],\n",
    "                                                       actor_pair[1],\n",
    "                                                       actor_to_column_map[actor_pair[0]])\n",
    "                    }\n",
    "                elif query['metric_name'] in ['distilbert-embedded chatbot classifier']:\n",
    "                    actor_pair = list(query['metric_actors'].values())[0]\n",
    "                    metric = get_cache_metric(query['metric_name'],\n",
    "                                              with_barney=query['metric_params']['with_barney'])\n",
    "                    del query['metric_params']['with_barney']\n",
    "                    args_dict = {\n",
    "                        'sentences': sentence_callable(query['reference_set'],\n",
    "                                                       actor_pair[1],\n",
    "                                                       actor_to_column_map[actor_pair[0]])\n",
    "                    }\n",
    "                elif query['metric_name'] in ['neural chatbot classifier']:\n",
    "                    actor_pair = list(query['metric_actors'].values())[0]\n",
    "                    classifier_char = query['metric_params']['classifier_char']\n",
    "                    args_dict = {\n",
    "                        'character': classifier_char,\n",
    "                        'load_path': os.path.join(base_folder, \"Data\", \"Characters\",\n",
    "                                      classifier_char, character_dict[classifier_char]['classifier_folder']),\n",
    "                    }\n",
    "                    metric = get_cache_metric(query['metric_name'],\n",
    "                                              classifier_char=classifier_char)\n",
    "                    del query['metric_params']['classifier_char']\n",
    "                    args_dict['sentences'] = sentence_callable(query['reference_set'],\n",
    "                                                               actor_pair[1],\n",
    "                                                               actor_to_column_map[actor_pair[0]])         \n",
    "                query_output['answer'] = metric.compute(**{**args_dict, **query['metric_params']})\n",
    "                results[query_hash] = query_output\n",
    "        except Exception as e:\n",
    "            print(\"Query failed due to \" + str(type(e)) + \" with message \" + str(e))\n",
    "        print()\n",
    "    print(\"Done.\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf531aa",
   "metadata": {},
   "source": [
    "# Example of Running an Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3be77e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric Name: See BBMetric.metrics_list\n",
    "# Metric Params: See optional and require params of each metric\n",
    "## NOTE: For neural chatbot classifier, add 'classifier_char' as a parameter\n",
    "# Metric Actors:\n",
    "## DATASET_CHARCONTEXT: (any character | \"Common\") + \"_df\"\n",
    "## DATASET_CHAR: (any character | \"Common\") + \"_df\"\n",
    "## DIALOGPT_GREEDY: any character | \"Base\"\n",
    "## DIALOGPT_NBEAMS: any character | \"Base\"\n",
    "## DIALOGPT_SAMPLE: any character | \"Base\"\n",
    "# Reference Set: (any character | \"Common\") + \"_df\"\n",
    "# Metric Attempt: Defaults to 0, add a number to save multiple runs of the same query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bf0116aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    {\n",
    "        'metric_name': 'google bleu',\n",
    "        'metric_actors': {\n",
    "            'predictor': (MetricActor.DATASET_CHAR, 'Vader_df'),\n",
    "            'reference': (MetricActor.DATASET_CHARCONTEXT, 'Vader_df'),\n",
    "        },\n",
    "        'reference_set': 'Vader_df',\n",
    "        'metric_params': {},\n",
    "        'metric_attempt': 0\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e5925112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Running Query 1/1 ####\n",
      "Evaluating bleurt (on reference set Vader_df) with:\n",
      "\tVader_df dataset as predictor\n",
      "\tVader_df dataset labels as reference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default BLEURT-Base checkpoint for sequence maximum length 128. You can use a bigger model for better results with e.g.: evaluate.load('bleurt', 'bleurt-large-512').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint C:\\Users\\Valerio\\.cache\\huggingface\\metrics\\bleurt\\default\\downloads\\extracted\\3d33e07d20dc36fda3d97eef6258f85c53f0aaa9906a4530ff316c246d91a357\\bleurt-base-128.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint bert_custom\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:bert_custom\n",
      "INFO:tensorflow:... vocab_file:vocab.txt\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... do_lower_case:True\n",
      "INFO:tensorflow:... max_seq_length:128\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating WordPiece tokenizer.\n",
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n",
      "INFO:tensorflow:BLEURT initialized.\n",
      "\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'9901c208f2f724ef76bc34e0c39bfaad': {'metric_name': 'bleurt',\n",
       "  'metric_version': 1,\n",
       "  'metric_attempt': 0,\n",
       "  'metric_actors': {'predictor': (<MetricActor.DATASET_CHAR: 1>, 'Vader'),\n",
       "   'reference': (<MetricActor.DATASET_CHARCONTEXT: 0>, 'Vader')},\n",
       "  'metric_params': {},\n",
       "  'context': {'dialogpt_size': 'small',\n",
       "   'dialogpt_context_sentences': 5,\n",
       "   'dialogpt_nbeams_beams': 3,\n",
       "   'dialogpt_sample_top_p': 0.92,\n",
       "   'dialogpt_sample_top_k': 50},\n",
       "  'metric_arity': <MetricArity.PAIRWISE: 2>,\n",
       "  'metric_determinism': <MetricDeterminism.NEURAL: 2>,\n",
       "  'reference_set': 'Vader_df',\n",
       "  'answer': {'score': -1.4269872084259987, 'std': 0.29314456560953456}}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_round(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a09bb1d",
   "metadata": {},
   "source": [
    "# Run Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f706444d",
   "metadata": {},
   "source": [
    "## Single Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c9fce35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Running Query 1/26 ####\n",
      "Evaluating distinct on reference set Barney_df with:\n",
      "\tBarney_df dataset as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-d05c63f64527f593\n",
      "Found cached dataset csv (E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-d05c63f64527f593/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a52547318d44133aeed61824992fbf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-d05c63f64527f593/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-e57fb526fe4a3ff3.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-d05c63f64527f593/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-54c202230f70778c.arrow\n",
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-d05c63f64527f593/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-2b7ecddd83bcebad.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-d05c63f64527f593/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-f85aa8d6528292e4.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache at ['testset', 'Barney_df']\n",
      "\n",
      "#### Running Query 2/26 ####\n",
      "Evaluating distinct on reference set Sheldon_df with:\n",
      "\tSheldon_df dataset as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-b47497d241584694\n",
      "Found cached dataset csv (E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-b47497d241584694/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc884165e704ec0b345eb88adfbe9b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-b47497d241584694/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-029452f8e061c873.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-b47497d241584694/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-c14841bc6fd888d0.arrow\n",
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-b47497d241584694/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-a95f39f7704e7643.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-b47497d241584694/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-3155a76a827528d3.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache at ['testset', 'Sheldon_df']\n",
      "\n",
      "#### Running Query 3/26 ####\n",
      "Evaluating distinct on reference set Harry_df with:\n",
      "\tHarry_df dataset as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-8734ab070ca4d4a4\n",
      "Found cached dataset csv (E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-8734ab070ca4d4a4/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c57d5d5ea2d4d539504b95874373d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-8734ab070ca4d4a4/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-6f2c723a222e2152.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-8734ab070ca4d4a4/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-06309c8f05ebbafb.arrow\n",
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-8734ab070ca4d4a4/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-065178db47afc42d.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-8734ab070ca4d4a4/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-b63cdf0d40382d55.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache at ['testset', 'Harry_df']\n",
      "\n",
      "#### Running Query 4/26 ####\n",
      "Evaluating distinct on reference set Fry_df with:\n",
      "\tFry_df dataset as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-edae583082198a82\n",
      "Found cached dataset csv (E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-edae583082198a82/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "230569a00f3e424b8366840d6b0b4b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-edae583082198a82/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-3a40bd254dc1230b.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-edae583082198a82/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-76bce446c8545bcd.arrow\n",
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-edae583082198a82/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-0d49f749e9201c30.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-edae583082198a82/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-2361c2a0ed34c32d.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache at ['testset', 'Fry_df']\n",
      "\n",
      "#### Running Query 5/26 ####\n",
      "Evaluating distinct on reference set Bender_df with:\n",
      "\tBender_df dataset as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-36d673def5b55b14\n",
      "Found cached dataset csv (E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-36d673def5b55b14/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b706ec10981f439cb9b0c51f74e2005f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-36d673def5b55b14/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-45e9a5cdc4703907.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-36d673def5b55b14/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-3d73977ab48375f4.arrow\n",
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-36d673def5b55b14/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-29c1b91d58842d36.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-36d673def5b55b14/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-15d3f645646c43ff.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache at ['testset', 'Bender_df']\n",
      "\n",
      "#### Running Query 6/26 ####\n",
      "Evaluating distinct on reference set Vader_df with:\n",
      "\tVader_df dataset as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-3e37c23a51e9d556\n",
      "Found cached dataset csv (E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-3e37c23a51e9d556/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c985726d7f324eb88916a3e6f65fe71a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-3e37c23a51e9d556/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-6affe80547fc0f38.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-3e37c23a51e9d556/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-6800bd34204a2976.arrow\n",
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-3e37c23a51e9d556/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-78893b2d23cae2d7.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-3e37c23a51e9d556/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-38619cd96763b020.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache at ['testset', 'Vader_df']\n",
      "\n",
      "#### Running Query 7/26 ####\n",
      "Evaluating distinct on reference set Joey_df with:\n",
      "\tJoey_df dataset as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-bc30ecf942c9a05e\n",
      "Found cached dataset csv (E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-bc30ecf942c9a05e/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2239b6cce1974423a433f69bb84bc5c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-bc30ecf942c9a05e/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-ba044a5350a0b4ee.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-bc30ecf942c9a05e/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-27a2b109b2a74d44.arrow\n",
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-bc30ecf942c9a05e/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-5b9e07b7a11ce3d7.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-bc30ecf942c9a05e/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-5910ff0b0ae92adb.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache at ['testset', 'Joey_df']\n",
      "\n",
      "#### Running Query 8/26 ####\n",
      "Evaluating distinct on reference set Phoebe_df with:\n",
      "\tPhoebe_df dataset as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-437509a5e3c6484b\n",
      "Found cached dataset csv (E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-437509a5e3c6484b/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a44de97579646f0afa2d4708b2e6e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-437509a5e3c6484b/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-f3dedb84963f27fc.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-437509a5e3c6484b/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-f69b60477b60f2fe.arrow\n",
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-437509a5e3c6484b/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-ae641b942c4f1782.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-437509a5e3c6484b/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-1b02de643a9ce81e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache at ['testset', 'Phoebe_df']\n",
      "\n",
      "#### Running Query 9/26 ####\n",
      "Evaluating distinct on reference set Common_df with:\n",
      "\tCommon_df dataset as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-a0e685ebee7bf9f8\n",
      "Found cached dataset csv (E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/cache/csv/default-a0e685ebee7bf9f8/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db2e05248de4231bea3cdbfb0229483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache at ['testset', 'Common_df']\n",
      "\n",
      "#### Running Query 10/26 ####\n",
      "Evaluating distinct on reference set Barney_df with:\n",
      "\tBarney dialogpt (sampling) as document\n",
      "Loading predictions from stored file\n",
      "Loaded predictions from stored file\n",
      "Loaded cache at ['predictions', 'Barney_df', 'Barney', 'sampling']\n",
      "\n",
      "#### Running Query 11/26 ####\n",
      "Evaluating distinct on reference set Sheldon_df with:\n",
      "\tSheldon dialogpt (sampling) as document\n",
      "Loading predictions from stored file\n",
      "Loaded predictions from stored file\n",
      "Loaded cache at ['predictions', 'Sheldon_df', 'Sheldon', 'sampling']\n",
      "\n",
      "#### Running Query 12/26 ####\n",
      "Evaluating distinct on reference set Harry_df with:\n",
      "\tHarry dialogpt (sampling) as document\n",
      "Loading predictions from stored file\n",
      "Loaded predictions from stored file\n",
      "Loaded cache at ['predictions', 'Harry_df', 'Harry', 'sampling']\n",
      "\n",
      "#### Running Query 13/26 ####\n",
      "Evaluating distinct on reference set Fry_df with:\n",
      "\tFry dialogpt (sampling) as document\n",
      "Loading predictions from stored file\n",
      "Loaded predictions from stored file\n",
      "Loaded cache at ['predictions', 'Fry_df', 'Fry', 'sampling']\n",
      "\n",
      "#### Running Query 14/26 ####\n",
      "Evaluating distinct on reference set Bender_df with:\n",
      "\tBender dialogpt (sampling) as document\n",
      "Loading predictions from stored file\n",
      "Loaded predictions from stored file\n",
      "Loaded cache at ['predictions', 'Bender_df', 'Bender', 'sampling']\n",
      "\n",
      "#### Running Query 15/26 ####\n",
      "Evaluating distinct on reference set Vader_df with:\n",
      "\tVader dialogpt (sampling) as document\n",
      "Loading predictions from stored file\n",
      "Loaded predictions from stored file\n",
      "Loaded cache at ['predictions', 'Vader_df', 'Vader', 'sampling']\n",
      "\n",
      "#### Running Query 16/26 ####\n",
      "Evaluating distinct on reference set Joey_df with:\n",
      "\tJoey dialogpt (sampling) as document\n",
      "Loading predictions from stored file\n",
      "Loaded predictions from stored file\n",
      "Loaded cache at ['predictions', 'Joey_df', 'Joey', 'sampling']\n",
      "\n",
      "#### Running Query 17/26 ####\n",
      "Evaluating distinct on reference set Phoebe_df with:\n",
      "\tPhoebe dialogpt (sampling) as document\n",
      "Loading predictions from stored file\n",
      "Loaded predictions from stored file\n",
      "Loaded cache at ['predictions', 'Phoebe_df', 'Phoebe', 'sampling']\n",
      "\n",
      "#### Running Query 18/26 ####\n",
      "Evaluating distinct on reference set Common_df with:\n",
      "\tBarney dialogpt (sampling) as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-a0e685ebee7bf9f8\n",
      "Found cached dataset csv (E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/cache/csv/default-a0e685ebee7bf9f8/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86e6124dd9e449e8987d1ab9621fc02c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at E:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\\Data\\Characters\\Barney\\barney_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/35 [00:00<?, ?it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  3%|                                                                                | 1/35 [00:06<03:47,  6.69s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  6%|                                                                              | 2/35 [00:10<02:40,  4.86s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  9%|                                                                            | 3/35 [00:12<01:50,  3.44s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 11%|                                                                         | 4/35 [00:14<01:30,  2.92s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 14%|                                                                       | 5/35 [00:19<01:55,  3.84s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 14%|                                                                       | 5/35 [00:20<02:05,  4.20s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13064\\67805705.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmetric\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"frequency chatbot classifier\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mmetric_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'mode'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'c-tf-idf'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     results = evaluate_round([\n\u001b[0m\u001b[0;32m     10\u001b[0m         {\n\u001b[0;32m     11\u001b[0m             \u001b[1;34m'metric_name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13064\\2364497150.py\u001b[0m in \u001b[0;36mevaluate_round\u001b[1;34m(queries)\u001b[0m\n\u001b[0;32m     70\u001b[0m                     \u001b[0margs_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mactor_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactor_pair\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'metric_actors'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m                         args_dict[args_map[actor_key]] = sentence_callable(query['reference_set'],\n\u001b[0m\u001b[0;32m     73\u001b[0m                                                                            \u001b[0mactor_pair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m                                                                            actor_to_column_map[actor_pair[0]])\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13064\\3133064778.py\u001b[0m in \u001b[0;36msentence_callable\u001b[1;34m(reference_set, character, column)\u001b[0m\n\u001b[0;32m      7\u001b[0m                \u001b[0mreference_set\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"Common_df\"\u001b[0m \u001b[1;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                (character == \"Base\" and column == \"sampling\"))\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mget_cache_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreference_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcharacter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mperplexity_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreference_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcharacter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13064\\241576506.py\u001b[0m in \u001b[0;36mget_cache_predictions\u001b[1;34m(dataset_from, character, base_folder, gen_type)\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'source'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_cache_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcharacter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             predictions_tk = get_chatbot_predictions(df['train']['context/0'], model,\n\u001b[0m\u001b[0;32m     45\u001b[0m                   \"\", gen_type, character, cache.tokenizer, base_folder, file_caching=False, override_predictions=False)            \n\u001b[0;32m     46\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\\Src\\lib\\BBDataLoad.py\u001b[0m in \u001b[0;36mget_chatbot_predictions\u001b[1;34m(sample_questions, model, filename, generation_method, character, tokenizer, base_folder, file_caching, override_predictions)\u001b[0m\n\u001b[0;32m    463\u001b[0m                 \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 465\u001b[1;33m                     generated_answer = model.generate(\n\u001b[0m\u001b[0;32m    466\u001b[0m                         \u001b[0mtokenized_question\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m                         \u001b[0mpad_token_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meos_token_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\transformers\\generation\\tf_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, input_ids, max_length, max_new_tokens, min_length, do_sample, early_stopping, num_beams, temperature, penalty_alpha, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, num_return_sequences, attention_mask, decoder_start_token_id, use_cache, output_scores, output_attentions, output_hidden_states, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, suppress_tokens, begin_suppress_tokens, forced_decoder_ids, **model_kwargs)\u001b[0m\n\u001b[0;32m    692\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdo_sample\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mnum_beams\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m             \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"seed\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 694\u001b[1;33m             return self._generate(\n\u001b[0m\u001b[0;32m    695\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m                 \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\transformers\\generation\\tf_utils.py\u001b[0m in \u001b[0;36m_generate\u001b[1;34m(self, input_ids, max_length, max_new_tokens, min_length, do_sample, early_stopping, num_beams, temperature, penalty_alpha, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, num_return_sequences, attention_mask, decoder_start_token_id, use_cache, seed, output_scores, output_attentions, output_hidden_states, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, suppress_tokens, begin_suppress_tokens, forced_decoder_ids, **model_kwargs)\u001b[0m\n\u001b[0;32m   1904\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1905\u001b[0m             \u001b[1;31m# 12. run sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1906\u001b[1;33m             return self.sample(\n\u001b[0m\u001b[0;32m   1907\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1908\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\transformers\\generation\\tf_utils.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, input_ids, logits_processor, logits_warper, max_length, pad_token_id, eos_token_id, seed, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, **model_kwargs)\u001b[0m\n\u001b[0;32m   2807\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_cond_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinished_sequences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2808\u001b[0m             \u001b[0mmaximum_iterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcur_len\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2809\u001b[1;33m             generated, _, cur_len, _ = tf.while_loop(\n\u001b[0m\u001b[0;32m   2810\u001b[0m                 \u001b[0msample_cond_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2811\u001b[0m                 \u001b[0msample_body_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    627\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'in a future version'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[1;32m--> 629\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop_v2\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[0;32m   2514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2515\u001b[0m   \"\"\"\n\u001b[1;32m-> 2516\u001b[1;33m   return while_loop(\n\u001b[0m\u001b[0;32m   2517\u001b[0m       \u001b[0mcond\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2518\u001b[0m       \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[0;32m   2763\u001b[0m                                               list(loop_vars))\n\u001b[0;32m   2764\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2765\u001b[1;33m         \u001b[0mloop_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2766\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2767\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(i, lv)\u001b[0m\n\u001b[0;32m   2754\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[0;32m   2755\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[1;32m-> 2756\u001b[1;33m         \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2757\u001b[0m       \u001b[0mtry_to_pack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\transformers\\generation\\tf_utils.py\u001b[0m in \u001b[0;36msample_body_fn\u001b[1;34m(generated, finished_sequences, cur_len, model_kwargs)\u001b[0m\n\u001b[0;32m   2723\u001b[0m             \u001b[0mmodel_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2724\u001b[0m             \u001b[1;31m# forward pass to get next token logits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2725\u001b[1;33m             model_outputs = self(\n\u001b[0m\u001b[0;32m   2726\u001b[0m                 \u001b[1;33m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2727\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mlayout_map_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc_in_current_and_subclasses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1130\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m                 ):\n\u001b[1;32m-> 1132\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_keras_call_info_injected\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\u001b[0m in \u001b[0;36mrun_call_with_unpacked_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m         \u001b[0munpacked_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_processing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfn_args_and_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munpacked_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m     \u001b[1;31m# Keras enforces the first layer argument to be passed, and checks it through `inspect.getfullargspec()`. This\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict, labels, training)\u001b[0m\n\u001b[0;32m    921\u001b[0m         )\n\u001b[0;32m    922\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 923\u001b[1;33m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwte\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"linear\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    924\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1130\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m                 ):\n\u001b[1;32m-> 1132\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_keras_call_info_injected\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mode)\u001b[0m\n\u001b[0;32m   3062\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3063\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"linear\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3064\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_linear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3065\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3066\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"mode {mode} is not valid.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\u001b[0m in \u001b[0;36m_linear\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3082\u001b[0m         \u001b[0mfirst_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3083\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3084\u001b[1;33m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3085\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3086\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst_dims\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1177\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, name)\u001b[0m\n\u001b[0;32m   3712\u001b[0m             a, b, adj_x=adjoint_a, adj_y=adjoint_b, Tout=output_type, name=name)\n\u001b[0;32m   3713\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3714\u001b[1;33m         return gen_math_ops.mat_mul(\n\u001b[0m\u001b[0;32m   3715\u001b[0m             a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0;32m   3716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   6711\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6712\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6713\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   6714\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"MatMul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"transpose_a\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"transpose_b\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6715\u001b[0m         transpose_b)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for metric in ['distinct', 'repetitiveness', 't5 grammar correction edit distance', 'flesch-kincaid index',\n",
    "               'distilbert-embedded chatbot classifier', 'frequency chatbot classifier']:\n",
    "    metric_pretty = BBMetric.load_metric(metric).pretty_name\n",
    "    metric_params = dict()\n",
    "    if metric == \"distilbert-embedded chatbot classifier\":\n",
    "        metric_params = {'with_barney': True}\n",
    "    elif metric == \"frequency chatbot classifier\":\n",
    "        metric_params = {'mode': 'c-tf-idf'}\n",
    "    results = evaluate_round([\n",
    "        {\n",
    "            'metric_name': metric,\n",
    "            'metric_actors': {\n",
    "                'document': (MetricActor.DATASET_CHAR, char + '_df')\n",
    "            },\n",
    "            'reference_set': char + '_df',\n",
    "            'metric_params': {},\n",
    "            'metric_attempt': 0\n",
    "        } for char in characters + [\"Common\"]\n",
    "    ] + [\n",
    "        {\n",
    "            'metric_name': metric,\n",
    "            'metric_actors': {\n",
    "                'document': (MetricActor.DIALOGPT_SAMPLE, char)\n",
    "            },\n",
    "            'reference_set': char + '_df',\n",
    "            'metric_params': {},\n",
    "            'metric_attempt': 0\n",
    "        } for char in characters\n",
    "    ] + [\n",
    "        {\n",
    "            'metric_name': metric,\n",
    "            'metric_actors': {\n",
    "                'document': (MetricActor.DIALOGPT_SAMPLE, char)\n",
    "            },\n",
    "            'reference_set': 'Common_df',\n",
    "            'metric_params': {},\n",
    "            'metric_attempt': 0\n",
    "        } for char in characters + [\"Base\"]\n",
    "    ])\n",
    "    metric_dict = load_metric_by_name(out_folder, metric_pretty)\n",
    "    metric_dict = {**metric_dict, **results}\n",
    "    save_metric_by_name(out_folder, metric_pretty, metric_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a7e1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'neural chatbot classifier'\n",
    "metric_pretty = BBMetric.load_metric(metric).pretty_name\n",
    "metric_params = dict()\n",
    "results = evaluate_round([\n",
    "    {\n",
    "        'metric_name': metric,\n",
    "        'metric_actors': {\n",
    "            'document': (MetricActor.DATASET_CHAR, char + '_df')\n",
    "        },\n",
    "        'reference_set': char + '_df',\n",
    "        'metric_params': {'classifier_char': char},\n",
    "        'metric_attempt': 0\n",
    "    } for char in characters + [\"Common\"]\n",
    "] + [\n",
    "    {\n",
    "        'metric_name': metric,\n",
    "        'metric_actors': {\n",
    "            'document': (MetricActor.DIALOGPT_SAMPLE, char)\n",
    "        },\n",
    "        'reference_set': char + '_df',\n",
    "        'metric_params': {'classifier_char': char},\n",
    "        'metric_attempt': 0\n",
    "    } for char in characters\n",
    "] + [\n",
    "    {\n",
    "        'metric_name': metric,\n",
    "        'metric_actors': {\n",
    "            'document': (MetricActor.DIALOGPT_SAMPLE, char)\n",
    "        },\n",
    "        'reference_set': 'Common_df',\n",
    "        'metric_params': {'classifier_char': char},\n",
    "        'metric_attempt': 0\n",
    "    } for char in characters + [\"Base\"]\n",
    "])\n",
    "metric_dict = load_metric_by_name(out_folder, metric_pretty)\n",
    "metric_dict = {**metric_dict, **results}\n",
    "save_metric_by_name(out_folder, metric_pretty, metric_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22640fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'perplexity'\n",
    "metric_pretty = BBMetric.load_metric(metric).pretty_name\n",
    "metric_params = dict()\n",
    "results = evaluate_round([\n",
    "    {\n",
    "        'metric_name': metric,\n",
    "        'metric_actors': {\n",
    "            'predictor': (MetricActor.DIALOGPT_SAMPLE, char)\n",
    "        },\n",
    "        'reference_set': char2 + '_df',\n",
    "        'metric_params': {},\n",
    "        'metric_attempt': 0\n",
    "    } for char in characters + [\"Base\"]\n",
    "      for char2 in characters + [\"Common\"]\n",
    "]\n",
    "metric_dict = load_metric_by_name(out_folder, metric_pretty)\n",
    "metric_dict = {**metric_dict, **results}\n",
    "save_metric_by_name(out_folder, metric_pretty, metric_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987bfcb3",
   "metadata": {},
   "source": [
    "# COMET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f17605",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"comet\"\n",
    "metric_pretty = BBMetric.load_metric(metric).pretty_name\n",
    "metric_params = dict()\n",
    "results = evaluate_round([\n",
    "    {\n",
    "        'metric_name': metric,\n",
    "        'metric_actors': {\n",
    "            'document': (MetricActor.DATASET_CHARCONTEXT, char + '_df'),\n",
    "            'reference': (MetricActor.DATASET_CHAR, char + \"_df\"),\n",
    "            'predictor': (MetricActor.DIALOGPT_SAMPLE, char)\n",
    "        },\n",
    "        'reference_set': char + '_df',\n",
    "        'metric_params': {},\n",
    "        'metric_attempt': 0\n",
    "    } for char in characters\n",
    "])\n",
    "metric_dict = load_metric_by_name(out_folder, metric_pretty)\n",
    "metric_dict = {**metric_dict, **results}\n",
    "save_metric_by_name(out_folder, metric_pretty, metric_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fddbe56",
   "metadata": {},
   "source": [
    "# Pairwise Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ba20ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in ['google bleu', 'meteor', 'bertscore', 'bartscore', 'bleurt', 'term error rate']:\n",
    "    metric_pretty = BBMetric.load_metric(metric).pretty_name\n",
    "    results = evaluate_round([\n",
    "        {\n",
    "            'metric_name': metric,\n",
    "            'metric_actors': {\n",
    "                'reference': (MetricActor.DATASET_CHAR, char + \"_df\"),\n",
    "                'predictor': (MetricActor.DIALOGPT_SAMPLE, char)\n",
    "            },\n",
    "            'reference_set': char + '_df',\n",
    "            'metric_params': {},\n",
    "            'metric_attempt': 0\n",
    "        } for char in characters\n",
    "    ] + [\n",
    "        {\n",
    "            'metric_name': metric,\n",
    "            'metric_actors': {\n",
    "                'reference': (MetricActor.DIALOGPT_SAMPLE, charpair[1]),\n",
    "                'predictor': (MetricActor.DIALOGPT_SAMPLE, charpair[0])\n",
    "            },\n",
    "            'reference_set': 'Common_df',\n",
    "            'metric_params': {},\n",
    "            'metric_attempt': 0\n",
    "        } for charpair in [('Joey', 'Phoebe'), ('Joey', 'Sheldon'), ('Bender', 'Fry'), ('Bender', 'Barney')]        \n",
    "    ])\n",
    "    metric_dict = load_metric_by_name(out_folder, metric_pretty)\n",
    "    metric_dict = {**metric_dict, **results}\n",
    "    save_metric_by_name(out_folder, pretty_name, metric_dict)\n",
    "    \n",
    "for metric in ['extended edit distance', 'word mover distance']:\n",
    "    metric_pretty = BBMetric.load_metric(metric).pretty_name\n",
    "    results = evaluate_round([\n",
    "        {\n",
    "            'metric_name': metric,\n",
    "            'metric_actors': {\n",
    "                'reference': (MetricActor.DATASET_CHAR, char + \"_df\"),\n",
    "                'predictor': (MetricActor.DIALOGPT_SAMPLE, char)\n",
    "            },\n",
    "            'reference_set': char + '_df',\n",
    "            'metric_params': {},\n",
    "            'metric_attempt': 0\n",
    "        } for char in characters\n",
    "    ] + [\n",
    "        {\n",
    "            'metric_name': metric,\n",
    "            'metric_actors': {\n",
    "                'document0': (MetricActor.DIALOGPT_SAMPLE, charpair[1]),\n",
    "                'document1': (MetricActor.DIALOGPT_SAMPLE, charpair[0])\n",
    "            },\n",
    "            'reference_set': 'Common_df',\n",
    "            'metric_params': {},\n",
    "            'metric_attempt': 0\n",
    "        } for charpair in [('Joey', 'Phoebe'), ('Joey', 'Sheldon'), ('Bender', 'Fry'), ('Bender', 'Barney'),\n",
    "                           ('Barney', 'Harry')]        \n",
    "    ])\n",
    "    metric_dict = load_metric_by_name(out_folder, metric_pretty)\n",
    "    metric_dict = {**metric_dict, **results}\n",
    "    save_metric_by_name(out_folder, metric_pretty, metric_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

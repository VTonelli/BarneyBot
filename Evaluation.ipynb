{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data.data_dicts import character_dict, source_dict, random_state\n",
    "\n",
    "model_name = 'microsoft/DialoGPT-small'\n",
    "character = 'Vader' # 'Barney' | 'Sheldon' | 'Harry' | 'Fry' | 'Vader' | 'Joey' | 'Phoebe' | 'Bender' | Default'\n",
    "character_2 = 'Harry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount google drive\n",
    "import os\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive',force_remount=True)\n",
    "    base_folder = '/content/drive/My Drive/unibo/NLP_project/BarneyBot'\n",
    "    os.system(\"pip install datasets\")\n",
    "    os.system(\"pip install transformers\")\n",
    "    os.system(\"pip install rouge_score\")\n",
    "    os.system(\"pip install -U sentence-transformers\")\n",
    "else:\n",
    "    base_folder = os.getcwd()\n",
    "    \n",
    "in_folder = os.path.join(base_folder, 'Data', 'Characters', character)\n",
    "if not os.path.exists(in_folder):\n",
    "    os.makedirs(in_folder)\n",
    "out_folder = os.path.join(base_folder, 'Data', 'Characters', character)\n",
    "if not os.path.exists(out_folder):\n",
    "    os.makedirs(out_folder)\n",
    "    \n",
    "in_folder_2 = os.path.join(base_folder, 'Data', 'Characters', character_2)\n",
    "if not os.path.exists(in_folder_2):\n",
    "    os.makedirs(in_folder_2)\n",
    "out_folder_2 = os.path.join(base_folder, 'Data', 'Characters', character_2)\n",
    "if not os.path.exists(out_folder_2):\n",
    "    os.makedirs(out_folder_2)\n",
    "    \n",
    "in_folder_def = os.path.join(base_folder, 'Data', 'Characters', 'Default')\n",
    "if not os.path.exists(in_folder_def):\n",
    "    os.makedirs(in_folder_def)\n",
    "out_folder_def = os.path.join(base_folder, 'Data', 'Characters', 'Default')\n",
    "if not os.path.exists(out_folder_def):\n",
    "    os.makedirs(out_folder_def)\n",
    "    \n",
    "metrics_folder = os.path.join(base_folder, 'Metrics')\n",
    "if not os.path.exists(metrics_folder):\n",
    "    os.makedirs(metrics_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_json(filepath, filename, data):\n",
    "    if not os.path.exists(filepath):\n",
    "        os.makedirs(filepath, exist_ok=True)\n",
    "    with open(os.path.join(filepath, filename + \".json\"), 'w') as f:\n",
    "        f.write(json.dumps(data, indent=4))\n",
    "\n",
    "def load_from_json(filepath, filename):\n",
    "    if not os.path.exists(os.path.join(filepath, filename + '.json')):\n",
    "        return dict()\n",
    "    with open(os.path.join(filepath, filename + '.json'), 'r') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "def load_df(character):\n",
    "    dataset_path = os.path.join(base_folder, \"Data\", \"Characters\", character, character+'.csv')\n",
    "    \n",
    "    character_hg = load_dataset('csv', \n",
    "                                data_files=dataset_path, \n",
    "                                cache_dir=os.path.join(base_folder, \"cache\"))\n",
    "    \n",
    "    # 85% train / 10% test / 5% validation\n",
    "    train_test_hg = character_hg['train'].train_test_split(test_size=0.15, seed=random_state)\n",
    "    test_val = train_test_hg['test'].train_test_split(test_size=0.33, seed=random_state)\n",
    "    \n",
    "    \n",
    "    character_hg = DatasetDict({\n",
    "        'train': train_test_hg['train'],\n",
    "        'test': test_val['train'],\n",
    "        'val': test_val['test']\n",
    "    })\n",
    "    \n",
    "    return character_hg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_conv(row, tokenizer):\n",
    "    MAX_LENGTH = 512\n",
    "    row = list(reversed(list(row.values())))\n",
    "    model_inputs = tokenizer(row)\n",
    "    tokenizer_pad_token_id = tokenizer.encode('#')[0]\n",
    "    for i in range(len(model_inputs['input_ids'])):\n",
    "        model_inputs['input_ids'][i].append(tokenizer.eos_token_id)\n",
    "        model_inputs['attention_mask'][i].append(1)\n",
    "    model_inputs['input_ids'] = [item for sublist in model_inputs['input_ids'] for item in sublist]\n",
    "    model_inputs['attention_mask'] = [item for sublist in model_inputs['attention_mask'] for item in sublist]\n",
    "    if MAX_LENGTH > len(model_inputs['input_ids']):\n",
    "        model_inputs['input_ids'] += [tokenizer_pad_token_id] * (MAX_LENGTH - len(model_inputs['input_ids']))\n",
    "        model_inputs['attention_mask'] += [0] * (MAX_LENGTH - len(model_inputs['attention_mask']))\n",
    "    elif MAX_LENGTH < len(model_inputs['input_ids']):\n",
    "        model_inputs['input_ids'] = model_inputs['input_ids'][:MAX_LENGTH-1]\n",
    "        model_inputs['input_ids'][-1] = tokenizer.eos_token_id\n",
    "        model_inputs['attention_mask'] = model_inputs['attention_mask'][:MAX_LENGTH-1]\n",
    "        model_inputs['attention_mask'][-1] = 1\n",
    "    model_inputs[\"labels\"] = model_inputs[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    tokenizer.pad_token = '#'\n",
    "    model_inputs = construct_conv(examples, tokenizer)\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-8c85b46caa75ae36\n",
      "Reusing dataset csv (D:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBot\\BarneyBot\\cache\\csv\\default-8c85b46caa75ae36\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f89bd891b9e4fdb9e534841880f42c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at D:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBot\\BarneyBot\\cache\\csv\\default-8c85b46caa75ae36\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-97a031af79d03f17.arrow and D:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBot\\BarneyBot\\cache\\csv\\default-8c85b46caa75ae36\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-ab2da13547277b18.arrow\n",
      "Loading cached split indices for dataset at D:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBot\\BarneyBot\\cache\\csv\\default-8c85b46caa75ae36\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-b6ad2521bd9c3aa6.arrow and D:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBot\\BarneyBot\\cache\\csv\\default-8c85b46caa75ae36\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-3d47950cec097a89.arrow\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"HF_DATASETS_CACHE\"] = os.path.join(base_folder, \"cache\")\n",
    "character_hg = load_df(character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_folder = os.path.join(out_folder, character_dict[character]['checkpoint_folder'])\n",
    "checkpoint_folder_2 = os.path.join(out_folder_2, character_dict[character_2]['checkpoint_folder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at D:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBot\\BarneyBot\\Data\\Characters\\Vader\\vader_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at D:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBot\\BarneyBot\\Data\\Characters\\Harry\\harry_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at microsoft/DialoGPT-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=os.path.join(base_folder, \"cache\"))\n",
    "tokenizer.pad_token = '#'\n",
    "\n",
    "model = TFAutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=checkpoint_folder)\n",
    "model.compile(optimizer=AdamWeightDecay(learning_rate=2e-5))\n",
    "\n",
    "model_2 = TFAutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=checkpoint_folder_2)\n",
    "model_2.compile(optimizer=AdamWeightDecay(learning_rate=2e-5))\n",
    "\n",
    "model_def = TFAutoModelForCausalLM.from_pretrained(model_name, cache_dir=os.path.join(base_folder, \"cache\"))\n",
    "model_def.compile(optimizer=AdamWeightDecay(learning_rate=2e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n",
      "Loading cached processed dataset at D:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBot\\BarneyBot\\cache\\csv\\default-8c85b46caa75ae36\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-78959818854f4741.arrow\n",
      "Loading cached processed dataset at D:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBot\\BarneyBot\\cache\\csv\\default-8c85b46caa75ae36\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-f484e4ffd2f07ebe.arrow\n",
      "Loading cached processed dataset at D:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBot\\BarneyBot\\cache\\csv\\default-8c85b46caa75ae36\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-8dab56c64be0533d.arrow\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import AdamWeightDecay\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(mlm=False, tokenizer=tokenizer, return_tensors='tf')\n",
    "\n",
    "tokenized_character_hg = character_hg.map(preprocess_function, batched=False)\n",
    "\n",
    "encoded_test_set = tokenized_character_hg[\"test\"].to_tf_dataset(\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_questions = character_hg['test']['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_beams = 3\n",
    "top_k = 50\n",
    "top_p = 0.92\n",
    "\n",
    "def get_predictions_cached(sample_questions, model, filename, generation_method, override_predictions=False):\n",
    "    prediction_path = os.path.join(in_folder, filename)\n",
    "    if os.path.exists(prediction_path) and not override_predictions:\n",
    "        print(\"Loading predictions from stored file\")\n",
    "        with open(prediction_path, 'r') as file:\n",
    "            json_string = file.read()\n",
    "        predictions = json.loads(json_string)\n",
    "        print(\"Loaded predictions from stored file\")\n",
    "\n",
    "    else:\n",
    "        print(\"Creating predictions\")\n",
    "        predictions = list()\n",
    "        for x in tqdm(sample_questions):\n",
    "            tokenized_question = tokenizer.encode(x + tokenizer.eos_token, return_tensors='tf')\n",
    "            max_length = 128 + tokenized_question.shape[1]\n",
    "            if generation_method == \"Greedy\":\n",
    "                generated_answer = model.generate(tokenized_question,\n",
    "                                    pad_token_id=tokenizer.eos_token_id, max_length=max_length)[0].numpy().tolist()\n",
    "            elif generation_method == \"Beam Search\":\n",
    "                generated_answer = model.generate(tokenized_question,\n",
    "                                             pad_token_id=tokenizer.eos_token_id, max_length=max_length,\n",
    "                                             n_beams=n_beams)[0].numpy().tolist()\n",
    "            elif generation_method == \"Sampling\":\n",
    "                b = True\n",
    "                c = 0\n",
    "                while b:\n",
    "                    generated_answer = model.generate(tokenized_question,\n",
    "                                                 pad_token_id=tokenizer.eos_token_id, max_length=max_length,\n",
    "                                                 do_sample=True, top_k=top_k, top_p=top_p)[0].numpy().tolist()\n",
    "                    c += 1\n",
    "                    if len(generated_answer[len(tokenized_question[0]):])>1:\n",
    "                        b = False       \n",
    "                    if c>100: \n",
    "                        generated_answer[len(tokenized_question[0]):] = tokenizer.encode('hi') + [tokenizer.eos_token_id]\n",
    "                        break\n",
    "            \n",
    "            predictions.append(generated_answer[len(tokenized_question[0]):])\n",
    "\n",
    "        # Save predictions as a JSON file\n",
    "        output_string = json.dumps(predictions)\n",
    "        with open(prediction_path, 'w') as file:\n",
    "            file.write(output_string)\n",
    "        \n",
    "        assert all([len(p)>1 for p in predictions])\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading predictions from stored file\n",
      "Loaded predictions from stored file\n",
      "Loading predictions from stored file\n",
      "Loaded predictions from stored file\n",
      "Loading predictions from stored file\n",
      "Loaded predictions from stored file\n"
     ]
    }
   ],
   "source": [
    "predictions_greedy = get_predictions_cached(sample_questions, model,\n",
    "                                            character_dict[character]['prediction_filename'] + '_greedy.json',\n",
    "                                            \"Greedy\")\n",
    "predictions_nbeams = get_predictions_cached(sample_questions, model,\n",
    "                                            character_dict[character]['prediction_filename'] + '_nbeams.json',\n",
    "                                            \"Beam Search\")\n",
    "predictions_sampling = get_predictions_cached(sample_questions, model,\n",
    "                                              character_dict[character]['prediction_filename'] + '_sampling.json',\n",
    "                                              \"Sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_for_metrics(data_test, predictions_greedy, predictions_nbeams, predictions_sampling):\n",
    "    i = 0\n",
    "    df = {'ctx':[], 'ctx_tk':[]}\n",
    "    has_labels = 'response' in data_test.features\n",
    "    if has_labels:\n",
    "        df['lbl'] = []\n",
    "        df['lbl_tk'] = []\n",
    "    if predictions_greedy:\n",
    "        df['prd_greedy'] = []\n",
    "        df['prd_greedy_tk'] = []\n",
    "    if predictions_nbeams:\n",
    "        df['prd_nbeams'] = []\n",
    "        df['prd_nbeams_tk'] = [] \n",
    "    if predictions_sampling:\n",
    "        df['prd_sampling'] = []\n",
    "        df['prd_sampling_tk'] = []\n",
    "    for sample in tqdm(data_test):\n",
    "        # encode the context and label sentences, add the eos_token and return a tensor\n",
    "        ctx_tk = tokenizer.encode(sample['context'] + tokenizer.eos_token, return_tensors='tf').numpy().tolist()\n",
    "        ctx = sample['context']\n",
    "        df['ctx_tk'].append(ctx_tk)\n",
    "        df['ctx'].append(ctx)\n",
    "        if has_labels:\n",
    "            lbl_tk = tokenizer.encode(sample['response'] + tokenizer.eos_token, return_tensors='tf').numpy().tolist()\n",
    "            lbl = sample['response']\n",
    "            df['lbl'].append(lbl)\n",
    "            df['lbl_tk'].append(lbl_tk)\n",
    "        if predictions_greedy:\n",
    "            prd_greedy_tk = predictions_greedy[i]\n",
    "            prd_greedy = tokenizer.decode(prd_greedy_tk, skip_special_tokens=True)\n",
    "            df['prd_greedy'].append(prd_greedy)\n",
    "            df['prd_greedy_tk'].append(prd_greedy_tk)\n",
    "        if predictions_nbeams:\n",
    "            prd_nbeams_tk = predictions_nbeams[i]\n",
    "            prd_nbeams = tokenizer.decode(prd_nbeams_tk, skip_special_tokens=True)\n",
    "            df['prd_nbeams'].append(prd_nbeams)\n",
    "            df['prd_nbeams_tk'].append(prd_nbeams_tk)\n",
    "        if predictions_sampling:\n",
    "            prd_sampling_tk = predictions_sampling[i]\n",
    "            prd_sampling = tokenizer.decode(prd_sampling_tk, skip_special_tokens=True)\n",
    "            df['prd_sampling'].append(prd_sampling)\n",
    "            df['prd_sampling_tk'].append(prd_sampling_tk)\n",
    "        i += 1\n",
    "    return pd.DataFrame(data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 105.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ctx</th>\n",
       "      <th>ctx_tk</th>\n",
       "      <th>lbl</th>\n",
       "      <th>lbl_tk</th>\n",
       "      <th>prd_greedy</th>\n",
       "      <th>prd_greedy_tk</th>\n",
       "      <th>prd_nbeams</th>\n",
       "      <th>prd_nbeams_tk</th>\n",
       "      <th>prd_sampling</th>\n",
       "      <th>prd_sampling_tk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I will not fight you.</td>\n",
       "      <td>[[40, 481, 407, 1907, 345, 13, 50256]]</td>\n",
       "      <td>Give yourself to the dark side. It is the only...</td>\n",
       "      <td>[[23318, 3511, 284, 262, 3223, 1735, 13, 632, ...</td>\n",
       "      <td>I will not fight you, father.</td>\n",
       "      <td>[40, 481, 407, 1907, 345, 11, 2988, 13, 50256]</td>\n",
       "      <td>I will not fight you, father.</td>\n",
       "      <td>[40, 481, 407, 1907, 345, 11, 2988, 13, 50256]</td>\n",
       "      <td>You cannot make me destroy you.</td>\n",
       "      <td>[1639, 2314, 787, 502, 4117, 345, 13, 50256]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unlock one-five-seven and nine.Release charges.</td>\n",
       "      <td>[[3118, 5354, 530, 12, 13261, 12, 26548, 290, ...</td>\n",
       "      <td>Did you find any droids?</td>\n",
       "      <td>[[11633, 345, 1064, 597, 3102, 2340, 30, 50256]]</td>\n",
       "      <td>Three Imperial TIE ships, one armed, and ready...</td>\n",
       "      <td>[12510, 11773, 309, 10008, 7937, 11, 530, 6936...</td>\n",
       "      <td>Three Imperial TIE ships, one armed, and ready...</td>\n",
       "      <td>[12510, 11773, 309, 10008, 7937, 11, 530, 6936...</td>\n",
       "      <td>Vader calmly adjusts his control sticks as the...</td>\n",
       "      <td>[53, 5067, 30180, 46094, 465, 1630, 16461, 355...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lord Vader, what about Leia and theWookiee?</td>\n",
       "      <td>[[22438, 27403, 11, 644, 546, 41212, 290, 262,...</td>\n",
       "      <td>They must never again leave thiscity.</td>\n",
       "      <td>[[2990, 1276, 1239, 757, 2666, 428, 19205, 13,...</td>\n",
       "      <td>Yes, my lord.</td>\n",
       "      <td>[5297, 11, 616, 15876, 13, 50256]</td>\n",
       "      <td>Yes, my lord.</td>\n",
       "      <td>[5297, 11, 616, 15876, 13, 50256]</td>\n",
       "      <td>The Senate will discuss this issue further.</td>\n",
       "      <td>[464, 3845, 481, 2112, 428, 2071, 2252, 13, 50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No!</td>\n",
       "      <td>[[2949, 0, 50256]]</td>\n",
       "      <td>All to easy. Perhaps you are not as strong as ...</td>\n",
       "      <td>[[3237, 284, 2562, 13, 8673, 345, 389, 407, 35...</td>\n",
       "      <td>No!</td>\n",
       "      <td>[2949, 0, 50256]</td>\n",
       "      <td>No!</td>\n",
       "      <td>[2949, 0, 50256]</td>\n",
       "      <td>Yes, Admiral.</td>\n",
       "      <td>[5297, 11, 24646, 13, 50256]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Give yourself to the dark side. It is the only...</td>\n",
       "      <td>[[23318, 3511, 284, 262, 3223, 1735, 13, 632, ...</td>\n",
       "      <td>Sister! So...you have a twinsister. Your feeli...</td>\n",
       "      <td>[[50, 1694, 0, 1406, 986, 5832, 423, 257, 2034...</td>\n",
       "      <td>I am your father.</td>\n",
       "      <td>[40, 716, 534, 2988, 13, 50256]</td>\n",
       "      <td>I am your father.</td>\n",
       "      <td>[40, 716, 534, 2988, 13, 50256]</td>\n",
       "      <td>I can't stop.</td>\n",
       "      <td>[40, 460, 470, 2245, 13, 50256]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Open the blast doors! Open theblast doors!</td>\n",
       "      <td>[[11505, 262, 11975, 8215, 0, 4946, 262, 39806...</td>\n",
       "      <td>I've been waiting for you, Obi-Wan. We meet ag...</td>\n",
       "      <td>[[40, 1053, 587, 4953, 329, 345, 11, 46662, 12...</td>\n",
       "      <td>The Force is with you, Skywalker.</td>\n",
       "      <td>[464, 5221, 318, 351, 345, 11, 29715, 13, 50256]</td>\n",
       "      <td>The Force is with you, Skywalker.</td>\n",
       "      <td>[464, 5221, 318, 351, 345, 11, 29715, 13, 50256]</td>\n",
       "      <td>You'll be</td>\n",
       "      <td>[1639, 1183, 307, 50256]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Strange, that I have not. I wonder if your fee...</td>\n",
       "      <td>[[38114, 11, 326, 314, 423, 407, 13, 314, 4240...</td>\n",
       "      <td>They are clear, my Master.</td>\n",
       "      <td>[[2990, 389, 1598, 11, 616, 5599, 13, 50256]]</td>\n",
       "      <td>I have felt it.</td>\n",
       "      <td>[40, 423, 2936, 340, 13, 50256]</td>\n",
       "      <td>I have felt it.</td>\n",
       "      <td>[40, 423, 2936, 340, 13, 50256]</td>\n",
       "      <td>As you wish.</td>\n",
       "      <td>[1722, 345, 4601, 13, 50256]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Vader's targeting computer swings around into ...</td>\n",
       "      <td>[[53, 5067, 338, 10822, 3644, 26728, 1088, 656...</td>\n",
       "      <td>I have you now.</td>\n",
       "      <td>[[40, 423, 345, 783, 13, 50256]]</td>\n",
       "      <td>Vader adjusts his control stick as the stars w...</td>\n",
       "      <td>[53, 5067, 46094, 465, 1630, 4859, 355, 262, 5...</td>\n",
       "      <td>Vader adjusts his control stick as the stars w...</td>\n",
       "      <td>[53, 5067, 46094, 465, 1630, 4859, 355, 262, 5...</td>\n",
       "      <td>Vader adjusts his control stick and adjusts hi...</td>\n",
       "      <td>[53, 5067, 46094, 465, 1630, 4859, 290, 46094,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Emperor's coming here?</td>\n",
       "      <td>[[464, 10851, 338, 2406, 994, 30, 50256]]</td>\n",
       "      <td>That is correct, Commander. And heis most disp...</td>\n",
       "      <td>[[2504, 318, 3376, 11, 13353, 13, 843, 339, 27...</td>\n",
       "      <td>Yes, my lord.</td>\n",
       "      <td>[5297, 11, 616, 15876, 13, 50256]</td>\n",
       "      <td>Yes, my lord.</td>\n",
       "      <td>[5297, 11, 616, 15876, 13, 50256]</td>\n",
       "      <td>You know what they say about a man with two li...</td>\n",
       "      <td>[1639, 760, 644, 484, 910, 546, 257, 582, 351,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The princess! Put all sections onalert!</td>\n",
       "      <td>[[464, 21752, 0, 5930, 477, 9004, 319, 44598, ...</td>\n",
       "      <td>Obi-Wan is here. The Force is withhim.</td>\n",
       "      <td>[[5944, 72, 12, 45681, 318, 994, 13, 383, 5221...</td>\n",
       "      <td>The Millennium Falcon lifts gracefully into th...</td>\n",
       "      <td>[464, 26139, 17621, 27103, 11542, 2759, 656, 2...</td>\n",
       "      <td>The Millennium Falcon lifts gracefully into th...</td>\n",
       "      <td>[464, 26139, 17621, 27103, 11542, 2759, 656, 2...</td>\n",
       "      <td>Skywalker, what is it?</td>\n",
       "      <td>[22308, 20783, 11, 644, 318, 340, 30, 50256]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Good.Use your aggressivefeelings, boy!Let the ...</td>\n",
       "      <td>[[10248, 13, 11041, 534, 8361, 36410, 654, 11,...</td>\n",
       "      <td>Obi-Wan has taught you well.</td>\n",
       "      <td>[[5944, 72, 12, 45681, 468, 7817, 345, 880, 13...</td>\n",
       "      <td>I sense a disturbance in theForce.</td>\n",
       "      <td>[40, 2565, 257, 30497, 287, 262, 10292, 13, 50...</td>\n",
       "      <td>I sense a disturbance in theForce.</td>\n",
       "      <td>[40, 2565, 257, 30497, 287, 262, 10292, 13, 50...</td>\n",
       "      <td>Heheheh, I wish you well. I will not fight you...</td>\n",
       "      <td>[1544, 258, 258, 71, 11, 314, 4601, 345, 880, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Surely he must be dead by now.</td>\n",
       "      <td>[[19457, 306, 339, 1276, 307, 2636, 416, 783, ...</td>\n",
       "      <td>Don't underestimate the power ofthe Force.</td>\n",
       "      <td>[[3987, 470, 34994, 262, 1176, 286, 1169, 5221...</td>\n",
       "      <td>He's a real trooper.</td>\n",
       "      <td>[1544, 338, 257, 1103, 41967, 13, 50256]</td>\n",
       "      <td>He's a real trooper.</td>\n",
       "      <td>[1544, 338, 257, 1103, 41967, 13, 50256]</td>\n",
       "      <td>It must be true, my lord.</td>\n",
       "      <td>[1026, 1276, 307, 2081, 11, 616, 15876, 13, 50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Shall I hold them?</td>\n",
       "      <td>[[2484, 439, 314, 1745, 606, 30, 50256]]</td>\n",
       "      <td>No. Leave them to me. I will deal</td>\n",
       "      <td>[[2949, 13, 17446, 606, 284, 502, 13, 314, 481...</td>\n",
       "      <td>Yes, my lord.</td>\n",
       "      <td>[5297, 11, 616, 15876, 13, 50256]</td>\n",
       "      <td>Yes, my lord.</td>\n",
       "      <td>[5297, 11, 616, 15876, 13, 50256]</td>\n",
       "      <td>Oh, Lord Vader.</td>\n",
       "      <td>[5812, 11, 4453, 27403, 13, 50256]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What if he doesn't survive? He's worth a lot t...</td>\n",
       "      <td>[[2061, 611, 339, 1595, 470, 7866, 30, 679, 33...</td>\n",
       "      <td>The Empire will compensate you if he dies. Put...</td>\n",
       "      <td>[[464, 8065, 481, 21392, 345, 611, 339, 10564,...</td>\n",
       "      <td>If he survives the next round, he may be of so...</td>\n",
       "      <td>[1532, 339, 36417, 262, 1306, 2835, 11, 339, 7...</td>\n",
       "      <td>If he survives the next round, he may be of so...</td>\n",
       "      <td>[1532, 339, 36417, 262, 1306, 2835, 11, 339, 7...</td>\n",
       "      <td>What if he does survive?</td>\n",
       "      <td>[2061, 611, 339, 857, 7866, 30, 50256]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Then you must go to the Sanctuary</td>\n",
       "      <td>[[6423, 345, 1276, 467, 284, 262, 27036, 50256]]</td>\n",
       "      <td>He will come to me?</td>\n",
       "      <td>[[1544, 481, 1282, 284, 502, 30, 50256]]</td>\n",
       "      <td>I have foreseen this.</td>\n",
       "      <td>[40, 423, 1674, 15898, 428, 13, 50256]</td>\n",
       "      <td>I have foreseen this.</td>\n",
       "      <td>[40, 423, 1674, 15898, 428, 13, 50256]</td>\n",
       "      <td>Yes, my lord.</td>\n",
       "      <td>[5297, 11, 616, 15876, 13, 50256]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Are you sure?</td>\n",
       "      <td>[[8491, 345, 1654, 30, 50256]]</td>\n",
       "      <td>I have felt him, my Master.</td>\n",
       "      <td>[[40, 423, 2936, 683, 11, 616, 5599, 13, 50256]]</td>\n",
       "      <td>Yes, my lord.</td>\n",
       "      <td>[5297, 11, 616, 15876, 13, 50256]</td>\n",
       "      <td>Yes, my lord.</td>\n",
       "      <td>[5297, 11, 616, 15876, 13, 50256]</td>\n",
       "      <td>What is thy bidding, my Master?</td>\n",
       "      <td>[2061, 318, 11906, 23829, 11, 616, 5599, 30, 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ctx  \\\n",
       "0                               I will not fight you.   \n",
       "1     Unlock one-five-seven and nine.Release charges.   \n",
       "2         Lord Vader, what about Leia and theWookiee?   \n",
       "3                                                 No!   \n",
       "4   Give yourself to the dark side. It is the only...   \n",
       "5          Open the blast doors! Open theblast doors!   \n",
       "6   Strange, that I have not. I wonder if your fee...   \n",
       "7   Vader's targeting computer swings around into ...   \n",
       "8                          The Emperor's coming here?   \n",
       "9             The princess! Put all sections onalert!   \n",
       "10  Good.Use your aggressivefeelings, boy!Let the ...   \n",
       "11                     Surely he must be dead by now.   \n",
       "12                                 Shall I hold them?   \n",
       "13  What if he doesn't survive? He's worth a lot t...   \n",
       "14                  Then you must go to the Sanctuary   \n",
       "15                                      Are you sure?   \n",
       "\n",
       "                                               ctx_tk  \\\n",
       "0              [[40, 481, 407, 1907, 345, 13, 50256]]   \n",
       "1   [[3118, 5354, 530, 12, 13261, 12, 26548, 290, ...   \n",
       "2   [[22438, 27403, 11, 644, 546, 41212, 290, 262,...   \n",
       "3                                  [[2949, 0, 50256]]   \n",
       "4   [[23318, 3511, 284, 262, 3223, 1735, 13, 632, ...   \n",
       "5   [[11505, 262, 11975, 8215, 0, 4946, 262, 39806...   \n",
       "6   [[38114, 11, 326, 314, 423, 407, 13, 314, 4240...   \n",
       "7   [[53, 5067, 338, 10822, 3644, 26728, 1088, 656...   \n",
       "8           [[464, 10851, 338, 2406, 994, 30, 50256]]   \n",
       "9   [[464, 21752, 0, 5930, 477, 9004, 319, 44598, ...   \n",
       "10  [[10248, 13, 11041, 534, 8361, 36410, 654, 11,...   \n",
       "11  [[19457, 306, 339, 1276, 307, 2636, 416, 783, ...   \n",
       "12           [[2484, 439, 314, 1745, 606, 30, 50256]]   \n",
       "13  [[2061, 611, 339, 1595, 470, 7866, 30, 679, 33...   \n",
       "14   [[6423, 345, 1276, 467, 284, 262, 27036, 50256]]   \n",
       "15                     [[8491, 345, 1654, 30, 50256]]   \n",
       "\n",
       "                                                  lbl  \\\n",
       "0   Give yourself to the dark side. It is the only...   \n",
       "1                            Did you find any droids?   \n",
       "2               They must never again leave thiscity.   \n",
       "3   All to easy. Perhaps you are not as strong as ...   \n",
       "4   Sister! So...you have a twinsister. Your feeli...   \n",
       "5   I've been waiting for you, Obi-Wan. We meet ag...   \n",
       "6                          They are clear, my Master.   \n",
       "7                                     I have you now.   \n",
       "8   That is correct, Commander. And heis most disp...   \n",
       "9              Obi-Wan is here. The Force is withhim.   \n",
       "10                       Obi-Wan has taught you well.   \n",
       "11         Don't underestimate the power ofthe Force.   \n",
       "12                  No. Leave them to me. I will deal   \n",
       "13  The Empire will compensate you if he dies. Put...   \n",
       "14                                He will come to me?   \n",
       "15                        I have felt him, my Master.   \n",
       "\n",
       "                                               lbl_tk  \\\n",
       "0   [[23318, 3511, 284, 262, 3223, 1735, 13, 632, ...   \n",
       "1    [[11633, 345, 1064, 597, 3102, 2340, 30, 50256]]   \n",
       "2   [[2990, 1276, 1239, 757, 2666, 428, 19205, 13,...   \n",
       "3   [[3237, 284, 2562, 13, 8673, 345, 389, 407, 35...   \n",
       "4   [[50, 1694, 0, 1406, 986, 5832, 423, 257, 2034...   \n",
       "5   [[40, 1053, 587, 4953, 329, 345, 11, 46662, 12...   \n",
       "6       [[2990, 389, 1598, 11, 616, 5599, 13, 50256]]   \n",
       "7                    [[40, 423, 345, 783, 13, 50256]]   \n",
       "8   [[2504, 318, 3376, 11, 13353, 13, 843, 339, 27...   \n",
       "9   [[5944, 72, 12, 45681, 318, 994, 13, 383, 5221...   \n",
       "10  [[5944, 72, 12, 45681, 468, 7817, 345, 880, 13...   \n",
       "11  [[3987, 470, 34994, 262, 1176, 286, 1169, 5221...   \n",
       "12  [[2949, 13, 17446, 606, 284, 502, 13, 314, 481...   \n",
       "13  [[464, 8065, 481, 21392, 345, 611, 339, 10564,...   \n",
       "14           [[1544, 481, 1282, 284, 502, 30, 50256]]   \n",
       "15   [[40, 423, 2936, 683, 11, 616, 5599, 13, 50256]]   \n",
       "\n",
       "                                           prd_greedy  \\\n",
       "0                       I will not fight you, father.   \n",
       "1   Three Imperial TIE ships, one armed, and ready...   \n",
       "2                                       Yes, my lord.   \n",
       "3                                                 No!   \n",
       "4                                   I am your father.   \n",
       "5                   The Force is with you, Skywalker.   \n",
       "6                                     I have felt it.   \n",
       "7   Vader adjusts his control stick as the stars w...   \n",
       "8                                       Yes, my lord.   \n",
       "9   The Millennium Falcon lifts gracefully into th...   \n",
       "10                 I sense a disturbance in theForce.   \n",
       "11                               He's a real trooper.   \n",
       "12                                      Yes, my lord.   \n",
       "13  If he survives the next round, he may be of so...   \n",
       "14                              I have foreseen this.   \n",
       "15                                      Yes, my lord.   \n",
       "\n",
       "                                        prd_greedy_tk  \\\n",
       "0      [40, 481, 407, 1907, 345, 11, 2988, 13, 50256]   \n",
       "1   [12510, 11773, 309, 10008, 7937, 11, 530, 6936...   \n",
       "2                   [5297, 11, 616, 15876, 13, 50256]   \n",
       "3                                    [2949, 0, 50256]   \n",
       "4                     [40, 716, 534, 2988, 13, 50256]   \n",
       "5    [464, 5221, 318, 351, 345, 11, 29715, 13, 50256]   \n",
       "6                     [40, 423, 2936, 340, 13, 50256]   \n",
       "7   [53, 5067, 46094, 465, 1630, 4859, 355, 262, 5...   \n",
       "8                   [5297, 11, 616, 15876, 13, 50256]   \n",
       "9   [464, 26139, 17621, 27103, 11542, 2759, 656, 2...   \n",
       "10  [40, 2565, 257, 30497, 287, 262, 10292, 13, 50...   \n",
       "11           [1544, 338, 257, 1103, 41967, 13, 50256]   \n",
       "12                  [5297, 11, 616, 15876, 13, 50256]   \n",
       "13  [1532, 339, 36417, 262, 1306, 2835, 11, 339, 7...   \n",
       "14             [40, 423, 1674, 15898, 428, 13, 50256]   \n",
       "15                  [5297, 11, 616, 15876, 13, 50256]   \n",
       "\n",
       "                                           prd_nbeams  \\\n",
       "0                       I will not fight you, father.   \n",
       "1   Three Imperial TIE ships, one armed, and ready...   \n",
       "2                                       Yes, my lord.   \n",
       "3                                                 No!   \n",
       "4                                   I am your father.   \n",
       "5                   The Force is with you, Skywalker.   \n",
       "6                                     I have felt it.   \n",
       "7   Vader adjusts his control stick as the stars w...   \n",
       "8                                       Yes, my lord.   \n",
       "9   The Millennium Falcon lifts gracefully into th...   \n",
       "10                 I sense a disturbance in theForce.   \n",
       "11                               He's a real trooper.   \n",
       "12                                      Yes, my lord.   \n",
       "13  If he survives the next round, he may be of so...   \n",
       "14                              I have foreseen this.   \n",
       "15                                      Yes, my lord.   \n",
       "\n",
       "                                        prd_nbeams_tk  \\\n",
       "0      [40, 481, 407, 1907, 345, 11, 2988, 13, 50256]   \n",
       "1   [12510, 11773, 309, 10008, 7937, 11, 530, 6936...   \n",
       "2                   [5297, 11, 616, 15876, 13, 50256]   \n",
       "3                                    [2949, 0, 50256]   \n",
       "4                     [40, 716, 534, 2988, 13, 50256]   \n",
       "5    [464, 5221, 318, 351, 345, 11, 29715, 13, 50256]   \n",
       "6                     [40, 423, 2936, 340, 13, 50256]   \n",
       "7   [53, 5067, 46094, 465, 1630, 4859, 355, 262, 5...   \n",
       "8                   [5297, 11, 616, 15876, 13, 50256]   \n",
       "9   [464, 26139, 17621, 27103, 11542, 2759, 656, 2...   \n",
       "10  [40, 2565, 257, 30497, 287, 262, 10292, 13, 50...   \n",
       "11           [1544, 338, 257, 1103, 41967, 13, 50256]   \n",
       "12                  [5297, 11, 616, 15876, 13, 50256]   \n",
       "13  [1532, 339, 36417, 262, 1306, 2835, 11, 339, 7...   \n",
       "14             [40, 423, 1674, 15898, 428, 13, 50256]   \n",
       "15                  [5297, 11, 616, 15876, 13, 50256]   \n",
       "\n",
       "                                         prd_sampling  \\\n",
       "0                     You cannot make me destroy you.   \n",
       "1   Vader calmly adjusts his control sticks as the...   \n",
       "2         The Senate will discuss this issue further.   \n",
       "3                                       Yes, Admiral.   \n",
       "4                                       I can't stop.   \n",
       "5                                           You'll be   \n",
       "6                                        As you wish.   \n",
       "7   Vader adjusts his control stick and adjusts hi...   \n",
       "8   You know what they say about a man with two li...   \n",
       "9                              Skywalker, what is it?   \n",
       "10  Heheheh, I wish you well. I will not fight you...   \n",
       "11                          It must be true, my lord.   \n",
       "12                                    Oh, Lord Vader.   \n",
       "13                           What if he does survive?   \n",
       "14                                      Yes, my lord.   \n",
       "15                    What is thy bidding, my Master?   \n",
       "\n",
       "                                      prd_sampling_tk  \n",
       "0        [1639, 2314, 787, 502, 4117, 345, 13, 50256]  \n",
       "1   [53, 5067, 30180, 46094, 465, 1630, 16461, 355...  \n",
       "2   [464, 3845, 481, 2112, 428, 2071, 2252, 13, 50...  \n",
       "3                        [5297, 11, 24646, 13, 50256]  \n",
       "4                     [40, 460, 470, 2245, 13, 50256]  \n",
       "5                            [1639, 1183, 307, 50256]  \n",
       "6                        [1722, 345, 4601, 13, 50256]  \n",
       "7   [53, 5067, 46094, 465, 1630, 4859, 290, 46094,...  \n",
       "8   [1639, 760, 644, 484, 910, 546, 257, 582, 351,...  \n",
       "9        [22308, 20783, 11, 644, 318, 340, 30, 50256]  \n",
       "10  [1544, 258, 258, 71, 11, 314, 4601, 345, 880, ...  \n",
       "11  [1026, 1276, 307, 2081, 11, 616, 15876, 13, 50...  \n",
       "12                 [5812, 11, 4453, 27403, 13, 50256]  \n",
       "13             [2061, 611, 339, 857, 7866, 30, 50256]  \n",
       "14                  [5297, 11, 616, 15876, 13, 50256]  \n",
       "15  [2061, 318, 11906, 23829, 11, 616, 5599, 30, 5...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_char = get_dataframe_for_metrics(character_hg['test'], predictions_greedy, predictions_nbeams, predictions_sampling)\n",
    "df_char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics For Character 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ccl_sim(ctx_lbl, ctx_cht, lbl_cht):\n",
    "    return ((1 - abs(ctx_lbl - ctx_cht))**2 + lbl_cht**2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Lib.BBMetrics import BBMetric\n",
    "\n",
    "def compute_set_metrics(model, model_2, character, character_2, test_set_name,\n",
    "                        context_sentences, label_responses, chatbot_responses, encoded_test_set,\n",
    "                        classifier_n_sentences=50, label_chatbot_symmetry=False,\n",
    "                        include_qualitative_sentences=False, verbose=True):\n",
    "    scores = {}\n",
    "    \n",
    "    lbl_text = 'label' if not label_chatbot_symmetry else 'chatbota'\n",
    "    cht_text = 'chatbot' if not label_chatbot_symmetry else 'chatbotb'\n",
    "    \n",
    "    scores['metadata'] = {}\n",
    "    scores['metadata']['dataset name'] = test_set_name\n",
    "    scores['metadata']['names'] = {\n",
    "        'context':'context'\n",
    "    }\n",
    "    if label_chatbot_symmetry:\n",
    "        scores['metadata']['names'][lbl_text] = character\n",
    "        scores['metadata']['names'][cht_text] = character_2\n",
    "    else:\n",
    "        scores['metadata']['names'][lbl_text] = 'label'\n",
    "        scores['metadata']['names'][cht_text] = character\n",
    "    \n",
    "    # 0) computes metrics for perplexity\n",
    "    metric = BBMetric.load_metric(\"semantic similarity\")\n",
    "    scores['semantic similarity'] = [metric.compute(sentences_a=context_sentences,\n",
    "                                            sentences_b=label_responses)]\n",
    "    scores['semantic similarity'].append(metric.compute(sentences_a=context_sentences,\n",
    "                                            sentences_b=chatbot_responses)),\n",
    "    scores['semantic similarity'].append(metric.compute(sentences_a=label_responses,\n",
    "                                              sentences_b=chatbot_responses))\n",
    "    scores['semantic similarity'].append(ccl_sim(scores['semantic similarity'][0]['score'],\n",
    "                                                 scores['semantic similarity'][1]['score'],\n",
    "                                                 scores['semantic similarity'][2]['score']))\n",
    "    scores['metadata']['semantic similarity'] = {\n",
    "        'ordering': ['context-'+lbl_text, 'context-'+cht_text, cht_text+'-'+lbl_text, 'ccl']\n",
    "    }\n",
    "    if verbose:\n",
    "        print('=== SEMANTIC SIMILARITY ===')\n",
    "        print('context-'+lbl_text+' similarity:   ', scores['semantic similarity'][0])\n",
    "        print('context-'+cht_text+' similarity: ', scores['semantic similarity'][1])\n",
    "        print(cht_text+'-'+lbl_text+' similarity:   ', scores['semantic similarity'][2])\n",
    "        print('ccl-sim similarity:            ', scores['semantic similarity'][3])\n",
    "    # 1) computes metrics for perplexity\n",
    "    if encoded_test_set is not None:\n",
    "        metric = BBMetric.load_metric(\"perplexity\")\n",
    "        if not label_chatbot_symmetry:\n",
    "            scores['perplexity'] = metric.compute(model=model, encoded_test_set=encoded_test_set)['score']\n",
    "            scores['metadata']['perplexity'] = {\n",
    "                'ordering': cht_text\n",
    "            }\n",
    "        else:\n",
    "            scores['perplexity'] = [metric.compute(model=model, encoded_test_set=encoded_test_set)['score']]\n",
    "            scores['perplexity'].append(metric.compute(model=model_2, encoded_test_set=encoded_test_set)['score'])\n",
    "            scores['metadata']['perplexity'] = {\n",
    "                'ordering': [lbl_text, cht_text]\n",
    "            }\n",
    "        if verbose:\n",
    "            print('===       PERPLEXITY     ===')\n",
    "            if label_chatbot_symmetry:\n",
    "                print(lbl_text + ' perplexity:         ', scores['perplexity'][0])\n",
    "                print(cht_text + ' perplexity:         ', scores['perplexity'][1])\n",
    "            else:\n",
    "                print(cht_text + ' perplexity:         ', scores['perplexity'])\n",
    "    elif verbose:\n",
    "        print(\"encoded_test_set not provided, skipping Perplexity.\")\n",
    "    # 2) computes metrics for bleu\n",
    "    metric = BBMetric.load_metric(\"bleu\")\n",
    "    scores['bleu'] = [metric.compute(predictions=label_responses, references=context_sentences)]\n",
    "    scores['bleu'].append(metric.compute(predictions=chatbot_responses, references=context_sentences))\n",
    "    scores['bleu'].append(metric.compute(predictions=chatbot_responses, references=label_responses))\n",
    "    scores['bleu'].append(ccl_sim(scores['bleu'][0]['score'],\n",
    "                                  scores['bleu'][1]['score'],\n",
    "                                  scores['bleu'][2]['score']))\n",
    "    scores['metadata']['bleu'] = {\n",
    "        'ordering': ['context-'+lbl_text, 'context-'+cht_text, cht_text+'-'+lbl_text, 'ccl']\n",
    "    }\n",
    "    if verbose:\n",
    "        print('===         BLEU         ===')\n",
    "        print('context-to-'+lbl_text+' bleu:      ', scores['bleu'][0])\n",
    "        print('context-to-'+cht_text+' bleu:    ', scores['bleu'][1])\n",
    "        print(lbl_text+'-to-'+cht_text+' bleu:      ', scores['bleu'][2])\n",
    "        print('ccl-sim bleu:            ', scores['bleu'][3])\n",
    "    # 3) computes metrics for rouge-L\n",
    "    metric = BBMetric.load_metric(\"rouge l\")\n",
    "    scores['rouge l'] = [metric.compute(predictions=label_responses, references=context_sentences)]\n",
    "    scores['rouge l'].append(metric.compute(predictions=chatbot_responses, references=context_sentences))\n",
    "    scores['rouge l'].append(metric.compute(predictions=chatbot_responses, references=label_responses))\n",
    "    scores['rouge l'].append(ccl_sim(scores['rouge l'][0]['score'],\n",
    "                                     scores['rouge l'][1]['score'],\n",
    "                                     scores['rouge l'][2]['score']))\n",
    "    scores['metadata']['rouge l'] = {\n",
    "        'ordering': ['context-'+lbl_text, 'context-'+cht_text, cht_text+'-'+lbl_text, 'ccl']\n",
    "    }\n",
    "    if verbose:\n",
    "        print('===        ROUGE-L       ===')\n",
    "        print('context-to-'+lbl_text+' rouge:     ', scores['rouge l'][0])\n",
    "        print('context-to-'+cht_text+' rouge:   ', scores['rouge l'][1])\n",
    "        print(lbl_text+'-to-'+cht_text+' rouge:     ', scores['rouge l'][2])\n",
    "        print('ccl-sim rouge:            ', scores['rouge l'][3])\n",
    "    # 4) computes metrics for distinct\n",
    "    metric = BBMetric.load_metric(\"distinct\")\n",
    "    scores['distinct'] = [metric.compute(sentences=context_sentences)]\n",
    "    scores['distinct'].append(metric.compute(sentences=label_responses))\n",
    "    scores['distinct'].append(metric.compute(sentences=chatbot_responses))\n",
    "    scores['metadata']['distinct'] = {\n",
    "        'ordering': ['context', lbl_text, cht_text]\n",
    "    }\n",
    "    if verbose:\n",
    "        print('===       DISTINCT      ===')\n",
    "        print('context distinct:          ', scores['distinct'][0])\n",
    "        print(lbl_text+' distinct:          ', scores['distinct'][1])\n",
    "        print(cht_text+' distinct:          ', scores['distinct'][2])\n",
    "        \n",
    "    # 6) computes emotion metric\n",
    "    metric = BBMetric.load_metric(\"emotion\")\n",
    "    scores['emotion'] = [metric.compute(sentences=context_sentences)]\n",
    "    scores['emotion'].append(metric.compute(sentences=label_responses))\n",
    "    scores['emotion'].append(metric.compute(sentences=chatbot_responses))\n",
    "    scores['emotion'].append(sp.stats.stats.pearsonr(scores['emotion'][1]['score'],\n",
    "                                                     scores['emotion'][2]['score'])[0])\n",
    "    scores['metadata']['emotion'] = {\n",
    "        'ordering': ['context-'+lbl_text, 'context-'+cht_text, cht_text+'-'+lbl_text, cht_text+'-'+lbl_text+' correlation']\n",
    "    }\n",
    "    if verbose:\n",
    "        print('===       EMOTION       ===')\n",
    "        print('context emotions:            \\n', list(zip(scores['emotion'][0]['label'], scores['emotion'][0]['score'])))\n",
    "        print(lbl_text+' emotions:              \\n', list(zip(scores['emotion'][1]['label'], scores['emotion'][1]['score'])))\n",
    "        print(cht_text+' emotions:            \\n', list(zip(scores['emotion'][2]['label'], scores['emotion'][2]['score'])))\n",
    "        print(lbl_text+'-'+cht_text+'emotion corr:  \\n', scores['emotion'][3])\n",
    "    # 8) computes sas metric\n",
    "    metric = BBMetric.load_metric(\"semantic answer similarity\")\n",
    "    scores['semantic answer similarity'] = [metric.compute(predictions=context_sentences,\n",
    "                                                    references=label_responses)]\n",
    "    scores['semantic answer similarity'].append(metric.compute(predictions=context_sentences,\n",
    "                                                        references=chatbot_responses))\n",
    "    scores['semantic answer similarity'].append(metric.compute(predictions=label_responses,\n",
    "                                                        references=chatbot_responses))\n",
    "    scores['semantic answer similarity'].append(ccl_sim(scores['semantic answer similarity'][0]['score'],\n",
    "                                                        scores['semantic answer similarity'][1]['score'],\n",
    "                                                        scores['semantic answer similarity'][2]['score']))\n",
    "    scores['metadata']['semantic answer similarity'] = {\n",
    "        'ordering': ['context-'+lbl_text, 'context-'+cht_text, cht_text+'-'+lbl_text, 'ccl']\n",
    "    }\n",
    "    if verbose:\n",
    "        print('===         SAS         ===')\n",
    "        print('context-'+lbl_text+' sas:          ', scores['semantic answer similarity'][0])\n",
    "        print('context-'+cht_text+' sas:        ', scores['semantic answer similarity'][1])\n",
    "        print(lbl_text+'-'+cht_text+' sas:          ', scores['semantic answer similarity'][2])\n",
    "        print('ccl-sim sas:               ', scores['semantic answer similarity'][3])\n",
    "    # 9) computes metrics for semantic classifier\n",
    "    metric = BBMetric.load_metric(\"semantic classifier\")\n",
    "    start_time = time.time()\n",
    "    scores['semantic classifier'] = [metric.compute(character=character, character_dict=character_dict, \n",
    "                                                   base_folder=base_folder, sentences=label_responses,\n",
    "                                                   n_sentences=classifier_n_sentences)]\n",
    "    scores['semantic classifier'].append(metric.compute(character=character, character_dict=character_dict, \n",
    "                                                   base_folder=base_folder, sentences=chatbot_responses,\n",
    "                                                   n_sentences=classifier_n_sentences))\n",
    "    end_time = time.time()\n",
    "    scores['metadata']['semantic classifier'] = {\n",
    "        'ordering': [lbl_text, cht_text]\n",
    "    }\n",
    "    if verbose:\n",
    "        print('=== SEMANTIC CLASSIFIER ===')\n",
    "        print('sem-classifier '+lbl_text+':                ', scores['semantic classifier'][0])\n",
    "        print('sem-classifier '+cht_text+':                  ', scores['semantic classifier'][1])\n",
    "        print('time elapsed computing semantic classifier:  {:.2f} s'.format(end_time - start_time))\n",
    "    if not label_chatbot_symmetry and os.path.exists(os.path.join(os.getcwd(), \"Data\", \"Characters\", character, \"humancoherence.csv\")):\n",
    "        scores['human'] = {}\n",
    "        metric = BBMetric.load_metric(\"human - coherence\")\n",
    "        scores['human']['coherence'] = metric.compute(filepath=os.path.join(os.getcwd(), \"Data\", \"Characters\",\n",
    "                                                                            character, \"humancoherence.csv\"))\n",
    "        metric = BBMetric.load_metric(\"human - style\")\n",
    "        scores['human']['style'] = metric.compute(filepath=os.path.join(os.getcwd(), \"Data\", \"Characters\",\n",
    "                                                                        character, \"humanstyle.csv\"))\n",
    "        metric = BBMetric.load_metric(\"human - consistency\")\n",
    "        scores['human']['consistency'] = metric.compute(filepath=os.path.join(os.getcwd(), \"Data\", \"Characters\",\n",
    "                                                                              character, \"humanconsistency.csv\"))\n",
    "        scores['metadata']['human'] = {\n",
    "            'ordering': {\n",
    "                'coherence': cht_text,\n",
    "                'consistency': cht_text,\n",
    "                'style': cht_text\n",
    "            }\n",
    "        }\n",
    "        if verbose:\n",
    "            print('===    HUMAN METRICS    ===')\n",
    "            print('coherence:                 ', scores['human']['coherence'])\n",
    "            print('consistency:               ', scores['human']['consistency'])\n",
    "            print('style:                     ', scores['human']['style'])\n",
    "    elif verbose:\n",
    "        print(\"Symmetric mode, skipping Human metrics.\")\n",
    "    if include_qualitative_sentences:\n",
    "        sentences_df = {}\n",
    "        sentences_df['context'] = context_sentences\n",
    "        sentences_df[lbl_text] = label_responses\n",
    "        sentences_df[cht_text] = chatbot_responses\n",
    "        scores['sentences'] = sentences_df\n",
    "        if verbose:\n",
    "            print('===      SENTENCES      ===')\n",
    "            for i in range(len(context_sentences)):\n",
    "                print(\"* context: \", context_sentences[i])\n",
    "                print(\"* \" + lbl_text + \":\", label_responses[i])\n",
    "                print(\"* \" + cht_text + \":\", chatbot_responses[i])\n",
    "                print()\n",
    "    elif verbose:\n",
    "        print(\"Skipping sentence outputting.\")\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nset_size = 10\\ni = 30\\nprint(\"##### Set (Size \" + str(set_size) + \") #####\")\\ncontext_sentences = list(df_char[\\'ctx\\'][i:i+set_size])\\nchatbot_responses = list(df_char[\\'prd_greedy\\'][i:i+set_size])\\nlabel_responses   = list(df_char[\\'lbl\\'][i:i+set_size])\\ncompute_set_metrics(model, None,\\n                    context_sentences, label_responses, chatbot_responses, character, encoded_test_set)\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "set_size = 10\n",
    "i = 30\n",
    "print(\"##### Set (Size \" + str(set_size) + \") #####\")\n",
    "context_sentences = list(df_char['ctx'][i:i+set_size])\n",
    "chatbot_responses = list(df_char['prd_greedy'][i:i+set_size])\n",
    "label_responses   = list(df_char['lbl'][i:i+set_size])\n",
    "compute_set_metrics(model, None,\n",
    "                    context_sentences, label_responses, chatbot_responses, character, encoded_test_set)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Full Test Set #####\n",
      "=== SEMANTIC SIMILARITY ===\n",
      "context-label similarity:    {'score': 0.2628557085990906, 'std': 0.12331006675958633}\n",
      "context-chatbot similarity:  {'score': 0.40181735157966614, 'std': 0.2566767632961273}\n",
      "chatbot-label similarity:    {'score': 0.2893322706222534, 'std': 0.14519359171390533}\n",
      "ccl-sim similarity:             0.41255010754106936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:23<00:00, 11.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===       PERPLEXITY     ===\n",
      "chatbot perplexity:          33.07173276985397\n",
      "===         BLEU         ===\n",
      "context-to-label bleu:       {'score': 0.0}\n",
      "context-to-chatbot bleu:     {'score': 0.03550769755670245}\n",
      "label-to-chatbot bleu:       {'score': 0.0}\n",
      "ccl-sim bleu:             0.46512270073618667\n",
      "===        ROUGE-L       ===\n",
      "context-to-label rouge:      {'score': 0.07925918737060042, 'std': 0.07479345524211507}\n",
      "context-to-chatbot rouge:    {'score': 0.21360017297517297, 'std': 0.2946762597315076}\n",
      "label-to-chatbot rouge:      {'score': 0.05387724292615597, 'std': 0.07551093518685495}\n",
      "ccl-sim rouge:             0.3761341432546935\n",
      "===       DISTINCT      ===\n",
      "context distinct:           {'score': 0.114955529740867, 'std': 0.04780861208267611}\n",
      "label distinct:           {'score': 0.13947061601006405, 'std': 0.02676100873863562}\n",
      "chatbot distinct:           {'score': 0.11159705177614018, 'std': 0.044972948026574824}\n",
      "===       EMOTION       ===\n",
      "context emotions:            \n",
      " [('sadness', 0.03771195514855208), ('joy', 0.3086917221080512), ('love', 0.0028261128700250993), ('anger', 0.46144572112098103), ('fear', 0.17504404807914398), ('surprise', 0.01428041995222884)]\n",
      "label emotions:              \n",
      " [('sadness', 0.09321646651005722), ('joy', 0.49179869345789484), ('love', 0.005095468684885418), ('anger', 0.3287064012256451), ('fear', 0.07919869394390844), ('surprise', 0.001984291597182164)]\n",
      "chatbot emotions:            \n",
      " [('sadness', 0.016448179114377126), ('joy', 0.5300553089473397), ('love', 0.0160360135450901), ('anger', 0.289736112288665), ('fear', 0.14465684418973979), ('surprise', 0.003067572473810287)]\n",
      "label-chatbotemotion corr:  \n",
      " 0.9695013633619715\n",
      "===         SAS         ===\n",
      "context-label sas:           {'score': 0.06032150238752365, 'std': 0.08580299466848373}\n",
      "context-chatbot sas:         {'score': 0.19251391291618347, 'std': 0.27074262499809265}\n",
      "label-chatbot sas:           {'score': 0.07981376349925995, 'std': 0.09865930676460266}\n",
      "ccl-sim sas:                0.379730124593987\n",
      "=== SEMANTIC CLASSIFIER ===\n",
      "sem-classifier label:                 {'score': 0.9999648332595825, 'std': 1.0683184882509522e-05}\n",
      "sem-classifier chatbot:                   {'score': 0.5347053408622742, 'std': 0.4730081558227539}\n",
      "time elapsed computing semantic classifier:  21.20 s\n",
      "===    HUMAN METRICS    ===\n",
      "coherence:                  {'score': 0.5, 'std': 0.09999999999999998}\n",
      "consistency:                {'score': 0.2, 'std': 0.0}\n",
      "style:                      {'score': 0.5, 'std': 0.09999999999999998}\n",
      "Skipping sentence outputting.\n"
     ]
    }
   ],
   "source": [
    "print(\"##### Full Test Set #####\")\n",
    "context_sentences = list(df_char['ctx'])\n",
    "chatbot_responses = list(df_char['prd_greedy'])\n",
    "label_responses   = list(df_char['lbl'])\n",
    "scores = compute_set_metrics(model, None,\n",
    "                             character, None, character + \" dataset\",\n",
    "                             context_sentences, label_responses, chatbot_responses, encoded_test_set,\n",
    "                             classifier_n_sentences=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metadata': {'dataset name': 'Vader dataset', 'names': {'context': 'context', 'label': 'label', 'chatbot': 'Vader'}, 'semantic similarity': {'ordering': ['context-label', 'context-chatbot', 'chatbot-label', 'ccl']}, 'perplexity': {'ordering': 'chatbot'}, 'bleu': {'ordering': ['context-label', 'context-chatbot', 'chatbot-label', 'ccl']}, 'rouge l': {'ordering': ['context-label', 'context-chatbot', 'chatbot-label', 'ccl']}, 'distinct': {'ordering': ['context', 'label', 'chatbot']}, 'emotion': {'ordering': ['context-label', 'context-chatbot', 'chatbot-label', 'chatbot-label correlation']}, 'semantic answer similarity': {'ordering': ['context-label', 'context-chatbot', 'chatbot-label', 'ccl']}, 'semantic classifier': {'ordering': ['label', 'chatbot']}, 'human': {'ordering': {'coherence': 'chatbot', 'consistency': 'chatbot', 'style': 'chatbot'}}}, 'semantic similarity': [{'score': 0.2628557085990906, 'std': 0.12331006675958633}, {'score': 0.40181735157966614, 'std': 0.2566767632961273}, {'score': 0.2893322706222534, 'std': 0.14519359171390533}, 0.41255010754106936], 'perplexity': 33.07173276985397, 'bleu': [{'score': 0.0}, {'score': 0.03550769755670245}, {'score': 0.0}, 0.46512270073618667], 'rouge l': [{'score': 0.07925918737060042, 'std': 0.07479345524211507}, {'score': 0.21360017297517297, 'std': 0.2946762597315076}, {'score': 0.05387724292615597, 'std': 0.07551093518685495}, 0.3761341432546935], 'distinct': [{'score': 0.114955529740867, 'std': 0.04780861208267611}, {'score': 0.13947061601006405, 'std': 0.02676100873863562}, {'score': 0.11159705177614018, 'std': 0.044972948026574824}], 'emotion': [{'score': [0.03771195514855208, 0.3086917221080512, 0.0028261128700250993, 0.46144572112098103, 0.17504404807914398, 0.01428041995222884], 'std': [0.0857842436988081, 0.3690483005813959, 0.00270720452815662, 0.3735565902200007, 0.2011020820626128, 0.044105974070753715], 'label': ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']}, {'score': [0.09321646651005722, 0.49179869345789484, 0.005095468684885418, 0.3287064012256451, 0.07919869394390844, 0.001984291597182164], 'std': [0.212059906677898, 0.43783053408101197, 0.007027570354401605, 0.3781002875885105, 0.1928357173741199, 0.002424143753576649], 'label': ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']}, {'score': [0.016448179114377126, 0.5300553089473397, 0.0160360135450901, 0.289736112288665, 0.14465684418973979, 0.003067572473810287], 'std': [0.008420545061595624, 0.37152693070973103, 0.02602968526892956, 0.32900149406524193, 0.28715456984454585, 0.00172150102913216], 'label': ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']}, 0.9695013633619715], 'semantic answer similarity': [{'score': 0.06032150238752365, 'std': 0.08580299466848373}, {'score': 0.19251391291618347, 'std': 0.27074262499809265}, {'score': 0.07981376349925995, 'std': 0.09865930676460266}, 0.379730124593987], 'semantic classifier': [{'score': 0.9999648332595825, 'std': 1.0683184882509522e-05}, {'score': 0.5347053408622742, 'std': 0.4730081558227539}], 'human': {'coherence': {'score': 0.5, 'std': 0.09999999999999998}, 'style': {'score': 0.5, 'std': 0.09999999999999998}, 'consistency': {'score': 0.2, 'std': 0.0}}}\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_as_json(metrics_folder, character+'_base_metrics', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics Between Different Sampling Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Greedy vs. N-Beams #####\n",
      "=== SEMANTIC SIMILARITY ===\n",
      "context-chatbota similarity:    {'score': 0.40181735157966614, 'std': 0.2566767632961273}\n",
      "context-chatbotb similarity:  {'score': 0.40181735157966614, 'std': 0.2566767632961273}\n",
      "chatbotb-chatbota similarity:    {'score': 1.0, 'std': 1.504943440977513e-07}\n",
      "ccl-sim similarity:             1.0\n",
      "encoded_test_set not provided, skipping Perplexity.\n",
      "===         BLEU         ===\n",
      "context-to-chatbota bleu:       {'score': 0.03550769755670245}\n",
      "context-to-chatbotb bleu:     {'score': 0.03550769755670245}\n",
      "chatbota-to-chatbotb bleu:       {'score': 1.0}\n",
      "ccl-sim bleu:             1.0\n",
      "===        ROUGE-L       ===\n",
      "context-to-chatbota rouge:      {'score': 0.21360017297517297, 'std': 0.2946762597315076}\n",
      "context-to-chatbotb rouge:    {'score': 0.21360017297517297, 'std': 0.2946762597315076}\n",
      "chatbota-to-chatbotb rouge:      {'score': 1.0, 'std': 0.0}\n",
      "ccl-sim rouge:             1.0\n",
      "===       DISTINCT      ===\n",
      "context distinct:           {'score': 0.114955529740867, 'std': 0.04780861208267611}\n",
      "chatbota distinct:           {'score': 0.11159705177614018, 'std': 0.044972948026574824}\n",
      "chatbotb distinct:           {'score': 0.11159705177614018, 'std': 0.044972948026574824}\n",
      "===       EMOTION       ===\n",
      "context emotions:            \n",
      " [('sadness', 0.03771195514855208), ('joy', 0.3086917221080512), ('love', 0.0028261128700250993), ('anger', 0.46144572112098103), ('fear', 0.17504404807914398), ('surprise', 0.01428041995222884)]\n",
      "chatbota emotions:              \n",
      " [('sadness', 0.016448179114377126), ('joy', 0.5300553089473397), ('love', 0.0160360135450901), ('anger', 0.289736112288665), ('fear', 0.14465684418973979), ('surprise', 0.003067572473810287)]\n",
      "chatbotb emotions:            \n",
      " [('sadness', 0.016448179114377126), ('joy', 0.5300553089473397), ('love', 0.0160360135450901), ('anger', 0.289736112288665), ('fear', 0.14465684418973979), ('surprise', 0.003067572473810287)]\n",
      "chatbota-chatbotbemotion corr:  \n",
      " 0.9999999999999998\n",
      "===         SAS         ===\n",
      "context-chatbota sas:           {'score': 0.19251391291618347, 'std': 0.27074262499809265}\n",
      "context-chatbotb sas:         {'score': 0.19251391291618347, 'std': 0.27074262499809265}\n",
      "chatbota-chatbotb sas:           {'score': 0.9645909667015076, 'std': 0.005309408530592918}\n",
      "ccl-sim sas:                0.9652178665210744\n",
      "=== SEMANTIC CLASSIFIER ===\n",
      "sem-classifier chatbota:                 {'score': 0.5347053408622742, 'std': 0.4730081558227539}\n",
      "sem-classifier chatbotb:                   {'score': 0.5347053408622742, 'std': 0.4730081558227539}\n",
      "time elapsed computing semantic classifier:  21.22 s\n",
      "Symmetric mode, skipping Human metrics.\n",
      "Skipping sentence outputting.\n"
     ]
    }
   ],
   "source": [
    "print(\"##### Greedy vs. N-Beams #####\")\n",
    "context_sentences = list(df_char['ctx'])\n",
    "greedy_responses  = list(df_char['prd_greedy'])\n",
    "nbeams_responses  = list(df_char['prd_nbeams'])\n",
    "scores['greedy_vs_nbeams'] = compute_set_metrics(None, None,\n",
    "                                                 character, character, character + \" dataset\",\n",
    "                                                 context_sentences,\n",
    "                                                 greedy_responses,\n",
    "                                                 nbeams_responses,\n",
    "                                                 None,\n",
    "                                                 classifier_n_sentences=75, label_chatbot_symmetry=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if split == True:\n",
    "    save_as_json(metrics_folder, character+'_greedy_vs_nbeams_metrics', scores['greedy_vs_nbeams'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Greedy vs. Sampling #####\n",
      "=== SEMANTIC SIMILARITY ===\n",
      "context-chatbota similarity:    {'score': 0.40181735157966614, 'std': 0.2566767632961273}\n",
      "context-chatbotb similarity:  {'score': 0.33888429403305054, 'std': 0.21229518949985504}\n",
      "chatbotb-chatbota similarity:    {'score': 0.3886221647262573, 'std': 0.1782136857509613}\n",
      "ccl-sim similarity:             0.5145608207777284\n",
      "encoded_test_set not provided, skipping Perplexity.\n",
      "===         BLEU         ===\n",
      "context-to-chatbota bleu:       {'score': 0.03550769755670245}\n",
      "context-to-chatbotb bleu:     {'score': 0.0}\n",
      "chatbota-to-chatbotb bleu:       {'score': 0.052702392718719064}\n",
      "ccl-sim bleu:             0.4665114718353257\n",
      "===        ROUGE-L       ===\n",
      "context-to-chatbota rouge:      {'score': 0.21360017297517297, 'std': 0.2946762597315076}\n",
      "context-to-chatbotb rouge:    {'score': 0.07668026418026418, 'std': 0.12749021277296071}\n",
      "chatbota-to-chatbotb rouge:      {'score': 0.12360127080521818, 'std': 0.14261019747999726}\n",
      "ccl-sim rouge:             0.38009225898962673\n",
      "===       DISTINCT      ===\n",
      "context distinct:           {'score': 0.114955529740867, 'std': 0.04780861208267611}\n",
      "chatbota distinct:           {'score': 0.11159705177614018, 'std': 0.044972948026574824}\n",
      "chatbotb distinct:           {'score': 0.10426948523125507, 'std': 0.05160577641798607}\n",
      "===       EMOTION       ===\n",
      "context emotions:            \n",
      " [('sadness', 0.03771195514855208), ('joy', 0.3086917221080512), ('love', 0.0028261128700250993), ('anger', 0.46144572112098103), ('fear', 0.17504404807914398), ('surprise', 0.01428041995222884)]\n",
      "chatbota emotions:              \n",
      " [('sadness', 0.016448179114377126), ('joy', 0.5300553089473397), ('love', 0.0160360135450901), ('anger', 0.289736112288665), ('fear', 0.14465684418973979), ('surprise', 0.003067572473810287)]\n",
      "chatbotb emotions:            \n",
      " [('sadness', 0.04246980120660737), ('joy', 0.5643179937906098), ('love', 0.006394262331014033), ('anger', 0.2555840458080638), ('fear', 0.1273233036590682), ('surprise', 0.003910565077603678)]\n",
      "chatbota-chatbotbemotion corr:  \n",
      " 0.9930754427042098\n",
      "===         SAS         ===\n",
      "context-chatbota sas:           {'score': 0.19251391291618347, 'std': 0.27074262499809265}\n",
      "context-chatbotb sas:         {'score': 0.12086492031812668, 'std': 0.13998103141784668}\n",
      "chatbota-chatbotb sas:           {'score': 0.13670310378074646, 'std': 0.1772124171257019}\n",
      "ccl-sim sas:                0.44026166576374615\n",
      "=== SEMANTIC CLASSIFIER ===\n",
      "sem-classifier chatbota:                 {'score': 0.5347053408622742, 'std': 0.4730081558227539}\n",
      "sem-classifier chatbotb:                   {'score': 0.7992286086082458, 'std': 0.3711322546005249}\n",
      "time elapsed computing semantic classifier:  21.92 s\n",
      "Symmetric mode, skipping Human metrics.\n",
      "Skipping sentence outputting.\n"
     ]
    }
   ],
   "source": [
    "print(\"##### Greedy vs. Sampling #####\")\n",
    "context_sentences   = list(df_char['ctx'])\n",
    "greedy_responses    = list(df_char['prd_greedy'])\n",
    "sampling_responses  = list(df_char['prd_sampling'])\n",
    "scores['greedy_vs_sampling'] = compute_set_metrics(None, None,\n",
    "                                                   character, character, character + \" dataset\",\n",
    "                                                   context_sentences,\n",
    "                                                   greedy_responses,\n",
    "                                                   sampling_responses,\n",
    "                                                   None,\n",
    "                                                   classifier_n_sentences=75, label_chatbot_symmetry=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if split == True:\n",
    "    save_as_json(metrics_folder, character+'_greedy_vs_sampling_metrics', scores['greedy_vs_sampling'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### N-Beams vs. Sampling #####\n",
      "=== SEMANTIC SIMILARITY ===\n",
      "context-chatbota similarity:    {'score': 0.40181735157966614, 'std': 0.2566767632961273}\n",
      "context-chatbotb similarity:  {'score': 0.33888429403305054, 'std': 0.21229518949985504}\n",
      "chatbotb-chatbota similarity:    {'score': 0.3886221647262573, 'std': 0.1782136857509613}\n",
      "ccl-sim similarity:             0.5145608207777284\n",
      "encoded_test_set not provided, skipping Perplexity.\n",
      "===         BLEU         ===\n",
      "context-to-chatbota bleu:       {'score': 0.03550769755670245}\n",
      "context-to-chatbotb bleu:     {'score': 0.0}\n",
      "chatbota-to-chatbotb bleu:       {'score': 0.052702392718719064}\n",
      "ccl-sim bleu:             0.4665114718353257\n",
      "===        ROUGE-L       ===\n",
      "context-to-chatbota rouge:      {'score': 0.21360017297517297, 'std': 0.2946762597315076}\n",
      "context-to-chatbotb rouge:    {'score': 0.07668026418026418, 'std': 0.12749021277296071}\n",
      "chatbota-to-chatbotb rouge:      {'score': 0.12360127080521818, 'std': 0.14261019747999726}\n",
      "ccl-sim rouge:             0.38009225898962673\n",
      "===       DISTINCT      ===\n",
      "context distinct:           {'score': 0.114955529740867, 'std': 0.04780861208267611}\n",
      "chatbota distinct:           {'score': 0.11159705177614018, 'std': 0.044972948026574824}\n",
      "chatbotb distinct:           {'score': 0.10426948523125507, 'std': 0.05160577641798607}\n",
      "===       EMOTION       ===\n",
      "context emotions:            \n",
      " [('sadness', 0.03771195514855208), ('joy', 0.3086917221080512), ('love', 0.0028261128700250993), ('anger', 0.46144572112098103), ('fear', 0.17504404807914398), ('surprise', 0.01428041995222884)]\n",
      "chatbota emotions:              \n",
      " [('sadness', 0.016448179114377126), ('joy', 0.5300553089473397), ('love', 0.0160360135450901), ('anger', 0.289736112288665), ('fear', 0.14465684418973979), ('surprise', 0.003067572473810287)]\n",
      "chatbotb emotions:            \n",
      " [('sadness', 0.04246980120660737), ('joy', 0.5643179937906098), ('love', 0.006394262331014033), ('anger', 0.2555840458080638), ('fear', 0.1273233036590682), ('surprise', 0.003910565077603678)]\n",
      "chatbota-chatbotbemotion corr:  \n",
      " 0.9930754427042098\n",
      "===         SAS         ===\n",
      "context-chatbota sas:           {'score': 0.19251391291618347, 'std': 0.27074262499809265}\n",
      "context-chatbotb sas:         {'score': 0.12086492031812668, 'std': 0.13998103141784668}\n",
      "chatbota-chatbotb sas:           {'score': 0.13670310378074646, 'std': 0.1772124171257019}\n",
      "ccl-sim sas:                0.44026166576374615\n",
      "=== SEMANTIC CLASSIFIER ===\n",
      "sem-classifier chatbota:                 {'score': 0.5347053408622742, 'std': 0.4730081558227539}\n",
      "sem-classifier chatbotb:                   {'score': 0.7992286086082458, 'std': 0.3711322546005249}\n",
      "time elapsed computing semantic classifier:  24.23 s\n",
      "Symmetric mode, skipping Human metrics.\n",
      "Skipping sentence outputting.\n"
     ]
    }
   ],
   "source": [
    "print(\"##### N-Beams vs. Sampling #####\")\n",
    "context_sentences   = list(df_char['ctx'])\n",
    "nbeams_responses    = list(df_char['prd_nbeams'])\n",
    "sampling_responses  = list(df_char['prd_sampling'])\n",
    "scores['nbeams_vs_sampling'] = compute_set_metrics(None, None,\n",
    "                                                   character, character, character + \" dataset\",\n",
    "                                                   context_sentences,\n",
    "                                                   nbeams_responses,\n",
    "                                                   sampling_responses,\n",
    "                                                   None,\n",
    "                                                   classifier_n_sentences=75, label_chatbot_symmetry=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if split == True:\n",
    "    save_as_json(metrics_folder, character+'_nbeams_vs_sampling_metrics', scores['nbeams_vs_sampling'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if split == True:    \n",
    "    scores = {}\n",
    "    scores['greedy_vs_nbeams'] = load_from_json(\n",
    "        filepath=metrics_folder,\n",
    "        filename=character+'_greedy_vs_nbeams_metrics'\n",
    "    )\n",
    "    scores['greedy_vs_sampling'] = load_from_json(\n",
    "        filepath=metrics_folder,\n",
    "        filename=character+'_greedy_vs_sampling_metrics'\n",
    "    )\n",
    "    scores['nbeams_vs_sampling'] = load_from_json(\n",
    "        filepath=metrics_folder,\n",
    "        filename=character+'_nbeams_vs_sampling_metrics'\n",
    "    )\n",
    "    \n",
    "    os.remove(os.path.join(\n",
    "        metrics_folder,\n",
    "        character+'_greedy_vs_nbeams_metrics.json'\n",
    "    ))\n",
    "    os.remove(os.path.join(\n",
    "        metrics_folder,\n",
    "        character+'_greedy_vs_sampling_metrics.json'\n",
    "    ))\n",
    "    os.remove(os.path.join(\n",
    "        metrics_folder,\n",
    "        character+'_nbeams_vs_sampling_metrics.json'\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_as_json(metrics_folder, character+'_sampling_comparison_metrics', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics Between Character vs Non-Finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [01:12<00:00,  4.52s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions_def_sampling = get_predictions_cached(sample_questions, model_def,\n",
    "                                                  os.path.join(in_folder_def, 'from_' + character + '_df_' + '_sampling.json'),\n",
    "                                                  \"Sampling\", override_predictions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 34.04it/s]\n"
     ]
    }
   ],
   "source": [
    "df_char_def = get_dataframe_for_metrics(character_hg['test'], None, None, predictions_def_sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(1):\\n    print(\"##### Sample \" + str(i+1) + \" #####\")\\n    context_sentence   = df_char[\\'ctx\\'][i]\\n    character_response = df_char[\\'prd_sampling\\'][i]\\n    default_response   = df_char_def[\\'prd_sampling\\'][i]\\n    compute_sample_metrics(context_sentence, default_response, character_response, label_chatbot_symmetry=True)\\n    print()\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for i in range(1):\n",
    "    print(\"##### Sample \" + str(i+1) + \" #####\")\n",
    "    context_sentence   = df_char['ctx'][i]\n",
    "    character_response = df_char['prd_sampling'][i]\n",
    "    default_response   = df_char_def['prd_sampling'][i]\n",
    "    compute_sample_metrics(context_sentence, default_response, character_response, label_chatbot_symmetry=True)\n",
    "    print()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nset_size = 50\\ni = 30\\nprint(\"##### Set (Size \" + str(set_size) + \") #####\")\\ncontext_sentences   = list(df_char[\\'ctx\\'][i:i+set_size])\\ncharacter_responses = list(df_char[\\'prd_sampling\\'][i:i+set_size])\\ndefault_responses   = list(df_char_def[\\'prd_sampling\\'][i:i+set_size])\\ncompute_set_metrics(None, None,\\n                    context_sentences, default_responses, character_responses, character, label_chatbot_symmetry=True)\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "set_size = 50\n",
    "i = 30\n",
    "print(\"##### Set (Size \" + str(set_size) + \") #####\")\n",
    "context_sentences   = list(df_char['ctx'][i:i+set_size])\n",
    "character_responses = list(df_char['prd_sampling'][i:i+set_size])\n",
    "default_responses   = list(df_char_def['prd_sampling'][i:i+set_size])\n",
    "compute_set_metrics(None, None,\n",
    "                    context_sentences, default_responses, character_responses, character, label_chatbot_symmetry=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Full Test Set #####\n",
      "=== SEMANTIC SIMILARITY ===\n",
      "context-chatbota similarity:    {'score': 0.33888429403305054, 'std': 0.21229518949985504}\n",
      "context-chatbotb similarity:  {'score': 0.3472537100315094, 'std': 0.18729861080646515}\n",
      "chatbotb-chatbota similarity:    {'score': 0.1780448853969574, 'std': 0.14780789613723755}\n",
      "ccl-sim similarity:             0.5075155981716266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:23<00:00, 11.70s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:23<00:00, 11.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===       PERPLEXITY     ===\n",
      "chatbota perplexity:          33.07173276985397\n",
      "chatbotb perplexity:          1079.779712171094\n",
      "===         BLEU         ===\n",
      "context-to-chatbota bleu:       {'score': 0.0}\n",
      "context-to-chatbotb bleu:     {'score': 0.0}\n",
      "chatbota-to-chatbotb bleu:       {'score': 0.0}\n",
      "ccl-sim bleu:             0.5\n",
      "===        ROUGE-L       ===\n",
      "context-to-chatbota rouge:      {'score': 0.07668026418026418, 'std': 0.12749021277296071}\n",
      "context-to-chatbotb rouge:    {'score': 0.09925618028365707, 'std': 0.08058334623547236}\n",
      "chatbota-to-chatbotb rouge:      {'score': 0.03541608602749907, 'std': 0.055429159087461294}\n",
      "ccl-sim rouge:             0.4783060694653144\n",
      "===       DISTINCT      ===\n",
      "context distinct:           {'score': 0.114955529740867, 'std': 0.04780861208267611}\n",
      "chatbota distinct:           {'score': 0.10426948523125507, 'std': 0.05160577641798607}\n",
      "chatbotb distinct:           {'score': 0.15787614830955177, 'std': 0.033784517908534414}\n",
      "===       EMOTION       ===\n",
      "context emotions:            \n",
      " [('sadness', 0.03771195514855208), ('joy', 0.3086917221080512), ('love', 0.0028261128700250993), ('anger', 0.46144572112098103), ('fear', 0.17504404807914398), ('surprise', 0.01428041995222884)]\n",
      "chatbota emotions:              \n",
      " [('sadness', 0.04246980120660737), ('joy', 0.5643179937906098), ('love', 0.006394262331014033), ('anger', 0.2555840458080638), ('fear', 0.1273233036590682), ('surprise', 0.003910565077603678)]\n",
      "chatbotb emotions:            \n",
      " [('sadness', 0.027188024438146385), ('joy', 0.38981148952734657), ('love', 0.06398122525206418), ('anger', 0.3537141057095141), ('fear', 0.163383948268347), ('surprise', 0.001921224447869463)]\n",
      "chatbota-chatbotbemotion corr:  \n",
      " 0.9090733223860813\n",
      "===         SAS         ===\n",
      "context-chatbota sas:           {'score': 0.12086492031812668, 'std': 0.13998103141784668}\n",
      "context-chatbotb sas:         {'score': 0.1199764683842659, 'std': 0.12971358001232147}\n",
      "chatbota-chatbotb sas:           {'score': 0.024445777758955956, 'std': 0.043585311621427536}\n",
      "ccl-sim sas:                0.49941074076467873\n",
      "=== SEMANTIC CLASSIFIER ===\n",
      "sem-classifier chatbota:                 {'score': 0.7992286086082458, 'std': 0.3711322546005249}\n",
      "sem-classifier chatbotb:                   {'score': 0.11794029176235199, 'std': 0.2851489186286926}\n",
      "time elapsed computing semantic classifier:  22.14 s\n",
      "Symmetric mode, skipping Human metrics.\n",
      "Skipping sentence outputting.\n"
     ]
    }
   ],
   "source": [
    "print(\"##### Full Test Set #####\")\n",
    "context_sentences   = list(df_char['ctx'])\n",
    "character_responses = list(df_char['prd_sampling'])\n",
    "default_responses   = list(df_char_def['prd_sampling'])\n",
    "scores = compute_set_metrics(model, model_def, character, 'Default', character + \" dataset\",\n",
    "                             context_sentences, \n",
    "                             character_responses, \n",
    "                             default_responses,\n",
    "                             encoded_test_set,\n",
    "                             classifier_n_sentences=75,\n",
    "                             label_chatbot_symmetry=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_as_json(metrics_folder, character+'_vs_nonfinetuned_metrics', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics Between Character 1 & Character 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_small(sample_questions, model, generation_method):\n",
    "    print(\"Creating predictions\")\n",
    "    predictions = list()\n",
    "    for x in tqdm(sample_questions):\n",
    "        tokenized_question = tokenizer.encode(x + tokenizer.eos_token, return_tensors='tf')\n",
    "        max_length = 128 + tokenized_question.shape[1]\n",
    "        if generation_method == \"Greedy\":\n",
    "            generated_answer = model.generate(tokenized_question,\n",
    "                                pad_token_id=tokenizer.eos_token_id, max_length=max_length)[0].numpy().tolist()\n",
    "        elif generation_method == \"Beam Search\":\n",
    "            generated_answer = model.generate(tokenized_question,\n",
    "                                         pad_token_id=tokenizer.eos_token_id, max_length=max_length,\n",
    "                                         n_beams=n_beams)[0].numpy().tolist()\n",
    "        elif generation_method == \"Sampling\":\n",
    "                b = True\n",
    "                c = 0\n",
    "                while b:\n",
    "                    generated_answer = model.generate(tokenized_question,\n",
    "                                                 pad_token_id=tokenizer.eos_token_id, max_length=max_length,\n",
    "                                                 do_sample=True, top_k=top_k, top_p=top_p)[0].numpy().tolist()\n",
    "                    \n",
    "                    c+= 1\n",
    "                    if len(generated_answer[len(tokenized_question[0]):])>1:\n",
    "                        b = False         \n",
    "                    if c>100: \n",
    "                        generated_answer[len(tokenized_question[0]):] = tokenizer.encode('hi') + [tokenizer.eos_token_id]\n",
    "                        break \n",
    "                        \n",
    "        predictions.append(generated_answer[len(tokenized_question[0]):])\n",
    "        \n",
    "        assert all([len(p)>1 for p in predictions])\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-500730463c87a718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to D:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBot\\BarneyBot\\cache\\csv\\default-500730463c87a718\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a573e179c2340259adf7454c07dfa18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59020d249c3148938c892fbee5400821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to D:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBot\\BarneyBot\\cache\\csv\\default-500730463c87a718\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c78912e6e74b93a9bcd41c1a3a04bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "764c3387bc6f418197062cfe59bf5dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_common = load_dataset('csv',\n",
    "                         data_files=os.path.join(base_folder, 'Data', 'common_dataset.csv'), \n",
    "                         cache_dir=os.path.join(base_folder, \"cache\"))\n",
    "\n",
    "df_common = df_common.remove_columns(['source'])\n",
    "tokenized_common_hg = df_common['train'].map(preprocess_function, batched=False)\n",
    "\n",
    "encoded_common_set = tokenized_common_hg.to_tf_dataset(\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'context'],\n",
       "        num_rows: 35\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec={'input_ids': TensorSpec(shape=(None, None), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(None, None), dtype=tf.int64, name=None), 'labels': TensorSpec(shape=(None, None), dtype=tf.int64, name=None)}>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_common_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [01:46<00:00,  3.04s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions_1_sampling = get_predictions_small(df_common['train']['context'], model, \"Sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [01:05<00:00,  1.87s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions_2_sampling = get_predictions_small(df_common['train']['context'], model_2, \"Sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 35/35 [00:00<00:00, 820.72it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 35/35 [00:00<00:00, 1664.22it/s]\n"
     ]
    }
   ],
   "source": [
    "df_common_char_1 = get_dataframe_for_metrics(df_common['train'], None, None, predictions_1_sampling)\n",
    "df_common_char_2 = get_dataframe_for_metrics(df_common['train'], None, None, predictions_2_sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Vader  Vs. Harry #####\n",
      "=== SEMANTIC SIMILARITY ===\n",
      "context-chatbota similarity:    {'score': 0.23312361538410187, 'std': 0.12934212386608124}\n",
      "context-chatbotb similarity:  {'score': 0.3900943398475647, 'std': 0.24657072126865387}\n",
      "chatbotb-chatbota similarity:    {'score': 0.2121538370847702, 'std': 0.14055652916431427}\n",
      "ccl-sim similarity:             0.37785380500072496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:01<00:00, 12.37s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:15<00:00, 15.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===       PERPLEXITY     ===\n",
      "chatbota perplexity:          91.02970090092596\n",
      "chatbotb perplexity:          78.51913341343958\n",
      "===         BLEU         ===\n",
      "context-to-chatbota bleu:       {'score': 0.0}\n",
      "context-to-chatbotb bleu:     {'score': 0.05853086059249302}\n",
      "chatbota-to-chatbotb bleu:       {'score': 0.0}\n",
      "ccl-sim bleu:             0.44318207022835593\n",
      "===        ROUGE-L       ===\n",
      "context-to-chatbota rouge:      {'score': 0.06097322556734762, 'std': 0.08966934088111173}\n",
      "context-to-chatbotb rouge:    {'score': 0.162452071737786, 'std': 0.2760050306397689}\n",
      "chatbota-to-chatbotb rouge:      {'score': 0.04082122632008216, 'std': 0.07810065627877678}\n",
      "ccl-sim rouge:             0.4045033181987411\n",
      "===       DISTINCT      ===\n",
      "context distinct:           {'score': 0.10984328048288133, 'std': 0.06188826948933667}\n",
      "chatbota distinct:           {'score': 0.12833456908400356, 'std': 0.0489616266859106}\n",
      "chatbotb distinct:           {'score': 0.06939809288088766, 'std': 0.06617640419891167}\n",
      "===       EMOTION       ===\n",
      "context emotions:            \n",
      " [('sadness', 0.014541770386443074), ('joy', 0.3401680953842255), ('love', 0.11487391056850486), ('anger', 0.3726624113565776), ('fear', 0.1548420296790677), ('surprise', 0.002911792248154857)]\n",
      "chatbota emotions:              \n",
      " [('sadness', 0.06520289192890881), ('joy', 0.42602432714775207), ('love', 0.003943276742938906), ('anger', 0.39549069156387956), ('fear', 0.10719208413086433), ('surprise', 0.002146721712779254)]\n",
      "chatbotb emotions:            \n",
      " [('sadness', 0.08254638263357005), ('joy', 0.38206895507672534), ('love', 0.024966166542643414), ('anger', 0.4246392826183832), ('fear', 0.0826501034033884), ('surprise', 0.0031291105892575746)]\n",
      "chatbota-chatbotbemotion corr:  \n",
      " 0.9892146402938997\n",
      "===         SAS         ===\n",
      "context-chatbota sas:           {'score': 0.0454055480659008, 'std': 0.09191413223743439}\n",
      "context-chatbotb sas:         {'score': 0.20271965861320496, 'std': 0.2952743172645569}\n",
      "chatbota-chatbotb sas:           {'score': 0.04602072760462761, 'std': 0.06589896231889725}\n",
      "ccl-sim sas:                0.3561187078259702\n",
      "=== SEMANTIC CLASSIFIER ===\n",
      "sem-classifier chatbota:                 {'score': 0.7206661105155945, 'std': 0.4144347608089447}\n",
      "sem-classifier chatbotb:                   {'score': 0.06225692108273506, 'std': 0.20964664220809937}\n",
      "time elapsed computing semantic classifier:  36.39 s\n",
      "Symmetric mode, skipping Human metrics.\n",
      "===      SENTENCES      ===\n",
      "* context:  Barney, this is about the building.\n",
      "* chatbota: That's no way to talk to the Emperor.\n",
      "* chatbotb: Yes.\n",
      "\n",
      "* context:  All right. I'll be right there. Stay where you are.\n",
      "* chatbota: He's right, my lord. I'll be with my lord, Lord.\n",
      "* chatbotb: Don't worry, I'll find you.\n",
      "\n",
      "* context:  I think there's a pretty girl smiling at me there.\n",
      "* chatbota: I'm here...\n",
      "* chatbotb: Look, there. She's asking me to come live with her.\n",
      "\n",
      "* context:  I love you, man.\n",
      "* chatbota: Thank you, sir.\n",
      "* chatbotb: I know.\n",
      "\n",
      "* context:  Not even if she's hot?\n",
      "* chatbota: Vader calmly adjusts his control stick as the stars zoom in on his ship.\n",
      "* chatbotb: Hagrid! Heh!\n",
      "\n",
      "* context:  Soft kitty, warm kitty Little ball of fur\n",
      "* chatbota: Admiral Piett zoomed in on the princess. She's in perfect position.\n",
      "* chatbotb: What is that?\n",
      "\n",
      "* context:  Penny.\n",
      "* chatbota: It is of no concern.\n",
      "* chatbotb: Sorry, Ron!\n",
      "\n",
      "* context:  Oh. Sheldon, thank you. Thats so romantic. But what about Rajesh? He was okay with you choosing the name?\n",
      "* chatbota: Vader calmly walks in calmly, his aim on his.\n",
      "* chatbotb: It's complicated.\n",
      "\n",
      "* context:  I didnt break it. I, I guess Stuart sold it to me like this.\n",
      "* chatbota: It was a deal made after you were beaten to death. You are now the Master.\n",
      "* chatbotb: You sold it to me like this.\n",
      "\n",
      "* context:  Be careful.\n",
      "* chatbota: You are a bold one.\n",
      "* chatbotb: Don't let them near your books.\n",
      "\n",
      "* context:  But why would anyone go near that dog?\n",
      "* chatbota: If only the Emperor could unearth the plans to this facility.\n",
      "* chatbotb: You monster!\n",
      "\n",
      "* context:  Expecto Patronum!\n",
      "* chatbota: The Emperor commands you not to lower your ship!\n",
      "* chatbotb: Do something!\n",
      "\n",
      "* context:  Ron Weasley.\n",
      "* chatbota: Don't you mean\n",
      "* chatbotb: Ron Weasley.\n",
      "\n",
      "* context:  I spoke a different language?\n",
      "* chatbota: No, your thoughts betray you, son. I will not fight you, you are a hero. You are my only friend.\n",
      "* chatbotb: You spoke a different language?\n",
      "\n",
      "* context:  Harry?\n",
      "* chatbota: You do not know the power of the\n",
      "* chatbotb: Oh, you're the teacher, aren't you?\n",
      "\n",
      "* context:  OK. First Bender, then Flexo, then Fry.\n",
      "* chatbota: Don't be too proud of this technological terror you've constructed. If we find you're behind this device...\n",
      "* chatbotb: All right there, Harry?\n",
      "\n",
      "* context:  Just relax, Bender. Tomorrow we'll pry you down, have a nice breakfast and then go hunt down and slaughter that ancient evil.\n",
      "* chatbota: Yes, my Master.\n",
      "* chatbotb: Buckbeak. Buckbeak.\n",
      "\n",
      "* context:  I'm too scared.\n",
      "* chatbota: Don't be too proud of your little treason. You'll be remembered as a hero.\n",
      "* chatbotb: Not nearly good enough.\n",
      "\n",
      "* context:  Dr. Zoidberg? Are you OK?\n",
      "* chatbota: The Force is strong with you. No use in haggling with a dangerous Imperial\n",
      "* chatbotb: Hagrid, please come back.\n",
      "\n",
      "* context:  Fry, thank God we found you.\n",
      "* chatbota: Oh. I have failed you, Admiral.\n",
      "* chatbotb: I will not be leaving until I repay my family.\n",
      "\n",
      "* context:  I will not fight you.\n",
      "* chatbota: No, no!\n",
      "* chatbotb: Dobby, please don't be dead.\n",
      "\n",
      "* context:  Lord Vader, what about Leia and theWookiee?\n",
      "* chatbota: I told you, nothing to worry about.\n",
      "* chatbotb: And you?\n",
      "\n",
      "* context:  The Emperor's coming here?\n",
      "* chatbota: That's why he's not in charge.\n",
      "* chatbotb: Come and join the Heir!\n",
      "\n",
      "* context:  Shall I hold them?\n",
      "* chatbota: If you have a gift of some sort, tell me when you are done.\n",
      "* chatbotb: Hold them.\n",
      "\n",
      "* context:  Lord Vader, what about Leia and theWookiee?\n",
      "* chatbota: Luke looks around the area, wondering where the Death Star is.\n",
      "* chatbotb: Not a clue.\n",
      "\n",
      "* context:  Oh! Joey uh, were you in our room last night?\n",
      "* chatbota: Don't leave me, Vader!\n",
      "* chatbotb: Not really.\n",
      "\n",
      "* context:  Hey.\n",
      "* chatbota: Good. Ready for the bombardment\n",
      "* chatbotb: Hello.\n",
      "\n",
      "* context:  Joey... are you sure? I mean, I know how much you love him!\n",
      "* chatbota: All aboard the\n",
      "* chatbotb: I love him!\n",
      "\n",
      "* context:  Ok, ten.\n",
      "* chatbota: Yes, my Lord.\n",
      "* chatbotb: Okay.\n",
      "\n",
      "* context:  Joey, Ross is gonna be here any second, would you mind watching Ben for me while I use the ladies' room?\n",
      "* chatbota: What makes you think I would help you with this?\n",
      "* chatbotb: Yes sir.\n",
      "\n",
      "* context:  What are you doing for a living?\n",
      "* chatbota: You're an out of control Rebel sympathizer.\n",
      "* chatbotb: All you've got to do is check on the mail.\n",
      "\n",
      "* context:  How are you doing?\n",
      "* chatbota: He walks off toward the X-wing formation.\n",
      "* chatbotb: All right. How are you doing?\n",
      "\n",
      "* context:  Where are you going to?\n",
      "* chatbota: Come with me.\n",
      "* chatbotb: Hang on. Let's take the train.\n",
      "\n",
      "* context:  What are you wearing?\n",
      "* chatbota: Vader calmly adjusts his control stick as the stars whip past in the window above his head.\n",
      "* chatbotb: No. I just don't want to talk about it.\n",
      "\n",
      "* context:  What do you want to do tonight?\n",
      "* chatbota: I will inform the Senate, Lord Vader.\n",
      "* chatbotb: I don't know.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"##### \" + character + \"  Vs. \" + character_2 + \" #####\")\n",
    "context_sentences   = list(df_common_char_1['ctx'])\n",
    "chatbot_responses   = list(df_common_char_1['prd_sampling'])\n",
    "chatbot_2_responses = list(df_common_char_2['prd_sampling'])\n",
    "scores = compute_set_metrics(model, model_2, character, character_2, \"common small dataset\",\n",
    "                             context_sentences, chatbot_responses, chatbot_2_responses, encoded_common_set,\n",
    "                             include_qualitative_sentences=True, label_chatbot_symmetry=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_as_json(metrics_folder, character+'_vs_'+character_2+'_metrics', scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

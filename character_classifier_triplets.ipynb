{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cb8e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount google drive\n",
    "import os\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive',force_remount=True)\n",
    "    base_folder = '/content/drive/My Drive/unibo/NLP_project/BarneyBot'\n",
    "    os.system(\"pip install datasets\")\n",
    "    os.system(\"pip install transformers\")\n",
    "    os.system(\"pip install rouge_score\")\n",
    "    os.system(\"pip install -U sentence-transformers\")\n",
    "else:\n",
    "    base_folder = os.getcwd()\n",
    "    \n",
    "in_folder = os.path.join(base_folder, \"in\")\n",
    "if not os.path.exists(in_folder):\n",
    "    os.makedirs(in_folder)\n",
    "out_folder = os.path.join(base_folder, \"out\")\n",
    "if not os.path.exists(out_folder):\n",
    "    os.makedirs(out_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a84797d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e695e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_dict = {\n",
    "    'Barney':{\n",
    "        'classifier_name': 'barney_classifier',\n",
    "        'series_df_filename': 'HIMYM.csv',\n",
    "        'classifier_df': 'barney_classifier.csv',\n",
    "        'encoded_lines_filename': 'barney_encoded_lines.npy',\n",
    "        'source': 'HIMYM'\n",
    "    },\n",
    "    'Sheldon':{\n",
    "        'classifier_name': 'sheldon_classifier',\n",
    "        'series_df_filename': 'TBBT.csv',\n",
    "        'classifier_df': 'sheldon_classifier.csv',\n",
    "        'encoded_lines_filename': 'sheldon_encoded_lines.npy',\n",
    "        'source': 'TBBT'\n",
    "    },\n",
    "    'Harry':{\n",
    "        'classifier_name': 'harry_classifier',\n",
    "        'series_df_filename': 'HP.csv',\n",
    "        'classifier_df': 'harry_classifier.csv',\n",
    "        'encoded_lines_filename': 'harry_encoded_lines.npy',\n",
    "        'source': 'HP'\n",
    "    },\n",
    "    'Fry':{\n",
    "        'classifier_name': 'fry_classifier',\n",
    "        'series_df_filename': 'Futurama.csv',\n",
    "        'classifier_df': 'fry_classifier.csv',\n",
    "        'encoded_lines_filename': 'fry_encoded_lines.npy',\n",
    "        'source': 'Futurama'\n",
    "    },\n",
    "    'Vader':{\n",
    "        'classifier_name': 'vader_classifier',\n",
    "        'series_df_filename': 'SW.csv',\n",
    "        'classifier_df': 'vader_classifier.csv',\n",
    "        'encoded_lines_filename': 'vader_encoded_lines.npy',\n",
    "        'source': 'SW'\n",
    "    },\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63306303",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 1000\n",
    "lr = 1e-6\n",
    "regularizer_weight_r = 1e-4\n",
    "regularizer_weight_s = 1e-3\n",
    "dropout_rate = 0.2\n",
    "train_size = 0.85\n",
    "test_size = 0.10\n",
    "n_shuffles = 10\n",
    "\n",
    "from_saved_embeddings = True\n",
    "\n",
    "character = 'Barney'\n",
    "\n",
    "version = ''\n",
    "shutdown_at_end = False # 'h'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5839f626",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_folder = os.path.join(base_folder, \"Data\", \"Sources\", character_dict[character]['source'])\n",
    "\n",
    "model_path = os.path.join(character_folder, character_dict[character]['classifier_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b1e178",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1223031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_df = pd.read_csv(os.path.join(character_folder, character_dict[character]['series_df_filename']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f46a6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_df[series_df['character']==character]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f54be9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_df['character'] = series_df['character'].apply(lambda x: 1 if x==character else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c629b0c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "series_df[series_df['character']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fc8bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_df = series_df[['character', 'line']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139c30e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b83ecd",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1963f7a7",
   "metadata": {},
   "source": [
    "## Sentence Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f40c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if it cannot find sentence embeddings, set from_saved_embeddings = True\n",
    "if not os.path.exists(os.path.join(character_folder, character_dict[character]['encoded_lines_filename'])):\n",
    "    from_saved_embeddings = False\n",
    "    print('Encoded lines not found, from_saved_embeddings set to False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eea5273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "if not from_saved_embeddings:\n",
    "    sentence_transformer = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cef89bb",
   "metadata": {},
   "source": [
    "## Sentence Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c488c258",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not from_saved_embeddings:\n",
    "\n",
    "    series_df['encoded_line'] = [sentence_transformer.encode(line) for line in tqdm(series_df['line'])]\n",
    "\n",
    "    # save sentences dataset\n",
    "    series_df[['line', 'character']].to_csv(\n",
    "        os.path.join(character_folder, character_dict[character]['classifier_df']), \n",
    "        index = False\n",
    "    )\n",
    "\n",
    "    np.save(\n",
    "        os.path.join(character_folder, character_dict[character]['encoded_lines_filename']),\n",
    "        series_df['encoded_line'].to_numpy()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b9fe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read sentences dataaset\n",
    "series_df = pd.read_csv(\n",
    "    os.path.join(character_folder, character_dict[character]['classifier_df']),\n",
    "    dtype={'line': str,\n",
    "           'character': int\n",
    "          }\n",
    ")\n",
    "\n",
    "series_df['encoded_line'] = np.load(\n",
    "    os.path.join(character_folder, character_dict[character]['encoded_lines_filename']), \n",
    "    allow_pickle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bc277a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "series_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2b9dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_train_df, series_test_df = train_test_split(series_df, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f8b429",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_train_df, series_val_df = train_test_split(series_train_df, test_size = 1-train_size-test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3283ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplet_df(series_df, n_shuffles=1):\n",
    "    \n",
    "    # separate character from others\n",
    "    series_df_1 = series_df[series_df['character']==1].copy()\n",
    "    series_df_0 = series_df[series_df['character']==0].copy()\n",
    "    \n",
    "    df_rows = {'character':[], 'encoded_lines':[]}\n",
    "    \n",
    "    for _ in range(n_shuffles):\n",
    "        # shuffle dataset\n",
    "        series_df_1 = series_df_1.sample(frac=1).reset_index(drop=True)\n",
    "        series_df_0 = series_df_0.sample(n=len(series_df_1)).reset_index(drop=True)\n",
    "        \n",
    "        for i in tqdm(range(2,len(series_df_1))):\n",
    "            # character\n",
    "            lines = list(series_df_1['encoded_line'][i-2:i+1])\n",
    "            lines = np.concatenate(lines)\n",
    "            df_rows['character'].append(1)\n",
    "            df_rows['encoded_lines'].append(lines)\n",
    "\n",
    "            # other\n",
    "            lines = list(series_df_0['encoded_line'][i-2:i+1])\n",
    "            lines = np.concatenate(lines)\n",
    "            df_rows['character'].append(0)\n",
    "            df_rows['encoded_lines'].append(lines)\n",
    "\n",
    "    df = pd.DataFrame(data=df_rows)\n",
    "    \n",
    "    return df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6677cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shuffled_df = get_triplet_df(series_df, n_shuffles=n_shuffles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ef379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shuffled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5172cab1",
   "metadata": {},
   "source": [
    "## Create Classification Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad7fe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_len = len(shuffled_df)\n",
    "train_len = int(tot_len*train_size)\n",
    "test_len = int(tot_len*test_size)\n",
    "val_len = tot_len - train_len - test_len\n",
    "\n",
    "print(tot_len, train_len, test_len, val_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1636e84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading training data...')\n",
    "X_train = np.array([[float(e) for e in s] for s in tqdm(shuffled_df['encoded_lines'][:train_len])])\n",
    "y_train = np.array([c for c in tqdm(shuffled_df['character'][:train_len])])\n",
    "\n",
    "print('Loading test data...')\n",
    "X_test = np.array([[float(e) for e in s] for s in tqdm(shuffled_df['encoded_lines'][:test_len])])\n",
    "y_test = np.array([c for c in tqdm(shuffled_df['character'][:test_len])])\n",
    "\n",
    "print('Loading validation data...')\n",
    "X_val = np.array([[float(e) for e in s] for s in tqdm(shuffled_df['encoded_lines'][:val_len])])\n",
    "y_val = np.array([c for c in tqdm(shuffled_df['character'][:val_len])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04af5ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute some statistics\n",
    "train_percentage_1 = len(y_train[y_train==1])/len(y_train)\n",
    "train_percentage_0 = len(y_train[y_train==0])/len(y_train)\n",
    "\n",
    "val_percentage_1 = len(y_val[y_val==1])/len(y_val)\n",
    "val_percentage_0 = len(y_val[y_val==0])/len(y_val)\n",
    "print('\\t0 (%)\\t\\t1 (%)')\n",
    "print('train\\t{:.2f}\\t\\t{:.2f}'.format(train_percentage_0, train_percentage_1))\n",
    "print('val\\t{:.2f}\\t\\t{:.2f}'.format(val_percentage_0, val_percentage_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9d8526",
   "metadata": {},
   "source": [
    "## Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6d6426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import keras/tensorflow libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a229b099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "def create_model():\n",
    "    inputs = keras.Input(shape=(len(X_train[0],)))\n",
    "    \n",
    "    x = layers.Dense(\n",
    "        1024,\n",
    "        activation='relu',\n",
    "        # kernel_regularizer=regularizers.l2(regularizer_weight),\n",
    "        # bias_regularizer=regularizers.l2(regularizer_weight)\n",
    "    )(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Dense(\n",
    "        1024,\n",
    "        activation='relu',\n",
    "        # kernel_regularizer=regularizers.l2(regularizer_weight),\n",
    "        # bias_regularizer=regularizers.l2(regularizer_weight)\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Dense(\n",
    "        512, \n",
    "        activation='relu',\n",
    "        # kernel_regularizer=regularizers.l2(regularizer_weight),\n",
    "        # bias_regularizer=regularizers.l2(regularizer_weight)\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Dense(\n",
    "        256, \n",
    "        activation='relu',\n",
    "        # kernel_regularizer=regularizers.l2(regularizer_weight),\n",
    "        # bias_regularizer=regularizers.l2(regularizer_weight)\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Dense(\n",
    "        128, \n",
    "        activation='relu',\n",
    "        kernel_regularizer=regularizers.l2(regularizer_weight_r),\n",
    "        bias_regularizer=regularizers.l2(regularizer_weight_r)\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    out = layers.Dense(\n",
    "        1, \n",
    "        activation='sigmoid',\n",
    "        kernel_regularizer=regularizers.l2(regularizer_weight_s),\n",
    "        bias_regularizer=regularizers.l2(regularizer_weight_s)\n",
    "    )(x)\n",
    "\n",
    "\n",
    "    classifier_model = keras.Model(inputs, out)\n",
    "    classifier_model.compile(\n",
    "        loss = keras.losses.BinaryCrossentropy(),\n",
    "        optimizer = keras.optimizers.Adam(learning_rate = lr),\n",
    "        metrics = [keras.metrics.BinaryAccuracy(), keras.metrics.Recall()]\n",
    "    )\n",
    "    return classifier_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edd2eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c20a436",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7447d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop_callback = callbacks.EarlyStopping(\n",
    "        monitor=\"val_binary_accuracy\",\n",
    "        min_delta=0,\n",
    "        patience=6,\n",
    "        verbose=0,\n",
    "        mode=\"max\",\n",
    "        baseline=None,\n",
    "        restore_best_weights=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b01066d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_history = classifier_model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    validation_data = (X_val, y_val),\n",
    "    epochs= epochs,\n",
    "    verbose = 1, \n",
    "    callbacks=[earlystop_callback],\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4acadb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('#'*25 + ' Model Test ' + '#'*25)\n",
    "fig, ax=plt.subplots(1,1,figsize=(5,5))\n",
    "y_pred = classifier_model.predict(X_test).round()\n",
    "# Plot the confusion matrix normalizing over the true values (over the rows)\n",
    "cm = confusion_matrix(y_test, y_pred) #, normalize='pred')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Others', character])\n",
    "disp.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1078a873",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_path = os.path.join(character_folder, character_dict[character]['classifier_name']+version)\n",
    "classifier_model.save(classifier_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c854e915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save history as a JSON file\n",
    "import json\n",
    "filename = character.lower() + '_training_history' + version + '.json'\n",
    "\n",
    "output_string = json.dumps(train_history.history)\n",
    "with open(os.path.join(character_folder, filename), 'w') as file:\n",
    "    file.write(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dde2323",
   "metadata": {},
   "outputs": [],
   "source": [
    "if shutdown_at_end:\n",
    "    os.system('shutdown /' + shutdown_at_end)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

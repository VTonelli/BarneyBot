{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount google drive\n",
    "import os\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive',force_remount=True)\n",
    "    base_folder = '/content/drive/My Drive/unibo/NLP_project/BarneyBot'\n",
    "    os.system(\"pip install datasets\")\n",
    "    os.system(\"pip install transformers\")\n",
    "    os.system(\"pip install rouge_score\")\n",
    "    os.system(\"pip install -U sentence-transformers\")\n",
    "else:\n",
    "    base_folder = os.getcwd()\n",
    "    \n",
    "in_folder = os.path.join(base_folder, \"in\")\n",
    "if not os.path.exists(in_folder):\n",
    "    os.makedirs(in_folder)\n",
    "out_folder = os.path.join(base_folder, \"out\")\n",
    "if not os.path.exists(out_folder):\n",
    "    os.makedirs(out_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_dict = {\n",
    "    'Barney':{\n",
    "        'classifier_name': 'barney_classifier',\n",
    "        'series_df_filename': 'HIMYM.csv',\n",
    "        'classifier_df': 'barney_classifier.csv',\n",
    "        'encoded_lines_filename': 'barney_encoded_lines.npy',\n",
    "        'source': 'HIMYM'\n",
    "    },\n",
    "    'Sheldon':{\n",
    "        'classifier_name': 'sheldon_classifier',\n",
    "        'series_df_filename': 'TBBT.csv',\n",
    "        'classifier_df': 'sheldon_classifier.csv',\n",
    "        'encoded_lines_filename': 'sheldon_encoded_lines.npy',\n",
    "        'source': 'TBBT'\n",
    "    },\n",
    "    'Harry':{\n",
    "        'classifier_name': 'harry_classifier',\n",
    "        'series_df_filename': 'HP.csv',\n",
    "        'classifier_df': 'harry_classifier.csv',\n",
    "        'encoded_lines_filename': 'harry_encoded_lines.npy',\n",
    "        'source': 'HP'\n",
    "    },\n",
    "    'Fry':{\n",
    "        'classifier_name': 'fry_classifier',\n",
    "        'series_df_filename': 'Futurama.csv',\n",
    "        'classifier_df': 'fry_classifier.csv',\n",
    "        'encoded_lines_filename': 'fry_encoded_lines.npy',\n",
    "        'source': 'Futurama'\n",
    "    },\n",
    "    'Vader':{\n",
    "        'classifier_name': 'vader_classifier',\n",
    "        'series_df_filename': 'SW.csv',\n",
    "        'classifier_df': 'vader_classifier.csv',\n",
    "        'encoded_lines_filename': 'vader_encoded_lines.npy',\n",
    "        'source': 'SW'\n",
    "    },\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 1000\n",
    "lr = 1e-6\n",
    "regularizer_weight_r = 1e-4\n",
    "regularizer_weight_s = 1e-3\n",
    "dropout_rate = 0.2\n",
    "train_size = 0.85\n",
    "test_size = 0.10\n",
    "n_shuffles = 1\n",
    "\n",
    "from_saved_embeddings = True\n",
    "\n",
    "character = 'Vader'\n",
    "\n",
    "version = ''\n",
    "shutdown_at_end = False # 'h'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_folder = os.path.join(base_folder, \"Data\", \"Sources\", character_dict[character]['source'])\n",
    "\n",
    "model_path = os.path.join(character_folder, character_dict[character]['classifier_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_df = pd.read_csv(os.path.join(character_folder, character_dict[character]['series_df_filename']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>film</th>\n",
       "      <th>line</th>\n",
       "      <th>character</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Star Wars IV - A New Hope</td>\n",
       "      <td>Where are those transmissions youintercepted?</td>\n",
       "      <td>Vader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Star Wars IV - A New Hope</td>\n",
       "      <td>What have you done with thoseplans?</td>\n",
       "      <td>Vader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Star Wars IV - A New Hope</td>\n",
       "      <td>If this is a consular ship... were is the Amba...</td>\n",
       "      <td>Vader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Star Wars IV - A New Hope</td>\n",
       "      <td>Commander, tear this ship apartuntil you've fo...</td>\n",
       "      <td>Vader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Star Wars IV - A New Hope</td>\n",
       "      <td>Don't play games with me, Your Highness. You w...</td>\n",
       "      <td>Vader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>Star Wars VI - Return of the Jedi</td>\n",
       "      <td>You cannot hide forever, Luke.</td>\n",
       "      <td>Vader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>Star Wars VI - Return of the Jedi</td>\n",
       "      <td>Give yourself to the dark side. It is the only...</td>\n",
       "      <td>Vader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>Star Wars VI - Return of the Jedi</td>\n",
       "      <td>Sister! So...you have a twinsister. Your feeli...</td>\n",
       "      <td>Vader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2828</th>\n",
       "      <td>Star Wars VI - Return of the Jedi</td>\n",
       "      <td>Luke, help me take this mask off.</td>\n",
       "      <td>Vader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>Star Wars VI - Return of the Jedi</td>\n",
       "      <td>Nothing can stop that now. Just for once... le...</td>\n",
       "      <td>Vader</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   film  \\\n",
       "11            Star Wars IV - A New Hope   \n",
       "12            Star Wars IV - A New Hope   \n",
       "14            Star Wars IV - A New Hope   \n",
       "15            Star Wars IV - A New Hope   \n",
       "44            Star Wars IV - A New Hope   \n",
       "...                                 ...   \n",
       "2800  Star Wars VI - Return of the Jedi   \n",
       "2802  Star Wars VI - Return of the Jedi   \n",
       "2803  Star Wars VI - Return of the Jedi   \n",
       "2828  Star Wars VI - Return of the Jedi   \n",
       "2830  Star Wars VI - Return of the Jedi   \n",
       "\n",
       "                                                   line character  \n",
       "11        Where are those transmissions youintercepted?     Vader  \n",
       "12                  What have you done with thoseplans?     Vader  \n",
       "14    If this is a consular ship... were is the Amba...     Vader  \n",
       "15    Commander, tear this ship apartuntil you've fo...     Vader  \n",
       "44    Don't play games with me, Your Highness. You w...     Vader  \n",
       "...                                                 ...       ...  \n",
       "2800                     You cannot hide forever, Luke.     Vader  \n",
       "2802  Give yourself to the dark side. It is the only...     Vader  \n",
       "2803  Sister! So...you have a twinsister. Your feeli...     Vader  \n",
       "2828                  Luke, help me take this mask off.     Vader  \n",
       "2830  Nothing can stop that now. Just for once... le...     Vader  \n",
       "\n",
       "[161 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_df[series_df['character']==character]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_df['character'] = series_df['character'].apply(lambda x: 1 if x==character else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>film</th>\n",
       "      <th>line</th>\n",
       "      <th>character</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Star Wars IV - A New Hope</td>\n",
       "      <td>Where are those transmissions youintercepted?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Star Wars IV - A New Hope</td>\n",
       "      <td>What have you done with thoseplans?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Star Wars IV - A New Hope</td>\n",
       "      <td>If this is a consular ship... were is the Amba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Star Wars IV - A New Hope</td>\n",
       "      <td>Commander, tear this ship apartuntil you've fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Star Wars IV - A New Hope</td>\n",
       "      <td>Don't play games with me, Your Highness. You w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>Star Wars VI - Return of the Jedi</td>\n",
       "      <td>You cannot hide forever, Luke.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>Star Wars VI - Return of the Jedi</td>\n",
       "      <td>Give yourself to the dark side. It is the only...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>Star Wars VI - Return of the Jedi</td>\n",
       "      <td>Sister! So...you have a twinsister. Your feeli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2828</th>\n",
       "      <td>Star Wars VI - Return of the Jedi</td>\n",
       "      <td>Luke, help me take this mask off.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>Star Wars VI - Return of the Jedi</td>\n",
       "      <td>Nothing can stop that now. Just for once... le...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   film  \\\n",
       "11            Star Wars IV - A New Hope   \n",
       "12            Star Wars IV - A New Hope   \n",
       "14            Star Wars IV - A New Hope   \n",
       "15            Star Wars IV - A New Hope   \n",
       "44            Star Wars IV - A New Hope   \n",
       "...                                 ...   \n",
       "2800  Star Wars VI - Return of the Jedi   \n",
       "2802  Star Wars VI - Return of the Jedi   \n",
       "2803  Star Wars VI - Return of the Jedi   \n",
       "2828  Star Wars VI - Return of the Jedi   \n",
       "2830  Star Wars VI - Return of the Jedi   \n",
       "\n",
       "                                                   line  character  \n",
       "11        Where are those transmissions youintercepted?          1  \n",
       "12                  What have you done with thoseplans?          1  \n",
       "14    If this is a consular ship... were is the Amba...          1  \n",
       "15    Commander, tear this ship apartuntil you've fo...          1  \n",
       "44    Don't play games with me, Your Highness. You w...          1  \n",
       "...                                                 ...        ...  \n",
       "2800                     You cannot hide forever, Luke.          1  \n",
       "2802  Give yourself to the dark side. It is the only...          1  \n",
       "2803  Sister! So...you have a twinsister. Your feeli...          1  \n",
       "2828                  Luke, help me take this mask off.          1  \n",
       "2830  Nothing can stop that now. Just for once... le...          1  \n",
       "\n",
       "[161 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_df[series_df['character']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_df = series_df[['character', 'line']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Did you hear that? They've shutdown the main r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>We're doomed!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>There'll be no escape for thePrincess this time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>What's that?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I should have known better than to trust the l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2841</th>\n",
       "      <td>0</td>\n",
       "      <td>He wasn't. I can feel it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2842</th>\n",
       "      <td>0</td>\n",
       "      <td>You love him, don't you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2843</th>\n",
       "      <td>0</td>\n",
       "      <td>Yes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2844</th>\n",
       "      <td>0</td>\n",
       "      <td>All right. I understand. Fine. When he comes b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2845</th>\n",
       "      <td>0</td>\n",
       "      <td>Oh. No, it's not like that at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2846 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      character                                               line\n",
       "0             0  Did you hear that? They've shutdown the main r...\n",
       "1             0                                      We're doomed!\n",
       "2             0   There'll be no escape for thePrincess this time.\n",
       "3             0                                       What's that?\n",
       "4             0  I should have known better than to trust the l...\n",
       "...         ...                                                ...\n",
       "2841          0                          He wasn't. I can feel it.\n",
       "2842          0                           You love him, don't you?\n",
       "2843          0                                               Yes.\n",
       "2844          0  All right. I understand. Fine. When he comes b...\n",
       "2845          0                 Oh. No, it's not like that at all.\n",
       "\n",
       "[2846 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded lines not found, from_saved_embeddings set to False\n"
     ]
    }
   ],
   "source": [
    "# if it cannot find sentence embeddings, set from_saved_embeddings = True\n",
    "if not os.path.exists(os.path.join(character_folder, character_dict[character]['encoded_lines_filename'])):\n",
    "    from_saved_embeddings = False\n",
    "    print('Encoded lines not found, from_saved_embeddings set to False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "if not from_saved_embeddings:\n",
    "    sentence_transformer = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▉                                                                              | 67/2846 [00:13<08:18,  5.58it/s]"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_944/3696028294.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfrom_saved_embeddings\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mseries_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoded_line'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msentence_transformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'line'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# save sentences dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_944/3696028294.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfrom_saved_embeddings\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mseries_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoded_line'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msentence_transformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'line'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# save sentences dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mstart_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Batches\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[0msentences_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentences_sorted\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_to_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[0mTokenizes\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m         \"\"\"\n\u001b[1;32m--> 318\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_sentence_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[0mbatch1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mtext_tuple\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m                 \u001b[0mbatch1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_tuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m                 \u001b[0mbatch2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_tuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m             \u001b[0mto_tokenize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "if not from_saved_embeddings:\n",
    "\n",
    "    series_df['encoded_line'] = [sentence_transformer.encode(line) for line in tqdm(series_df['line'])]\n",
    "\n",
    "    # save sentences dataset\n",
    "    series_df[['line', 'character']].to_csv(\n",
    "        os.path.join(character_folder, character_dict[character]['classifier_df']), \n",
    "        index = False\n",
    "    )\n",
    "\n",
    "    np.save(\n",
    "        os.path.join(character_folder, character_dict[character]['encoded_lines_filename']),\n",
    "        series_df['encoded_line'].to_numpy()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read sentences dataaset\n",
    "series_df = pd.read_csv(\n",
    "    os.path.join(character_folder, character_dict[character]['classifier_df']),\n",
    "    dtype={'line': str,\n",
    "           'character': int\n",
    "          }\n",
    ")\n",
    "\n",
    "series_df['encoded_line'] = np.load(\n",
    "    os.path.join(character_folder, character_dict[character]['encoded_lines_filename']), \n",
    "    allow_pickle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "series_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_train_df, series_test_df = train_test_split(series_df, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_train_df, series_val_df = train_test_split(series_train_df, test_size = 1-train_size-tes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplet_df(series_df, n_shuffles=1):\n",
    "    \n",
    "    # separate character from others\n",
    "    series_df_1 = series_df[series_df['character']==1].copy()\n",
    "    series_df_0 = series_df[series_df['character']==0].copy()\n",
    "    \n",
    "    df_rows = {'character':[], 'encoded_lines':[]}\n",
    "    \n",
    "    for _ in range(n_shuffles):\n",
    "        # shuffle dataset\n",
    "        series_df_1 = series_df_1.sample(frac=1).reset_index(drop=True)\n",
    "        series_df_0 = series_df_0.sample(n=len(series_df_1)).reset_index(drop=True)\n",
    "        \n",
    "        for i in tqdm(range(2,len(series_df_1))):\n",
    "            # character\n",
    "            lines = list(series_df_1['encoded_line'][i-2:i+1])\n",
    "            lines = np.concatenate(lines)\n",
    "            df_rows['character'].append(1)\n",
    "            df_rows['encoded_lines'].append(lines)\n",
    "\n",
    "            # other\n",
    "            lines = list(series_df_0['encoded_line'][i-2:i+1])\n",
    "            lines = np.concatenate(lines)\n",
    "            df_rows['character'].append(0)\n",
    "            df_rows['encoded_lines'].append(lines)\n",
    "\n",
    "    df = pd.DataFrame(data=df_rows)\n",
    "    \n",
    "    return df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shuffled_df = get_triplet_df(series_df, n_shuffles=n_shuffles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shuffled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Classification Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_len = len(shuffled_df)\n",
    "train_len = int(tot_len*train_size)\n",
    "test_len = int(tot_len*test_size)\n",
    "val_len = tot_len - train_len - test_len\n",
    "\n",
    "print(tot_len, train_len, test_len, val_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading training data...')\n",
    "X_train = np.array([[float(e) for e in s] for s in tqdm(shuffled_df['encoded_lines'][:train_len])])\n",
    "y_train = np.array([c for c in tqdm(shuffled_df['character'][:train_len])])\n",
    "\n",
    "print('Loading test data...')\n",
    "X_test = np.array([[float(e) for e in s] for s in tqdm(shuffled_df['encoded_lines'][:test_len])])\n",
    "y_test = np.array([c for c in tqdm(shuffled_df['character'][:test_len])])\n",
    "\n",
    "print('Loading validation data...')\n",
    "X_val = np.array([[float(e) for e in s] for s in tqdm(shuffled_df['encoded_lines'][:val_len])])\n",
    "y_val = np.array([c for c in tqdm(shuffled_df['character'][:val_len])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute some statistics\n",
    "train_percentage_1 = len(y_train[y_train==1])/len(y_train)\n",
    "train_percentage_0 = len(y_train[y_train==0])/len(y_train)\n",
    "\n",
    "val_percentage_1 = len(y_val[y_val==1])/len(y_val)\n",
    "val_percentage_0 = len(y_val[y_val==0])/len(y_val)\n",
    "print('\\t0 (%)\\t\\t1 (%)')\n",
    "print('train\\t{:.2f}\\t\\t{:.2f}'.format(train_percentage_0, train_percentage_1))\n",
    "print('val\\t{:.2f}\\t\\t{:.2f}'.format(val_percentage_0, val_percentage_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import keras/tensorflow libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "def create_model():\n",
    "    inputs = keras.Input(shape=(len(X_train[0],)))\n",
    "    \n",
    "    x = layers.Dense(\n",
    "        1024,\n",
    "        activation='relu',\n",
    "        # kernel_regularizer=regularizers.l2(regularizer_weight),\n",
    "        # bias_regularizer=regularizers.l2(regularizer_weight)\n",
    "    )(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Dense(\n",
    "        1024,\n",
    "        activation='relu',\n",
    "        # kernel_regularizer=regularizers.l2(regularizer_weight),\n",
    "        # bias_regularizer=regularizers.l2(regularizer_weight)\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Dense(\n",
    "        512, \n",
    "        activation='relu',\n",
    "        # kernel_regularizer=regularizers.l2(regularizer_weight),\n",
    "        # bias_regularizer=regularizers.l2(regularizer_weight)\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Dense(\n",
    "        256, \n",
    "        activation='relu',\n",
    "        # kernel_regularizer=regularizers.l2(regularizer_weight),\n",
    "        # bias_regularizer=regularizers.l2(regularizer_weight)\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Dense(\n",
    "        128, \n",
    "        activation='relu',\n",
    "        kernel_regularizer=regularizers.l2(regularizer_weight_r),\n",
    "        bias_regularizer=regularizers.l2(regularizer_weight_r)\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    out = layers.Dense(\n",
    "        1, \n",
    "        activation='sigmoid',\n",
    "        kernel_regularizer=regularizers.l2(regularizer_weight_s),\n",
    "        bias_regularizer=regularizers.l2(regularizer_weight_s)\n",
    "    )(x)\n",
    "\n",
    "\n",
    "    classifier_model = keras.Model(inputs, out)\n",
    "    classifier_model.compile(\n",
    "        loss = keras.losses.BinaryCrossentropy(),\n",
    "        optimizer = keras.optimizers.Adam(learning_rate = lr),\n",
    "        metrics = [keras.metrics.BinaryAccuracy(), keras.metrics.Recall()]\n",
    "    )\n",
    "    return classifier_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop_callback = callbacks.EarlyStopping(\n",
    "        monitor=\"val_binary_accuracy\",\n",
    "        min_delta=0,\n",
    "        patience=6,\n",
    "        verbose=0,\n",
    "        mode=\"max\",\n",
    "        baseline=None,\n",
    "        restore_best_weights=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_history = classifier_model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    validation_data = (X_val, y_val),\n",
    "    epochs= epochs,\n",
    "    verbose = 1, \n",
    "    callbacks=[earlystop_callback],\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('#'*25 + ' Model Test ' + '#'*25)\n",
    "fig, ax=plt.subplots(1,1,figsize=(5,5))\n",
    "y_pred = classifier_model.predict(X_test).round()\n",
    "# Plot the confusion matrix normalizing over the true values (over the rows)\n",
    "cm = confusion_matrix(y_test, y_pred) #, normalize='pred')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Others', character])\n",
    "disp.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_path = os.path.join(character_folder, character_dict[character]['classifier_name']+version)\n",
    "classifier_model.save(classifier_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save history as a JSON file\n",
    "import json\n",
    "filename = character.lower() + '_training_history' + version + '.json'\n",
    "\n",
    "output_string = json.dumps(train_history.history)\n",
    "with open(os.path.join(character_folder, filename), 'w') as file:\n",
    "    file.write(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if shutdown_at_end:\n",
    "    os.system('shutdown /' + shutdown_at_end)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

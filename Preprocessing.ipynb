{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "character = 'Fry' # 'Barney' | 'Sheldon' | 'Harry' | 'Fry' | 'Vader' | 'Joey' | 'Phoebe' | 'Default'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dict = {\n",
    "    'HIMYM':{\n",
    "        'dataset_folder': 'Episodes',\n",
    "    },\n",
    "    'Futurama':{\n",
    "        'dataset_folder': 'Episodes',\n",
    "    },\n",
    "    'Friends':{\n",
    "        'dataset_folder': None,\n",
    "    },\n",
    "    'HP':{\n",
    "        'dataset_folder': None,\n",
    "    },\n",
    "    'SW':{\n",
    "        'dataset_folder': 'Scripts',\n",
    "    },\n",
    "    'TBBT':{\n",
    "        'dataset_folder': 'Episodes',\n",
    "    },\n",
    "}\n",
    "\n",
    "character_dict = {\n",
    "    'Barney': {\n",
    "        'source':'HIMYM',\n",
    "        'delete_names':[\"Barney's Secretary\",\n",
    "                        'Marshall to Barney',\n",
    "                        \"Barney's mom\",\n",
    "                        'Ted, from seeing Barney',\n",
    "                        'Lily, holding Barney',\n",
    "                        'Marshall, on the phone with Barney',\n",
    "                        \"At Casa a pezzi. Barney is playing the piano.Ted's father\",\n",
    "                        'Marshall, to the girl Barney is talking to']\n",
    "    },\n",
    "    'Sheldon': {\n",
    "        'source':'TBBT',\n",
    "        'delete_names':[]\n",
    "    },\n",
    "    'Harry': {\n",
    "        'source':'HP',\n",
    "        'delete_names':[]\n",
    "    },\n",
    "    'Fry': {\n",
    "        'source':'Futurama',\n",
    "        'delete_names':['Mrs fry',\n",
    "                        'Mr fry',\n",
    "                        'Luck of the fryrish']\n",
    "    },\n",
    "    'Vader': {\n",
    "        'source':'SW',\n",
    "        'delete_names':[\"INT. DARTH VADER'S WINGMAN - COCKPIT\"]\n",
    "    },\n",
    "    'Joey': {\n",
    "        'source':'Friends',\n",
    "        'delete_names':[\"Joeys Sisters\",\n",
    "                        'Joey\\'s Date', \n",
    "                        \"Joey's Look-A-Like\", \n",
    "                        'Joeys Sister', \n",
    "                        \"Joey's Doctor\", \n",
    "                        \"Joey's Hand Twin\", \n",
    "                        'Joeys Date', \n",
    "                        'Joeys Grandmother']\n",
    "    },\n",
    "    'Phoebe': {\n",
    "        'source':'Friends',\n",
    "        'delete_names':['Amy turns around to Phoebe',\n",
    "                        'Phoebe Waitress']\n",
    "    },\n",
    "    'Default':None\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if character != 'Default':\n",
    "    source = character_dict[character]['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount google drive (for Colab only)\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive',force_remount=True)\n",
    "    base_folder = '/content/drive/My Drive/unibo/NLP_project/BarneyBot'\n",
    "else:\n",
    "    base_folder = os.getcwd()\n",
    "    \n",
    "in_folder = os.path.join(base_folder, \"Data\", 'Characters', character)\n",
    "if not os.path.exists(in_folder):\n",
    "    os.makedirs(in_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the dataset documents and store their data into a DataFrame\n",
    "def load_dataset():\n",
    "    def _load_himym_friends_tbbt_dataset(sources_folder):\n",
    "        dataframe_rows = []\n",
    "        # Get number of documents and their names\n",
    "        documents_n = len(os.listdir(sources_folder))\n",
    "        documents_names = os.listdir(sources_folder)\n",
    "        # Loop over documents\n",
    "        for i in tqdm(range(documents_n)):\n",
    "            filename = documents_names[i]\n",
    "            sources_label = filename[:-4]\n",
    "            # Open document\n",
    "            with open(os.path.join(sources_folder, filename), encoding=\"utf8\") as file:\n",
    "                # Loop over lines (= words)\n",
    "                for line in file.readlines():\n",
    "                        dataframe_row = {\n",
    "                            \"source\": sources_label,\n",
    "                            \"line\": line,\n",
    "                        }\n",
    "                        dataframe_rows.append(dataframe_row)\n",
    "        # Build the dataframe from the words\n",
    "        df = pd.DataFrame(dataframe_rows)\n",
    "        return df\n",
    "    def _load_futurama_dataset(sources_folder):\n",
    "        futurama_txt = ''\n",
    "        # Loop over documents\n",
    "        for filename in tqdm(os.listdir(sources_folder)):\n",
    "            futurama_txt += open(os.path.join(sources_folder, filename)).read()\n",
    "        # Split lines\n",
    "        start_idx = 0\n",
    "        end_idx = 0\n",
    "        lines = []\n",
    "        while start_idx < len(futurama_txt):\n",
    "            start_idx = futurama_txt.find('<b>', end_idx)\n",
    "            if start_idx == -1: # if no '<b>' is found, just save the rest\n",
    "                lines.append(futurama_txt[end_idx:].replace('</b>',''))\n",
    "                break\n",
    "            elif start_idx != end_idx: # '<b>' is found\n",
    "                lines.append(futurama_txt[end_idx+4:start_idx])\n",
    "            end_idx = futurama_txt.find('</b>', start_idx)\n",
    "            if end_idx == -1: # if no '</b>' is found, just save the rest\n",
    "                lines.append(futurama_txt[start_idx:].replace('<b>',''))\n",
    "                break\n",
    "            lines.append(futurama_txt[start_idx+3:end_idx])\n",
    "        df = pd.DataFrame(lines, columns=['line'])\n",
    "        return df\n",
    "    def _load_hp_dataset(sources_folder):\n",
    "        sep = ';'\n",
    "        df = None\n",
    "        df_files = []\n",
    "        for filename in os.listdir(sources_folder):\n",
    "            df_files.append(pd.read_csv(os.path.join(sources_folder, filename), sep=sep).rename(columns = lambda x: x.lower()))\n",
    "        df = pd.concat(df_files)\n",
    "        df = df.rename(columns = {'character':'character', 'sentence':'line'})\n",
    "        return df\n",
    "    def _load_sw_dataset(source_folder):\n",
    "        dataframe_rows = []\n",
    "        # Get number of documents and their names\n",
    "        documents_n = len(os.listdir(source_folder))\n",
    "        documents_names = os.listdir(source_folder)\n",
    "        # Loop over documents\n",
    "        for i in tqdm(range(documents_n)):\n",
    "            filename = documents_names[i]\n",
    "            film_name = filename[:-4]\n",
    "            # Open document\n",
    "            with open(os.path.join(source_folder, filename)) as file:\n",
    "                film_rows = []\n",
    "                sentence = \"\"\n",
    "                empty_line_allow = False\n",
    "                between_numbers = False\n",
    "                found_character = False\n",
    "                for line in file.readlines():\n",
    "                    if re.search(r\"^[0-9]+.\", line) != None: # Line is number followed by dot (page number)\n",
    "                        pass\n",
    "                    elif re.search(r\"^[A-Z]{2,}\", line) != None: # Line begins with an-all caps (a character)\n",
    "                        sentence += line\n",
    "                        found_character = True\n",
    "                        empty_line_allow = True\n",
    "                    elif line.isspace():\n",
    "                        if empty_line_allow:\n",
    "                            pass\n",
    "                        else:\n",
    "                            if found_character:\n",
    "                                film_row = {\n",
    "                                    \"film\": film_name,\n",
    "                                    \"line\": sentence,\n",
    "                                }\n",
    "                                film_rows.append(film_row)\n",
    "                                sentence = \"\"\n",
    "                                found_character = False\n",
    "                    elif found_character:\n",
    "                        sentence += line\n",
    "                        empty_line_allow = False\n",
    "                dataframe_rows.extend(film_rows)\n",
    "        # Build the dataframe from the words\n",
    "        df = pd.DataFrame(dataframe_rows)\n",
    "        return df\n",
    "    ### Function starts here\n",
    "    if character == 'Default':\n",
    "        return None\n",
    "    sources_subfolder = source_dict[source]['dataset_folder']\n",
    "    if sources_subfolder:\n",
    "        sources_folder = os.path.join(base_folder, \"Data\", \"Sources\", source, sources_subfolder)\n",
    "    else:\n",
    "        sources_folder = os.path.join(base_folder, \"Data\", \"Sources\", source)\n",
    "    if source == 'HIMYM' or source == 'Friends' or source == 'TBBT':\n",
    "        df = _load_himym_friends_tbbt_dataset(sources_folder)\n",
    "    elif source == 'Futurama':\n",
    "        df = _load_futurama_dataset(sources_folder)\n",
    "    elif source == 'HP':\n",
    "        df = _load_hp_dataset(sources_folder)\n",
    "    elif source == 'SW':\n",
    "        df = _load_sw_dataset(sources_folder)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 72/72 [00:02<00:00, 34.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Dataset!\n",
      "\n",
      "                                                line\n",
      "0                                              >\\n\\n\n",
      "1                                          FUTURA...\n",
      "2  \\n                                       Episo...\n",
      "3                                     \"SPACE PILO...\n",
      "4  \\n                                           B...\n",
      "line    113015\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Execute creation of dataset\n",
    "df = load_dataset()\n",
    "if not isinstance(df, type(None)):\n",
    "    print(\"Loaded Dataset!\")\n",
    "    print()\n",
    "    print(df.head())\n",
    "    print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "def process_dataset(df):\n",
    "    def _process_himym_dataset(df):\n",
    "        df = df[~df['line'].str.startswith(\"[\")]\n",
    "        df = df[~df['line'].str.startswith(\"(\")]\n",
    "        df['line'] = df['line'].str.strip()\n",
    "        df['line'] = df['line'].str.replace(r\"\\(.*\\)\",\"\")\n",
    "        df['line'] = df['line'].str.replace(r\"[\\/(){}\\[\\]\\|@_#]|\\\\t|\\\\n\",\" \")\n",
    "        df['line'] = df['line'].str.replace(r\"[^.\\',;:?!0-9a-zA-Z \\-]\",\"\")\n",
    "        df = df[~df['line'].isnull()]\n",
    "        df[['character', 'line']] = df['line'].str.split(\":\", 1, expand=True)\n",
    "        df = df.dropna()\n",
    "        df['line'] = df['line'].str.strip()\n",
    "        df['line'] = df['line'][df['line'].str.len() >= 2]\n",
    "        df = df[~df['line'].isnull()]\n",
    "        df = df.dropna()\n",
    "        df = df.reset_index(drop=True)\n",
    "        return df\n",
    "    def _process_tbbt_dataset(df):\n",
    "        df = df[~df['line'].str.startswith(\"[\")]\n",
    "        df = df[~df['line'].str.startswith(\"(\")]\n",
    "        df = df[~df['line'].str.startswith(\"Scene: \")]\n",
    "        df['line'] = df['line'].str.strip()\n",
    "        df['line'] = df['line'].str.replace(r\"\\(.*\\)\",\"\")\n",
    "        df['line'] = df['line'].str.replace(r\"[\\/(){}\\[\\]\\|@_#]|\\\\t|\\\\n\",\" \")\n",
    "        df['line'] = df['line'].str.replace(r\"[^.\\',;:?!0-9a-zA-Z \\-]\",\"\")\n",
    "        df = df[~df['line'].isnull()]\n",
    "        df[['character', 'line']] = df['line'].str.split(\":\", 1, expand=True)\n",
    "        df = df.dropna()\n",
    "        df['line'] = df['line'].str.strip()\n",
    "        df['line'] = df['line'][df['line'].str.len() >= 2]\n",
    "        df = df[~df['line'].isnull()]\n",
    "        df = df.dropna()\n",
    "        df = df.reset_index(drop=True)\n",
    "        return df\n",
    "    def _process_futurama_dataset(df):\n",
    "        df['line'] = df['line'].str.strip()\n",
    "        df['line'] = df['line'].str.replace(r\"\\[.*\\]\",\"\")\n",
    "        df['line'] = df['line'].str.replace(r\"\\(.*\\)\",\"\")\n",
    "        df['line'] = df['line'].str.replace(r\"\\<.*\\>\",\"\")\n",
    "        df['line'] = df['line'].str.replace(r\"\\s+\",\" \")\n",
    "        df['line'] = df['line'].str.replace(\"\\n\",\"\")\n",
    "        df = df[~df['line'].str.startswith(\"(\")]\n",
    "        df = df[~df['line'].str.startswith(\"[\")]\n",
    "        df['line'] = df['line'].str.replace(r\"[\\/(){}\\[\\]\\|@_#]|\\\\t|\\\\n\",\" \")\n",
    "        df['line'] = df['line'].str.replace(r\"[^.\\',;:?!0-9a-zA-Z \\-]\",\"\")\n",
    "        df['line'] = df['line'][df['line'].str.len() >= 2]\n",
    "        df = df.dropna()\n",
    "        df = df.reset_index(drop=True)\n",
    "        print(df.head())\n",
    "        print(len(df))\n",
    "        df_rows = []\n",
    "        for row in tqdm(range(len(df)-1)):\n",
    "            if df['line'][row].isupper():\n",
    "                df_row = {\n",
    "                    'line': df['line'][row+1].strip()[:512],\n",
    "                    'character': df['line'][row].strip().capitalize()\n",
    "                }\n",
    "                df_rows.append(df_row)\n",
    "        df = pd.DataFrame(df_rows)\n",
    "        df = df[df['character'].str.contains('Futurama')==False]\n",
    "        df = df.dropna()\n",
    "        df = df.reset_index(drop=True)\n",
    "        return df\n",
    "    def _process_friends_dataset(df):\n",
    "        df = df[~df['line'].str.startswith(\"[\")]\n",
    "        df = df[~df['line'].str.startswith(\"(\")]\n",
    "        df['line'] = df['line'].str.strip()\n",
    "        df['line'] = df['line'].str.replace(r\"\\(.*\\)\",\"\")\n",
    "        df['line'] = df['line'].str.replace(r\"[\\/(){}\\[\\]\\|@_#]|\\\\t|\\\\n\",\" \")\n",
    "        df['line'] = df['line'].str.replace(r\"[^.\\',;:?!0-9a-zA-Z \\-]\",\"\")\n",
    "        df = df[~df['line'].isnull()]\n",
    "        df[['character', 'line']] = df['line'].str.split(\":\", 1, expand=True)\n",
    "        df = df.dropna()\n",
    "        df['line'] = df['line'].str.strip()\n",
    "        df['line'] = df['line'][df['line'].str.len() >= 2]\n",
    "        df = df[~df['line'].isnull()]\n",
    "        df = df[~(df['character'] == 'Written by')]\n",
    "        df = df.dropna()\n",
    "        df = df.reset_index(drop=True)\n",
    "        return df\n",
    "    def _process_sw_dataset(df):\n",
    "        df = df[~df['line'].str.startswith(\"[\")]\n",
    "        df = df[~df['line'].str.startswith(\"(\")]\n",
    "        df['line'] = df['line'].str.strip()\n",
    "        df['line'] = df['line'].str.replace(r\"\\(.*\\)\",\"\")\n",
    "        df[['character', 'line']] = df['line'].str.split(\"\\n\", 1, expand=True)\n",
    "        df['line'] = df['line'].str.replace(r\"[\\/(){}\\[\\]\\|@_#]|\\\\t|\\\\n\",\" \")\n",
    "        df['line'] = df['line'].str.replace(r\"[^.\\',;:?!0-9a-zA-Z \\-]\",\"\")\n",
    "        df = df[~df['line'].isnull()]\n",
    "        df = df[df['character'].str.split().apply(lambda l: len(l)) <= 6]\n",
    "        df = df.dropna()\n",
    "        df = df.reset_index(drop=True)\n",
    "        return df\n",
    "    def _process_hp_dataset(df):\n",
    "        df['line'] = df['line'].str.strip()\n",
    "        df['line'] = df['line'].str.replace(r\"\\(.*\\)\",\"\")\n",
    "        df['line'] = df['line'].str.replace(r\"[\\/(){}\\[\\]\\|@_#]|\\\\t|\\\\n\",\" \")\n",
    "        df['line'] = df['line'].str.replace(r\"[^.\\',;:?!0-9a-zA-Z \\-]\",\"\")\n",
    "        df = df[~df['line'].isnull()]\n",
    "        df = df.dropna()\n",
    "        df['line'] = df['line'].str.strip()\n",
    "        df['character'] = [line.lower() for line in df['character']]\n",
    "        df = df[~df['line'].isnull()]\n",
    "        df = df.dropna()\n",
    "        df = df.reset_index(drop=True)\n",
    "        return df\n",
    "    # Function starts here\n",
    "    if character == 'Default':\n",
    "        return None\n",
    "    if source == 'HIMYM':\n",
    "        df = _process_himym_dataset(df)\n",
    "    elif source == 'Friends':\n",
    "        df = _process_friends_dataset(df)\n",
    "    elif source == 'Futurama':\n",
    "        df = _process_futurama_dataset(df)\n",
    "    elif source == 'TBBT':\n",
    "        df = _process_tbbt_dataset(df)\n",
    "    elif source == 'HP':\n",
    "        df = _process_hp_dataset(df)\n",
    "    elif source == 'SW':\n",
    "        df = _process_sw_dataset(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                line\n",
      "0                                           FUTURAMA\n",
      "1                                        Episode 101\n",
      "2                                   SPACE PILOT 3000\n",
      "3  By David X. Cohen amp; Matt Groening Transcrib...\n",
      "4                                                MAN\n",
      "30614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 30613/30613 [00:00<00:00, 64857.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Dataset into line-character format!\n",
      "\n",
      "                                                line         character\n",
      "0  By David X. Cohen amp; Matt Groening Transcrib...  Space pilot 3000\n",
      "1  Space. It seems to go on and on forever. But t...               Man\n",
      "2                  And that's how you play the game!               Fry\n",
      "3                                  You stink, loser!               Kid\n",
      "4                 Hey, Fry. Pizza goin' out! C'mon!!           Panucci\n",
      "15226\n"
     ]
    }
   ],
   "source": [
    "df = process_dataset(df)\n",
    "if not isinstance(df, type(None)):\n",
    "    print(\"Processed Dataset into line-character format!\")\n",
    "    print()\n",
    "    print(df.head())\n",
    "    print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters contanining Fry : {'Fry', 'Spanish fry', 'Mrs fry', 'Fry 1', 'Fry and the slurm factory', 'Future fry', \"Fry's photo\", 'Fry and zoidberg', 'Holo-fry', 'Mr fry', 'Fry and bender', 'Fry 1729', 'Past fry', 'Fry leela and bender', 'Luck of the fryrish', 'The why of fry'} 2746\n"
     ]
    }
   ],
   "source": [
    "if not isinstance(df, type(None)):\n",
    "    char_names = [c for c in df['character'] if character.lower() in c.lower()]\n",
    "    print(\"Characters contanining\", character, \":\", set(char_names), len(char_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not isinstance(df, type(None)):\n",
    "    char_names = set(char_names) - set(character_dict[character]['delete_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not isinstance(df, type(None)):\n",
    "    df['character'] = df['character'].apply(lambda x: character if x in char_names else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique character names in dataset after name processing: ['Space pilot 3000' 'Man' 'Fry' 'Kid' 'Panucci' 'Michelle' 'Bike thief'\n",
      " 'Crowd' 'Lou' 'Terry' 'Woman' 'Leela' 'Man  1' 'Man  2' 'Robot'\n",
      " 'Booth voice' 'Bender' 'Ipgee' 'Smitty' 'Nimoy' 'Url.' 'Nixon' 'Url'\n",
      " 'Clark' 'Farnsworth' 'Aliens' 'The end' 'The series has landed'\n",
      " 'Announcer' 'Evans' 'Hermes' 'Zoidberg' 'Amy' 'Fansworth' 'Sal'\n",
      " 'Crater face' 'Whalerbots' 'Whalerbot' 'Gopher  1' 'Gopher  2' 'Narrator'\n",
      " 'Ralph kramdenbot' 'Gophers' 'Farmer' 'Lulabelle 7' 'Daisy-mae 128k'\n",
      " 'Crushinator' 'I, robot' 'Tv.' 'Commentator' 'Calculon' 'Monique'\n",
      " 'Human friend' 'Landlord  1' 'Landlord  3' 'Hattie' 'Priestbot'\n",
      " 'Tenant  1' 'Tenant  2' 'Randy' 'Tenant  3'\n",
      " \"Love's labours lost in space\" 'Doug' 'Bolt' 'M-5438' 'Janitor'\n",
      " 'Computer voice' 'Zapp' 'Kif' 'Crewman' 'Fear of a bot planet' 'Umpire'\n",
      " 'Vendor' 'Holo-hermes' 'Guardbot  1' 'Guardbot  2' 'Constructionbot'\n",
      " 'Patrol officer  1' 'Patrol officer  2' 'Rusty' 'Wendy' 'Human'\n",
      " 'Army robot' 'Robot  1' 'Robot  2' 'Robot  3' 'Robot  4' 'Robot  5'\n",
      " 'Robot mayor' 'Bender figurine' 'Robot  6' 'Judge' 'Robot bailiff'\n",
      " 'Blue elder' 'Red elder' 'Green elder' 'Yellow elder' 'Elders'\n",
      " 'Orange elder' 'Robot  7' 'Robot  8' 'A fishful of dollars' 'Teacher'\n",
      " 'Saleswoman' 'Cosmetologist' 'Salesman' 'Mom' 'Teller' 'Robot chef'\n",
      " 'Auctioneer' 'Decapodian woman' 'Bidder  1' 'Bidder  2' 'Walt' 'Larry'\n",
      " 'Igner' 'Fred' 'Anderson' 'Repobot' 'My three suns' 'Elzar'\n",
      " 'Crack addict' 'Organ dealer' 'Alien' 'Nurse' 'Guard  1' 'Guard  2'\n",
      " 'Guard  3' 'Guards' 'Merg' 'Gorgak' 'Florp' 'Bont' 'Operator'\n",
      " 'A big piece of garbage' 'Wernstrom' 'Waiter' 'Popeil' 'Female scientist'\n",
      " 'Male scientist' 'Poopenmeyer' 'Linda' 'Morbo' 'Military man' 'Doll'\n",
      " 'Hell is other robots' 'Beastie boys' 'Mike' 'Mca' 'Ad-rock' 'Fender'\n",
      " 'Preacherbot' 'Hookerbot' 'Robot devil' 'A flight to remember' 'Ok!'\n",
      " 'Croupier' 'Izac' 'Countess' 'Mrs. wong' 'Mr wong' 'Mrs wong' 'Labarbara'\n",
      " 'Boy' 'Mars university' 'Fratbot  1' 'Fratbot  2' 'Fratbot  3' 'Oily'\n",
      " 'Fatbot' 'Gearshift' 'Meiderneyer' 'Chet' 'Monkey' 'Guenter' 'Vernon'\n",
      " 'Chrissy' 'Mr. wong' 'Student' 'When aliens attack' 'Technician'\n",
      " 'Single female lawyer' 'Stenographer' 'Lrrr' 'Fox announcer' 'Bully'\n",
      " 'Mcneal' 'Nd-nd' 'Announcer  1' 'Announcer  2' 'Babe' 'Dixie' 'Slurms'\n",
      " 'Slurm announcer  2' 'Fembot' 'Glurmo' 'Grunka lunkas' 'Grunka lunka  1'\n",
      " 'Grunka lunka  2' 'Glermo' 'Slurm queen' 'Small glurmo  2'\n",
      " 'Small glurmo  1' 'Commissioner' 'I second that emotion' 'Jeffery' 'All'\n",
      " 'Doctorbot' 'Vyolet' 'Dwayne' 'Raoul' 'Vyloet' 'Brannigan, begin again'\n",
      " 'Glab' 'Amazonian' 'Neutral president' 'Hyper-chicken' 'Juror  1'\n",
      " 'Juror  2' 'Neptunian' 'A head in the polls' 'Johnson' 'Jackson'\n",
      " 'Stoned guy' 'N.r.a. man' 'V.a.p. man' 'Mine spokesman' 'Pawnbroker'\n",
      " 'Schiffer' 'Clinton' 'Ford' 'Washington' 'Bush sr.' 'Carter' 'Dole'\n",
      " 'Journalist  1' 'Chang' 'Campaign manager' 'Xmas story' \"O'brien\" 'Trees'\n",
      " 'Child' 'Salesman  1' 'Tinny tim' 'Salesman  2' 'Santa' 'Robots'\n",
      " 'Farnsowrth' 'Why must i be a crustacean in love?' 'Singers' 'Plumberbot'\n",
      " 'Nautilus' 'Decapod manm  1' 'Decapod man  1' 'Decapod man  2'\n",
      " 'Decapod woman  1' 'Decapod woman  2' 'Decapod woman  3' 'Edna'\n",
      " 'Decapod emperor' 'Put your head on my shoulder' 'Lincoln'\n",
      " 'Malfunctioning eddie' 'Victor' 'Mechanic' 'Gary' 'Petunia'\n",
      " 'The lesser of two evils' \"Alien's wife\" 'Cowboy' 'Einstein' 'Hammurabi'\n",
      " 'Mugger' 'Stockbroker  1' 'Stockbroker  2' 'Tour guide' 'Bending unit'\n",
      " 'Flexo' 'Stripperbot' 'Barker' 'Women' 'Raging bender' 'Refreshment-bot'\n",
      " 'Crow t. robot' 'Chair' 'Doubledeal' 'Flabby' 'Fnog' 'Bill' 'Referee'\n",
      " 'Clearcutter' 'Foreigner' 'Chain smoker' 'Fembot  1' 'Billionairebot'\n",
      " 'Destructor' 'Cosell' 'Foreman' 'Little' 'A bicyclops built for two'\n",
      " 'Younger kid' 'Nerd  1' 'Nerd  2' 'Nerds' 'Nerd  3' 'Nerd  4' 'Cyclops'\n",
      " 'Voice' 'Alkazar' 'Cyclopian' 'Scientist' 'Rat woman' 'Pig' '5-eyes'\n",
      " 'Sandy' 'Thing  2' 'How hermes requisitioned his groove back' 'Morgan'\n",
      " 'Australian guy' 'Old man' 'Grade 53' 'Grade 41' 'Ok.' 'Grade 20'\n",
      " 'Wrist thing' 'Grade 11' 'Number 1.0' 'Everybody' 'Bureacrats'\n",
      " 'A clone of my own' 'Cubert' 'Universal translator' 'Holo-farnsworth'\n",
      " 'Barrierbot  1' 'Barrierbot  2' 'Guardbot  3' 'Guardbot  4'\n",
      " 'The deep south' 'Mermaid' 'Umbriel' 'Merman' 'Colonel' 'Donovan'\n",
      " 'Mermaids' 'Bender gets made' \"Hattie's doctor\" 'Doctor' 'Donbot'\n",
      " 'Clamps' 'Joey' 'Waitress' 'The problem with popplers' 'Jingle' 'Gillman'\n",
      " 'Hippie  1' 'Hippie  2' 'Waterfall jr.' 'Poppler' 'Smartly-dressed man'\n",
      " 'Woman  1' 'Woman  2' 'Jrrr' \"Mother's day\" 'Greeting card' 'Janitorbot'\n",
      " 'Mom cut-out' 'Betamax player' 'Coffee machine' 'Garbage disposal'\n",
      " 'Q.t. mcwhiskers' 'Slurm machine' 'Ceiling fan' 'Lamp' 'Gorillas'\n",
      " 'Anthology of interest i' 'Scruffy' 'Hawking' 'Gore' 'Nichols' 'Gygax'\n",
      " 'Deep blue' 'The honking' 'Solicitorbot' 'Tandy' 'Vladimir-ghost'\n",
      " 'Robot ghosts' 'Vandal  1' 'Vandal  2' 'Gypsy' 'Yokelbot' 'S.' 'Inuitbot'\n",
      " 'Project satan' 'War is the h word' 'Clerk' 'Soldier  1' 'Hick'\n",
      " 'P.a. announcer' 'Ihawk' 'Kissenger' 'Brain ball  1' 'Brain ball  2'\n",
      " 'The cryonic woman' 'Italian  1' 'Italian  2' 'Chef' 'Shore' 'Butch'\n",
      " 'Kid  1' \"Butch's girlfriend\" 'Orowheat' 'Ice-v' \"Butch's mom\"\n",
      " 'Parasites lost' 'Trucker  1' 'Trucker  2' 'Worm mayor' 'Worm guard  1'\n",
      " 'Worm guard  2' 'Amazon women in the mood' 'Kug' 'Thog' 'Ornik'\n",
      " 'Kug and ornik' 'Femputer' 'Amazonians' 'Bendless love' 'Autopilot'\n",
      " 'Angleyne' 'Steward' 'Bartenderbot' 'The day the earth stood stupid'\n",
      " 'Judge  1' 'Ken' 'Nibbler' 'Fiona' 'Nibblonian chef' 'Arthur' 'Big brain'\n",
      " 'Ahab' 'Queequeg' 'Tom sawyer' 'Butler' \"That's lobstertainment\" 'Zoid'\n",
      " 'Rivers' 'Crystal' 'Doorman' 'The birdbot of icecatraz' 'Waterfall sr'\n",
      " 'Wiggles' 'Protestor  1' 'Protestor  2' 'Protestor  3' 'Penguin  1'\n",
      " 'Hunter  1' 'Hunter  2' 'Penguins' 'Old man waterfall'\n",
      " 'Luck of the fryrish' 'Mr fry' 'Mrs fry' 'Yancy' 'Jockey' 'Hairbot'\n",
      " 'Guy  1' 'G!' 'Guy  2' 'Noticeably f.a.t.' 'Mutant' 'Andy' \"Yancy's wife\"\n",
      " 'The cyber house rules' 'Card' 'Kids' 'Kirk' 'Vogel' 'French guy'\n",
      " 'Man  3' 'Adlai' 'Nina' 'Sally' 'Albert' 'Little boy' 'Kid  2' 'Kid  3'\n",
      " 'Insane in the mainframe' 'Franklin' 'Roberto' 'Baillif' 'Whitey'\n",
      " 'Camera' 'Bailiff' 'Dr. perceptron' 'Nurse ratchet' 'Unit 2013' 'Norm'\n",
      " 'Lincolnbot' 'Frankie' 'Mad hatterbot' \"Bendin' in the wind\"\n",
      " 'Patch cord adams' 'Beck' 'Barman' 'Emcee' 'Garfunkel'\n",
      " 'Cylon and garfunkel' 'Hippie  3' 'Hippie  4' 'Hippie  5' 'Cylon'\n",
      " 'Bender and beck' 'Hippie  6' 'Caterpillar alien'\n",
      " 'Time keeps on slipping' 'Tate' 'Arachneon' 'Thorias' 'Curly joe'\n",
      " 'Sweet clyde' 'I dated a robot' 'Smith' 'Girl' 'Mother' 'Trekkie  1'\n",
      " 'Trekkie  2' 'Liubot' 'Billy' 'Monroebot' 'Mavis' 'Jervis' 'Liu' 'Cheech'\n",
      " 'George michael' 'Nerd' 'Albrightbot' 'Liubot  2' 'Liubot  3' 'Liubot  4'\n",
      " 'Alex' 'Natalie' 'Vampire' 'Mayor' 'Roswell that ends well' 'General'\n",
      " 'Sergeant' 'Enos' 'Mildred' 'Truman' 'Doctor  2' 'Doctor  1'\n",
      " 'Conspiracy nutter' 'Ufo! ufo!' 'A tale of two santas' 'Cronkite'\n",
      " 'Neptunian  1' 'Neptunian  2' 'Neptunian  3' 'Neptunian  4' 'Neptunians'\n",
      " 'Mrs. grant' 'Kwanzaabot' 'Pramala' 'Anthology of interest ii'\n",
      " 'Wernstrum' 'Mario' 'Pac-man' 'Ms pac-man' 'Beserk' 'Donkey kong'\n",
      " 'Who ask machine' 'Love and rocket' 'Ship' 'Sheldon' 'Gwen' 'Frame  1'\n",
      " 'Frame  2' 'Fembot  2' 'Guard' \"Leela's homeworld\" 'Photographer' 'Guy'\n",
      " 'Leg mutant' 'Mutants' 'Hooded figure  1' 'Triclops' 'Octopus' 'Father'\n",
      " 'Hooded figure  2' 'Munda' 'Morris' 'Where the buggalo roam' 'Dj' 'Rj'\n",
      " 'Joe' 'Singing wind' 'Martian' 'Martian  2' 'A pharaoh to remember'\n",
      " 'Roller-skater' 'Osiran' 'Hermenthotip' 'High priest' 'Singer' 'Slave  1'\n",
      " 'Priests' 'Slaves' 'Slave  2' 'Slave  3' 'Statue' 'Priest' 'Godfellas'\n",
      " 'Pirate' 'Shrimpkin priest' 'Shrimpkins' 'Malachi' \"Malachi's wife\"\n",
      " 'Malachi jr' 'Helper' 'Farmer  1' 'Farmer  2' 'Sherpa' 'Female voice'\n",
      " 'Galaxy' 'God' 'Monk  1' 'Monk  2' 'Monk  3' 'Future stock' 'Everyone'\n",
      " 'That guy' 'Caveman' 'Monster' 'Suz' 'Lackey' 'Brokerbot  1'\n",
      " 'Brokerbot  2' 'Brokerbot  3' 'Jor-el' 'A leela of her own'\n",
      " 'Cygnoid woman' 'Cygnoid man' 'Cygnoid  2' 'Uecker' 'Cygnoid  3'\n",
      " 'Skipper' 'Man  4' 'Director' 'Jackie' 'Aaron jr' 'Aaron sr' 'Fishy joe'\n",
      " '30 iron chef' 'Hobo' 'Gus' 'Spargle' 'Ricardo' 'Customer' 'Hiroki'\n",
      " 'Koji' 'Stewart' 'Aki' 'Female announcer' 'Where no fan has gone before'\n",
      " 'Shatner' 'Takei' 'Congregation' 'Frakes' 'Koenig' 'Melllvar' 'Welshy'\n",
      " \"Melllvar's mother\" \"Melllvars's mother\" 'Crimes of the hot' 'Suzie'\n",
      " 'Gas' 'Gay sailor' 'Van' 'Dark wizard' 'Prototype' 'Audience' 'Kegg'\n",
      " 'Mic' 'Hedonismbot' 'Jurassic bark' 'Beeler' 'Ray' \"Woman's voice\"\n",
      " 'Robo-puppy' 'Cryogenisist' 'Y2k!' 'The route of all evil' 'Dwight'\n",
      " 'Bret' 'A taste of freedom' 'Decapodian man' 'Stilt people'\n",
      " 'Pain monster' 'Ambassador moivin' 'Myrtle fu' 'Scout leader'\n",
      " 'Holo-zoidberg' \"O'connor\" 'Souter' 'Scalia' 'Person' 'Ensign'\n",
      " 'Frieda waterfall' 'Scoop chang' 'Kif gets knocked up a notch' 'Moriarty'\n",
      " 'Jack the ripper' 'Evil lincoln' 'Atilla the hun' 'Midwife'\n",
      " 'Less than hero' 'Sewercom announcer' 'Pi-kea robot' 'Andrew' 'Song'\n",
      " 'Security guard' 'Zookeeper' 'Teddy roosevelt' 'Big eared mutant'\n",
      " 'Big mouthed mutant' 'Parrot' 'Bubblegum tate'\n",
      " \"Teenage mutant leela's hurdles\" 'Wanda' 'Heather' 'Moose' 'Mandy'\n",
      " 'Sibling' 'L -' 'Chaz' 'Trashcan' 'Nibblonian' 'Infosphere brain'\n",
      " 'Giant brain' 'Brain  1' 'Brain  2' 'Brain  3' 'Orphan' 'The sting' 'Bee'\n",
      " 'Captain' 'Bees' 'Queen' 'The farnsworth parabox' 'Bender 1'\n",
      " 'Farnsworth 1' 'Leela 1' 'Amy 1' 'Zoidberg 1' 'Hermes 1'\n",
      " 'Bender and bender 1' 'Hermes 25' 'Leela 1729' 'Bender 1729'\n",
      " 'Farnsworth xvii' 'Farnsworth 420' 'Amy 420' 'Three hundred big boys'\n",
      " 'Tattoo' 'Geneworks woman' 'Whale biologist' 'Butt tattoos' 'Caddy'\n",
      " 'Little orphan' 'Holo-roseanne' 'Hobo  1' 'Hobo  2' 'Ranger park'\n",
      " 'Bend her' 'Barbados slim' 'Starter' 'Official' 'Male announcer'\n",
      " 'Coilette' 'Humorbot 5.0' 'Humoubot 5.0' 'Obsoletely fabulous'\n",
      " 'Nannybot 1.0' \"Farnsworth's killbot\" \"Wernstrom's killbot\" 'Teenbot'\n",
      " 'Robot 1-x' 'Cartridge unit' 'Waterbot' 'Sinclair' 'Upgrader'\n",
      " 'Bender should not be allowed on tv' 'Antonio' 'Robberbot'\n",
      " 'Casting director' 'Mombot' 'Emotitron jr' 'Macaulay culkon' 'Betabot'\n",
      " 'Network president' 'Alphabot' 'Gammabot' 'Tv?' 'Cool-o-meter' 'Fart.'\n",
      " 'Fart mob' \"The devil's hands are idle playthings\" 'Mrs mellenger'\n",
      " 'Grumpy snail' 'Holo-vogel' 'Holo-orphans' 'Holo-leela' 'Holo-bender'\n",
      " 'Bartender' 'Holo-robot devil']\n"
     ]
    }
   ],
   "source": [
    "if not isinstance(df, type(None)):\n",
    "    print(\"Unique character names in dataset after name processing:\", df['character'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining Fry sentences: 2716\n"
     ]
    }
   ],
   "source": [
    "if not isinstance(df, type(None)):\n",
    "    print(\"Remaining\", character, \"sentences:\", len(df[df['character'] == character]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataset at D:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBot\\BarneyBot\\Data\\Sources\\Futurama\\Futurama.csv\n"
     ]
    }
   ],
   "source": [
    "if not isinstance(df, type(None)):\n",
    "    source_path = os.path.join(base_folder, \"Data\", \"Sources\", character_dict[character]['source'])\n",
    "    if not os.path.exists(source_path):\n",
    "        os.makedirs(source_path)\n",
    "    df.to_csv(os.path.join(source_path, str(character_dict[character]['source'])+\".csv\"), index=False)\n",
    "    print(\"Saved dataset at\", os.path.join(source_path, str(character_dict[character]['source'])+\".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: May consider feeding one sentence and one Sheldon reply or multiple sentences encoded with one Sheldon reply\n",
    "def get_character(df, level=2):\n",
    "    if character == 'Default':\n",
    "        return None\n",
    "    dataframe_rows = []\n",
    "    idxs_character = df[df['character'] == character].index\n",
    "    dataframe_rows = []\n",
    "    for i in idxs_character:\n",
    "        l = []\n",
    "        l.append(df['line'][i])\n",
    "        for j in range(0,level):\n",
    "            line = max(i-j-1,0)\n",
    "            l.append(df['line'][line])\n",
    "        dataframe_rows.append(l)\n",
    "    df = pd.DataFrame(dataframe_rows, columns=['response', 'context', 'context/0'])\n",
    "    return df\n",
    "\n",
    "df = get_character(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            response  \\\n",
      "0                  And that's how you play the game!   \n",
      "1                   Michelle, baby! Where you going?   \n",
      "2      I hate my life I hate my life I hate my life.   \n",
      "3  Hello? Pizza delivery for......Icy Wiener?! Aw...   \n",
      "4                                          What the?   \n",
      "\n",
      "                                             context  \\\n",
      "0  Space. It seems to go on and on forever. But t...   \n",
      "1                 Hey, Fry. Pizza goin' out! C'mon!!   \n",
      "2  It's not working out, Fry. I put your stuff ou...   \n",
      "3                                    Happy new year!   \n",
      "4                                               One!   \n",
      "\n",
      "                                           context/0  \n",
      "0  By David X. Cohen amp; Matt Groening Transcrib...  \n",
      "1                                  You stink, loser!  \n",
      "2                   Michelle, baby! Where you going?  \n",
      "3      I hate my life I hate my life I hate my life.  \n",
      "4                                                Wu!  \n"
     ]
    }
   ],
   "source": [
    "if not isinstance(df, type(None)):\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed dataset length: 2716\n"
     ]
    }
   ],
   "source": [
    "if not isinstance(df, type(None)):\n",
    "    print(\"Preprocessed dataset length:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataset at D:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBot\\BarneyBot\\Data\\Characters\\Fry\\Fry.csv\n"
     ]
    }
   ],
   "source": [
    "if not isinstance(df, type(None)):\n",
    "    char_path = os.path.join(base_folder, \"Data\", \"Characters\", character)\n",
    "    if not os.path.exists(char_path):\n",
    "        os.makedirs(char_path)\n",
    "    df.to_csv(os.path.join(char_path, str(character)+\".csv\"), index=False)\n",
    "    print(\"Saved dataset at\", os.path.join(char_path, str(character)+\".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

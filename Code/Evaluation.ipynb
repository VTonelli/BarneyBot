{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dde1bf5a",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46f38c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "verbose = True\n",
    "use_cuda = False\n",
    "\n",
    "do_metric_training = False\n",
    "do_predictions = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aaa0c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip install -r \"E:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\\requirements.txt\"\n",
      "pip install -r \"E:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\\requirements.txt\"\n"
     ]
    }
   ],
   "source": [
    "### Run environment setup\n",
    "import os\n",
    "import lib.BBSetup as BBSetup\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    BBSetup.colab_setup(mount_folder=r\"/content/drive/My Drive/unibo/NLP_project/BarneyBot\")\n",
    "except:\n",
    "    try:\n",
    "        BBSetup.anaconda_manual_setup(base_folder=r\"E:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\",\n",
    "                                      env_name=\"barneybot\")\n",
    "    except:\n",
    "        BBSetup.anaconda_auto_setup(base_folder=r\"E:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\")\n",
    "\n",
    "### Define folders\n",
    "base_folder = BBSetup.BASE_FOLDER\n",
    "in_folder = BBSetup.set_folder(os.path.join(base_folder, 'Data', 'Characters'))\n",
    "out_folder = BBSetup.set_folder(os.path.join(base_folder, 'Metrics', 'New'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64468996",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programs\\Anaconda\\envs\\barneybot\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tonel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Various necessary imports\n",
    "from lib.BBDataLoad import load_char_df, get_chatbot_predictions, dialogpt_preprocess_function\n",
    "from datasets import load_dataset\n",
    "from transformers import TFAutoModelForCausalLM\n",
    "from lib.BBMetrics import BBMetric\n",
    "from lib.BBMetricResults import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Get the list of characters, removing the Default one\n",
    "from lib.BBData import character_dict, model_name, random_state\n",
    "import lib.BBData as BBData\n",
    "characters = list(character_dict.keys())\n",
    "characters.remove('Default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96c27ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████████████████████████████████████████████████████████████████████| 26.0/26.0 [00:00<?, ?B/s]\n",
      "E:\\Programs\\Anaconda\\envs\\barneybot\\lib\\site-packages\\huggingface_hub\\file_download.py:127: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in E:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\\cache. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████| 641/641 [00:00<?, ?B/s]\n",
      "Downloading: 100%|█████████████████████████████████████████████████████████████████| 1.04M/1.04M [00:01<00:00, 582kB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████| 456k/456k [00:00<00:00, 472kB/s]\n"
     ]
    }
   ],
   "source": [
    "# Import structures from HuggingFace\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "# Load the DialoGPT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
    "                                          cache_dir=os.path.join(base_folder, \"cache\"))\n",
    "tokenizer.pad_token = '#'\n",
    "data_collator = DataCollatorForLanguageModeling(mlm=False, tokenizer=tokenizer, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57b98f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to recursively flatten a list of lists (useful for evaluation queries)\n",
    "def flatten(S):\n",
    "    if S == []:\n",
    "        return S\n",
    "    if isinstance(S[0], list):\n",
    "        return flatten(S[0]) + flatten(S[1:])\n",
    "    return S[:1] + flatten(S[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55849736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run chatbot models to store responses onto a predictions file, so that they can be loaded quickly when computing metrics\n",
    "if do_predictions:\n",
    "    print(\"Saving predictions to file\")\n",
    "    with tqdm(total=len(characters)*4) as pbar:\n",
    "        # Responses of chatbot of a character on their own dataset\n",
    "        for char in characters:\n",
    "            checkpoint_folder = os.path.join(in_folder, char,\n",
    "                                             character_dict[char]['checkpoint_folder'])\n",
    "            model = TFAutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=checkpoint_folder)\n",
    "            model.compile()\n",
    "            samples = load_char_df(char)\n",
    "            for gen_type in ['greedy', 'nbeams', 'sampling']:\n",
    "                get_chatbot_predictions(samples['test']['context/0'], model,\n",
    "                              character_dict[char]['prediction_filename'] + '_' + gen_type + '.json',\n",
    "                              gen_type, char, cache.tokenizer, base_folder, override_predictions=True)\n",
    "                pbar.update(1)\n",
    "        # Responses of default dialogpt on each character's dataset\n",
    "        for char in characters:\n",
    "            model = TFAutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                                           cache_dir=os.path.join(base_folder, \"cache\"))\n",
    "            model.compile()\n",
    "            samples = load_char_df(char)\n",
    "            get_chatbot_predictions(samples['test']['context/0'], model,\n",
    "                              'from_' + char + \"_df__sampling.json\", gen_type,\n",
    "                              \"Default\", cache.tokenizer, base_folder, override_predictions=True)\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17d247a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Metrics training.\n"
     ]
    }
   ],
   "source": [
    "# Train metrics (only has to be done once)\n",
    "if do_metric_training:\n",
    "    print(\"Training metrics\")\n",
    "    # Neural Chatbot Classifier training\n",
    "    with tqdm(total=len(characters) + 2) as pbar:\n",
    "        for char in tqdm(characters):\n",
    "            neural_classifier = BBMetric.load_metric(\"neural chatbot classifier\")\n",
    "            neural_classifier.train(character=char, random_state=random_state,\n",
    "                     source_encoded_path=None,\n",
    "                     source_path=os.path.join(base_folder, \"Data\", \"Sources\",\n",
    "                                              character_dict[char]['source'],\n",
    "                                              character_dict[char]['source'] + \".csv\"),\n",
    "                     source_save_path=os.path.join(base_folder, \"Data\", \"Characters\", char),\n",
    "                     save_path=os.path.join(base_folder, \"Data\", \"Characters\", char))\n",
    "            pbar.update(1)\n",
    "        # Distilbert-Embedded Chatbot Classifier training\n",
    "        bertembedded_classifier = BBMetric.load_metric(\"distilbert-embedded chatbot classifier\")\n",
    "        bertembedded_classifier.train(characters_path=os.path.join(base_folder, \"Data\", \"Characters\"),\n",
    "                                      save_path=os.path.join(base_folder, \"Data\", \"Metrics\", \n",
    "                                                             \"distilbert_embedder\"),\n",
    "                                      train_embedder=True,\n",
    "                                      verbose=True)\n",
    "        pbar.update(1)\n",
    "        # Also train the classifier without Barney\n",
    "        characters_no_barney = characters.copy()\n",
    "        characters_no_barney.remove(\"Barney\")\n",
    "        bertembedded_classifier = BBMetric.load_metric(\"distilbert-embedded chatbot classifier\")\n",
    "        bertembedded_classifier.metric.set_characters(characters_no_barney)\n",
    "        bertembedded_classifier.train(characters_path=os.path.join(base_folder, \"Data\", \"Characters\"),\n",
    "                                      save_path=os.path.join(base_folder, \"Data\", \"Metrics\", \n",
    "                                                             \"distilbert_embedder_nobarney\"),\n",
    "                                      train_embedder=True,\n",
    "                                      verbose=True)\n",
    "        pbar.update(1)\n",
    "else:\n",
    "    print(\"Skipping Metrics training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea2ce54",
   "metadata": {},
   "source": [
    "# Cache System Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8285eb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a cache structure to avoid reloading models and predictions\n",
    "from types import SimpleNamespace\n",
    "\n",
    "# Structure of the cache\n",
    "cache = {\n",
    "    'dialogpt': {char: None for char in characters + [\"Base\"]},\n",
    "    'tokenizer': None,\n",
    "    'datacollator': None,\n",
    "    'trained_metric': {\n",
    "        'neural chatbot classifier': {char: None for char in characters},\n",
    "        'frequency chatbot classifier': {'c-tf-idf': None, 'tf-idf': None, 'word frequency': None},\n",
    "        'distilbert-embedded chatbot classifier': {'Full': None, 'No Barney': None}\n",
    "    },\n",
    "    'testset': {char + \"_df\": None for char in characters + [\"Common\"]},\n",
    "    'concat_and_encoded_testset': {char + \"_df\": None for char in characters + [\"Common\"]},\n",
    "    'predictions': {\n",
    "        char + \"_df\": { # Dataset\n",
    "            char: { # Chatbot\n",
    "                'greedy': None,\n",
    "                'nbeams': None,\n",
    "                'sampling': None\n",
    "            } for char in characters + [\"Base\"]\n",
    "        } for char in characters + [\"Common\"]\n",
    "    },\n",
    "}\n",
    "cache = SimpleNamespace(**cache)\n",
    "\n",
    "# Simple function to load an entry into the cache, if it is not present, otherwise just return it\n",
    "def load_cache_entry(value, entry):\n",
    "    pointer = cache\n",
    "    for i in range(len(entry)-1):\n",
    "        val = entry[i]\n",
    "        if isinstance(pointer, dict):\n",
    "            pointer = pointer[val]\n",
    "        elif isinstance(pointer, SimpleNamespace):\n",
    "            pointer = pointer.__dict__[val]\n",
    "        else:\n",
    "            raise Exception()\n",
    "    if not pointer[entry[-1]]:\n",
    "        pointer[entry[-1]] = value\n",
    "        if verbose:\n",
    "            print(\"Loaded cache at \" + str(entry))\n",
    "    return pointer[entry[-1]]\n",
    "\n",
    "# Simple function to remove a cache entry reference, to avoid memory overloading\n",
    "def flush_cache_entries(entries):\n",
    "    for entry in entries:\n",
    "        pointer = cache\n",
    "        for i in range(len(entry)-1):\n",
    "            val = entry[i]\n",
    "            if isinstance(pointer, dict):\n",
    "                pointer = pointer[val]\n",
    "            elif isinstance(pointer, SimpleNamespace):\n",
    "                pointer = pointer.__dict__[val]\n",
    "            else:\n",
    "                raise Exception()\n",
    "        pointer[entry[-1]] = None\n",
    "        if verbose:\n",
    "            print(\"Flushed cache at \" + str(entry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96df347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the testset (context, label) for a given character from cache\n",
    "def get_cache_testset(character, base_folder):\n",
    "    if not cache.testset[character + \"_df\"]:\n",
    "        # Load the testset of a character\n",
    "        if character != \"Common\":\n",
    "            df = load_char_df(character, base_folder)['test']\n",
    "        else: # Load the common dataset\n",
    "            df = load_dataset('csv',\n",
    "                     data_files=os.path.join(base_folder, 'Data', 'Sources', 'common_dataset.csv'), \n",
    "                     cache_dir=os.path.join(base_folder, \"cache\"))['train']\n",
    "        load_cache_entry(df, ['testset', character + \"_df\"])\n",
    "    return cache.testset[character + \"_df\"]\n",
    "\n",
    "# Function to get the encoded and concatenated contexts/labels, used for perplexity\n",
    "def get_cache_concat_and_encoded_testset(character, base_folder):\n",
    "    if not cache.concat_and_encoded_testset[character + \"_df\"]:\n",
    "        testset = get_cache_testset(character, base_folder)\n",
    "        concat_encoded_testset = testset.map(lambda row: dialogpt_preprocess_function(row,\n",
    "                                                                            cache.tokenizer),\n",
    "                                             batched=False)\n",
    "        concat_encoded_testset = concat_encoded_testset.to_tf_dataset(\n",
    "            columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    "            shuffle=False,\n",
    "            batch_size=8,\n",
    "            collate_fn=cache.datacollator,\n",
    "        )\n",
    "        load_cache_entry(concat_encoded_testset, ['concat_and_encoded_testset', character + \"_df\"])\n",
    "    return cache.concat_and_encoded_testset[character + \"_df\"]\n",
    "\n",
    "# Function to get the responses of a chatbot to contexts, given a character and the context source (dataset_from)\n",
    "def get_cache_predictions(dataset_from, character, base_folder, gen_type):\n",
    "    if not cache.predictions[dataset_from][character][gen_type]:\n",
    "        # If the dataset is that of a character, compute the predictions for character (or base dialogpt) on that dataset\n",
    "        if dataset_from == character + \"_df\":\n",
    "            if character != \"Base\":\n",
    "                predictions_tk = get_chatbot_predictions(None, None,\n",
    "                      character_dict[character]['prediction_filename'] + '_' + gen_type + '.json',\n",
    "                      None, character, None, base_folder, override_predictions=False)\n",
    "            else:\n",
    "                predictions_tk = get_chatbot_predictions(None, None,\n",
    "                      'from_' + dataset_from + '__' + gen_type + '.json',\n",
    "                      None, 'Default', None, base_folder, override_predictions=False)\n",
    "        # Otherwise, load the common dataset and do the same\n",
    "        elif dataset_from == \"Common_df\":\n",
    "            df = load_dataset('csv',\n",
    "                         data_files=os.path.join(base_folder, 'Data', 'Sources', 'common_dataset.csv'), \n",
    "                         cache_dir=os.path.join(base_folder, \"cache\"))\n",
    "            df = df.remove_columns(['source'])\n",
    "            model = get_cache_model(character)\n",
    "            predictions_tk = get_chatbot_predictions(df['train']['context/0'], model,\n",
    "                  \"\", gen_type, character, cache.tokenizer, base_folder, file_caching=False, override_predictions=False)            \n",
    "        else: # Other cases are not supported\n",
    "            raise NotImplementedError(\"Unexpected predictions to load!\")\n",
    "        # Given the predictions, decode them and load them into cache\n",
    "        predictions = []\n",
    "        for line in predictions_tk:\n",
    "            predictions.append(cache.tokenizer.decode(line, skip_special_tokens=True))\n",
    "        load_cache_entry(predictions, ['predictions', dataset_from, character, gen_type])\n",
    "    return cache.predictions[dataset_from][character][gen_type]\n",
    "\n",
    "# Function to cache metrics. Most are just loaded normally through BBMetrics.load_metric, while others are also\n",
    "# prepared for use (e.g. classifiers)\n",
    "def get_cache_metric(metric_name, **kwargs):\n",
    "    # Possible args\n",
    "    classifier_char = None if 'classifier_char' not in kwargs else kwargs['classifier_char']\n",
    "    mode = None if 'mode' not in kwargs else kwargs['mode']\n",
    "    with_barney = None if 'with_barney' not in kwargs else kwargs['with_barney']\n",
    "    with_barney = 'Full' if with_barney else 'No Barney'\n",
    "    # If the metric is one of those requiring caching...\n",
    "    if metric_name in cache.trained_metric:\n",
    "        if metric_name == \"neural chatbot classifier\":\n",
    "            if not cache.trained_metric[metric_name][classifier_char]:\n",
    "                # Load the neural classifier\n",
    "                cache.trained_metric[metric_name][classifier_char] = BBMetric.load_metric(metric_name)\n",
    "                # Perform a dummy round for caching all internal metric loadables\n",
    "                cache.trained_metric[metric_name][classifier_char].compute( \n",
    "                    character=classifier_char,\n",
    "                    load_path=os.path.join(base_folder, \"Data\", \"Characters\",\n",
    "                              classifier_char, character_dict[classifier_char]['classifier_folder']),\n",
    "                    sentences=[\"Hi\", \"Hello\", \"How\"])\n",
    "            return cache.trained_metric[metric_name][classifier_char]\n",
    "        elif metric_name == \"frequency chatbot classifier\":\n",
    "            if not cache.trained_metric[metric_name][mode]:\n",
    "                # Load the frequency classifier\n",
    "                cache.trained_metric[metric_name][mode] = BBMetric.load_metric(metric_name)\n",
    "                # Train it on the given mode (usually c-tf-idf)\n",
    "                cache.trained_metric[metric_name][mode].train(\n",
    "                    characters_path=os.path.join(base_folder, \"Data\", \"Characters\"),\n",
    "                    mode=mode)\n",
    "            return cache.trained_metric[metric_name][mode]\n",
    "        elif metric_name == \"distilbert-embedded chatbot classifier\":\n",
    "            if not cache.trained_metric[metric_name][with_barney]:\n",
    "                # Load and train (KNN only, since the embedder is loaded from file) the distilbert classifier\n",
    "                # Both the \"with Barney\" and \"without Barney\" options can be loaded\n",
    "                if with_barney == 'Full':\n",
    "                    cache.trained_metric[metric_name][with_barney] = BBMetric.load_metric(metric_name,\n",
    "                                embedder_path=os.path.join(base_folder, \"Data\", \"Metrics\", \n",
    "                                                           \"distilbert_embedder\"),\n",
    "                                from_pretrained=True, use_cuda=use_cuda)\n",
    "                    cache.trained_metric[metric_name][with_barney].train(\n",
    "                        characters_path=os.path.join(base_folder, \"Data\", \"Characters\"),\n",
    "                        save_path=None, train_embedder=False\n",
    "                    )\n",
    "                else:\n",
    "                    cache.trained_metric[metric_name][with_barney] = BBMetric.load_metric(metric_name,\n",
    "                                embedder_path=os.path.join(base_folder, \"Data\", \"Metrics\", \n",
    "                                                           \"distilbert_embedder_nobarney\"),\n",
    "                                from_pretrained=True, use_cuda=use_cuda)\n",
    "                    cache.trained_metric[metric_name][with_barney].train(\n",
    "                        characters_path=os.path.join(base_folder, \"Data\", \"Characters\"),\n",
    "                        save_path=None, train_embedder=False\n",
    "                    )\n",
    "            return cache.trained_metric[metric_name][with_barney]\n",
    "    else: # If the metric does not require caching, simply load it from BBMetrics\n",
    "        return BBMetric.load_metric(metric_name)\n",
    "\n",
    "# Function to load a DialoGPT model into cache and retrieve it\n",
    "def get_cache_model(character):\n",
    "    # Load either the base model or one of the characters fine-tuned models\n",
    "    if character == \"Base\":\n",
    "        model = TFAutoModelForCausalLM.from_pretrained(model_name, cache_dir=os.path.join(base_folder, \"cache\"))\n",
    "    else:\n",
    "        checkpoint_folder = os.path.join(in_folder, character, character_dict[character]['checkpoint_folder'])\n",
    "        model = TFAutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=checkpoint_folder)\n",
    "    # Compile the model and store it in cache, return\n",
    "    model.compile()\n",
    "    cache.dialogpt[character] = model\n",
    "    return cache.dialogpt[character]\n",
    "\n",
    "# Finally, store in cache also the tokenizer and datacollator, since they are frequently used to prepare data\n",
    "cache.tokenizer = tokenizer\n",
    "cache.datacollator = data_collator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc3e480",
   "metadata": {},
   "source": [
    "# Evaluation Process Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8dba10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the correct list of strings to pass onto a metric, given the context show, the chatbot and the required\n",
    "# column (e.g. context, label or predictions)\n",
    "def sentence_callable(reference_set, character, column):\n",
    "    # If we ask for context or labels, return data from the testset\n",
    "    if column == \"context/0\" or column == \"response\":\n",
    "        assert(reference_set == character + \"_df\")\n",
    "        return get_cache_testset(character, base_folder)[column]\n",
    "    else: # If we ask for predictions, return data from the cached predictions (on the appropriate dataset)\n",
    "        assert(reference_set == character + \"_df\" or \\\n",
    "               reference_set == \"Common_df\" or \\\n",
    "               (character == \"Base\" and column == \"sampling\"))\n",
    "        return get_cache_predictions(reference_set, character, base_folder, column)\n",
    "\n",
    "# Function to extract the correct data necessary by perplexity (model and specially encoded testset)\n",
    "def perplexity_callable(reference_set, character):\n",
    "    return {\n",
    "        'model': get_cache_model(character),\n",
    "        'encoded_test_set': get_cache_concat_and_encoded_testset(reference_set.replace(\"_df\", \"\"),\n",
    "                                                                 base_folder)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15b49468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the evaluation procedure, taking in input a list of dictionaries, each acting as a query\n",
    "def evaluate_round(queries):\n",
    "    # Internal maps from enum to string, for proper interpretation of the query into function args\n",
    "    actors_pprint_map = {\n",
    "        MetricActor.DATASET_CHAR: \"dataset\",\n",
    "        MetricActor.DATASET_CHARCONTEXT: \"dataset labels\",\n",
    "        MetricActor.DIALOGPT_GREEDY: \"dialogpt (greedy)\",\n",
    "        MetricActor.DIALOGPT_NBEAMS: \"dialogpt (nbeamns)\",\n",
    "        MetricActor.DIALOGPT_SAMPLE: \"dialogpt (sampling)\"\n",
    "    }\n",
    "    actor_to_column_map = {\n",
    "        MetricActor.DATASET_CHARCONTEXT: 'context/0',\n",
    "        MetricActor.DATASET_CHAR: 'response',\n",
    "        MetricActor.DIALOGPT_GREEDY: 'greedy',\n",
    "        MetricActor.DIALOGPT_NBEAMS: 'nbeams',\n",
    "        MetricActor.DIALOGPT_SAMPLE: 'sampling'\n",
    "    }\n",
    "    # Store query results here\n",
    "    results = dict()\n",
    "    # Iterate over queries\n",
    "    for i in range(len(queries)):\n",
    "        try:\n",
    "            query = queries[i].copy() # Since there are destructive operations\n",
    "            print(\"#### Running Query \" + str(i+1) + \"/\" + str(len(queries)) + \" ####\")\n",
    "            # Query requires to run an operation (flush the cache, generally)\n",
    "            if 'run' in query:\n",
    "                query['run'](**query['run_args'])\n",
    "            # Otherwise, it is a metric-computing query\n",
    "            else:\n",
    "                # Print some info to user\n",
    "                print(\"Evaluating \" + query['metric_name'] + \\\n",
    "                      \" on reference set \" + query['reference_set'] + \" with:\")\n",
    "                for actor_type, actor in query['metric_actors'].items():\n",
    "                    print(\"\\t\" + actor[1] + \" \" + actors_pprint_map[actor[0]] + \" as \" + actor_type)\n",
    "                # Get metric metadata data for outputting\n",
    "                query_output = dict()\n",
    "                query_output['metric_name'] = query['metric_name']\n",
    "                query_output['metric_version'] = 1 if 'metric_version' not in query else query['metric_version']\n",
    "                query_output['metric_attempt'] = 0 if 'metric_attempt' not in query else query['metric_attempt']\n",
    "                query_output['metric_actors'] = query['metric_actors']\n",
    "                query_output['metric_params'] = query['metric_params']\n",
    "                query_output['context'] = {\n",
    "                    \"dialogpt_size\": \"small\",\n",
    "                    \"dialogpt_context_sentences\": BBData.context_n,\n",
    "                    \"dialogpt_nbeams_beams\": BBData.n_beams,\n",
    "                    \"dialogpt_sample_top_p\": BBData.top_p,\n",
    "                    \"dialogpt_sample_top_k\": BBData.top_k\n",
    "                }\n",
    "                query_output['metric_arity'] = get_metric_arity(query['metric_name'])\n",
    "                query_output['metric_determinism'] = get_metric_determinism(query['metric_name'],\n",
    "                                                                            query_output['metric_version'])\n",
    "                query_output['reference_set'] = query['reference_set']\n",
    "                query_hash = dict_hash({'metric_name': query_output['metric_name'],\n",
    "                                        'metric_version': query_output['metric_version'],\n",
    "                                        'reference_set': query_output['reference_set'],\n",
    "                                        'metric_attempt': query_output['metric_attempt'],\n",
    "                                        'metric_actors': query_output['metric_actors'],\n",
    "                                        'context': query_output['context'],\n",
    "                                        'metric_params': query_output['metric_params']})\n",
    "                # This is a lazy fix to remove the \"_df\" suffix used in query, but not used in some functions\n",
    "                for key in query['metric_actors'].keys():\n",
    "                    if query['metric_actors'][key][0] == MetricActor.DATASET_CHARCONTEXT or \\\n",
    "                        query['metric_actors'][key][0] == MetricActor.DATASET_CHAR:\n",
    "                        query['metric_actors'][key] = (query['metric_actors'][key][0],\n",
    "                                                       query['metric_actors'][key][1].replace(\"_df\", \"\"))\n",
    "                # Get the parameters for the actual metric computation: some cases depending on the specific query\n",
    "                if query['metric_name'] in ['google bleu', 'meteor', 'rouge l', 'mpnet embedding similarity',\n",
    "                                'emotion classifier', 'distinct', 'roberta crossencoding similarity',\n",
    "                                'repetitiveness', 'translation error rate', 'bertscore', 'bleurt', 'bartscore',\n",
    "                                'word mover distance', 't5 grammar correction edit distance',\n",
    "                                'extended edit distance', 'flesch-kincaid index']:\n",
    "                    # For most, simply use the correct arg name and fetch the list of strings\n",
    "                    args_map = {\n",
    "                        'predictor': 'predictions', 'reference': 'references', 'document': 'sentences',\n",
    "                        'document0': 'sentences_a', 'document1': 'sentences_b'\n",
    "                    }\n",
    "                    metric = get_cache_metric(query['metric_name'])\n",
    "                    args_dict = {}\n",
    "                    for actor_key, actor_pair in query['metric_actors'].items():\n",
    "                        args_dict[args_map[actor_key]] = sentence_callable(query['reference_set'],\n",
    "                                                                           actor_pair[1],\n",
    "                                                                           actor_to_column_map[actor_pair[0]])\n",
    "                # For COMET, also get the proper args, but naming is slightly different\n",
    "                elif query['metric_name'] == 'comet':\n",
    "                    args_map = {\n",
    "                        'predictor': 'predictions', 'reference': 'references', 'document': 'sources'\n",
    "                    }\n",
    "                    metric = get_cache_metric(query['metric_name'])\n",
    "                    args_dict = {}\n",
    "                    for actor_key, actor_pair in query['metric_actors'].items():    \n",
    "                        args_dict[args_map[actor_key]] = sentence_callable(query['reference_set'],\n",
    "                                                                           actor_pair[1],\n",
    "                                                                           actor_to_column_map[actor_pair[0]])\n",
    "                # For perplexity, the special \"perplexity_callable\" is used to fetch the args, since it requires the model\n",
    "                elif query['metric_name'] in ['perplexity']:\n",
    "                    actor_pair = list(query['metric_actors'].values())[0]\n",
    "                    metric = get_cache_metric(query['metric_name'])\n",
    "                    args_dict = perplexity_callable(query['reference_set'],\n",
    "                                                    actor_pair[1])\n",
    "                # For frequency classifier, handle the custom param \"mode\"\n",
    "                elif query['metric_name'] in ['frequency chatbot classifier']:\n",
    "                    actor_pair = list(query['metric_actors'].values())[0]\n",
    "                    metric = get_cache_metric(query['metric_name'],\n",
    "                                              mode=query['metric_params']['mode'])\n",
    "                    del query['metric_params']['mode']\n",
    "                    args_dict = {\n",
    "                        'sentences': sentence_callable(query['reference_set'],\n",
    "                                                       actor_pair[1],\n",
    "                                                       actor_to_column_map[actor_pair[0]])\n",
    "                    }\n",
    "                # For distilbert classifier, handle the custom param \"with_barney\"\n",
    "                elif query['metric_name'] in ['distilbert-embedded chatbot classifier']:\n",
    "                    actor_pair = list(query['metric_actors'].values())[0]\n",
    "                    metric = get_cache_metric(query['metric_name'],\n",
    "                                              with_barney=query['metric_params']['with_barney'])\n",
    "                    del query['metric_params']['with_barney']\n",
    "                    args_dict = {\n",
    "                        'sentences': sentence_callable(query['reference_set'],\n",
    "                                                       actor_pair[1],\n",
    "                                                       actor_to_column_map[actor_pair[0]])\n",
    "                    }\n",
    "                # For neural classifier, handle the custom param \"classifier_char\"\n",
    "                elif query['metric_name'] in ['neural chatbot classifier']:\n",
    "                    actor_pair = list(query['metric_actors'].values())[0]\n",
    "                    classifier_char = query['metric_params']['classifier_char']\n",
    "                    args_dict = {\n",
    "                        'character': classifier_char,\n",
    "                        'load_path': os.path.join(base_folder, \"Data\", \"Characters\",\n",
    "                                      classifier_char, character_dict[classifier_char]['classifier_folder']),\n",
    "                    }\n",
    "                    metric = get_cache_metric(query['metric_name'],\n",
    "                                              classifier_char=classifier_char)\n",
    "                    del query['metric_params']['classifier_char']\n",
    "                    args_dict['sentences'] = sentence_callable(query['reference_set'],\n",
    "                                                               actor_pair[1],\n",
    "                                                               actor_to_column_map[actor_pair[0]])\n",
    "                # Finally, compute the actual metric on the args\n",
    "                query_output['answer'] = metric.compute(**{**args_dict, **query['metric_params']})\n",
    "                results[query_hash] = query_output\n",
    "        # If a query fails, do not interrupt the whole operation, just print the failure and proceed to the next query\n",
    "        except Exception as e:\n",
    "            print(\"Query failed due to \" + str(type(e)) + \" with message \" + str(e))\n",
    "        print()\n",
    "    print(\"Done.\")\n",
    "    # Return the list of results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf531aa",
   "metadata": {},
   "source": [
    "# Example of Running an Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf0116aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric Name: See BBMetric.metrics_list\n",
    "# Metric Params: See optional and require params of each metric\n",
    "## NOTE: For neural chatbot classifier, add 'classifier_char' as a parameter\n",
    "# Metric Actors:\n",
    "## DATASET_CHARCONTEXT: (any character | \"Common\") + \"_df\"\n",
    "## DATASET_CHAR: (any character | \"Common\") + \"_df\"\n",
    "## DIALOGPT_GREEDY: any character | \"Base\"\n",
    "## DIALOGPT_NBEAMS: any character | \"Base\"\n",
    "## DIALOGPT_SAMPLE: any character | \"Base\"\n",
    "# Reference Set: (any character | \"Common\") + \"_df\"\n",
    "# Metric Attempt: Defaults to 0, add a number to save multiple runs of the same query\n",
    "\n",
    "queries = [\n",
    "    {\n",
    "        'metric_name': 'google bleu',\n",
    "        'metric_actors': {\n",
    "            'predictor': (MetricActor.DATASET_CHAR, 'Vader_df'),\n",
    "            'reference': (MetricActor.DATASET_CHARCONTEXT, 'Vader_df'),\n",
    "        },\n",
    "        'reference_set': 'Vader_df',\n",
    "        'metric_params': {},\n",
    "        'metric_attempt': 0\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5925112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate_round(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a09bb1d",
   "metadata": {},
   "source": [
    "# Run Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f49708",
   "metadata": {},
   "source": [
    "Here we use the above code to compute the actual metrics. Several variations on this are possible, as the system is made to be quite flexible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78010c1d",
   "metadata": {},
   "source": [
    "## 10 Sentences Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c9fce35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-9ad41ba7d956ebd3\n",
      "Found cached dataset csv (E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/cache/csv/default-9ad41ba7d956ebd3/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache at ['testset', 'Common_df']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_10 = dict()\n",
    "\n",
    "# The test is performed over Barney and Vader\n",
    "for char in ['Barney', 'Vader']:\n",
    "    # Load the testset for the correct character\n",
    "    if char == 'Barney':\n",
    "        test_10[char + '_context'] = get_cache_testset('Common', base_folder)['context/0'][0]\n",
    "        test_10[char + '_label'] = get_cache_testset('Common', base_folder)['response'][0]\n",
    "    elif char == 'Vader':\n",
    "        test_10[char + '_context'] = get_cache_testset('Common', base_folder)['context/0'][20]\n",
    "        test_10[char + '_label'] = get_cache_testset('Common', base_folder)['response'][20]\n",
    "    # Load the model for the correct character\n",
    "    test_10[char + '_responses'] = list()\n",
    "    test_10[char + '_model'] = None\n",
    "    #test_10[char + '_model'] = get_cache_model(char)\n",
    "    '''\n",
    "    for i in tqdm(range(10)):\n",
    "        tokenized_question = cache.tokenizer.encode(test_10[char + '_context'] + cache.tokenizer.eos_token,\n",
    "                                                    return_tensors='tf')\n",
    "        max_length = 128 + tokenized_question.shape[1]\n",
    "        generated_answer = test_10[char + '_model'].generate(\n",
    "                            tokenized_question,\n",
    "                            pad_token_id=cache.tokenizer.eos_token_id,\n",
    "                            max_length=max_length,\n",
    "                            do_sample=True,\n",
    "                            top_k=BBData.top_k,\n",
    "                            top_p=BBData.top_p)[0].numpy().tolist()\n",
    "        generated_answer = generated_answer[len(tokenized_question[0]):]\n",
    "        test_10[char + '_responses'].append(cache.tokenizer.decode(generated_answer, skip_special_tokens=True))\n",
    "    '''\n",
    "    # (Precomputed responses for repeatability. The above code can be uncommented to run a new test)\n",
    "    test_10['Barney_responses'] = ['No, this is about believing that you can rule the galaxy by making all the wrong decisions for your lover girlfriend.', 'Barney, you are a disgrace.', \"That's not the point. You're trying to fill a hole in the story of a really big problem that I've been trying to solve. Now, where are you going to put the tape?\", \"I'm pretty sure it's about a girl.\", 'Why do I keep doing that? I mean, who is this guy?', 'I am not sure I like this story.', 'No, this is about the girl.', \"We're not going to get that.\", 'No, this is about the building.', \"My building? It is on the property of a small local company. It was run by a woman. This woman's website said it's a women's only club.\"]\n",
    "    test_10['Vader_responses'] = ['What is your destiny.', 'I will not', 'That is not a true statement.', 'We will not fight you. If you fight us.', \"That's why you fail.\", 'You have not done well. Perhaps we should have a surprise meet.', 'The Rebellion will not fight you, Commander. We will not fight you. The Empire has not broken you. The Empire has only broken your faith. You will not destroy us.', 'I promise you my word.', \"Don't do this to me.\", 'Lord Vader, I suggest you not try to keep this ship afloat. This ship has been constructed in perfect condition. And your men have only taken a few months to fix the damages.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e32e8328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BARNEY\n",
      "\t-Context-\n",
      "\t\t* Barney, this is about the building.\n",
      "\t-Answers-\n",
      "\t\t* No, this is about believing that you can rule the galaxy by making all the wrong decisions for your lover girlfriend.\n",
      "\t\t* Barney, you are a disgrace.\n",
      "\t\t* That's not the point. You're trying to fill a hole in the story of a really big problem that I've been trying to solve. Now, where are you going to put the tape?\n",
      "\t\t* I'm pretty sure it's about a girl.\n",
      "\t\t* Why do I keep doing that? I mean, who is this guy?\n",
      "\t\t* I am not sure I like this story.\n",
      "\t\t* No, this is about the girl.\n",
      "\t\t* We're not going to get that.\n",
      "\t\t* No, this is about the building.\n",
      "\t\t* My building? It is on the property of a small local company. It was run by a woman. This woman's website said it's a women's only club.\n",
      "\n",
      "VADER\n",
      "\t-Context-\n",
      "\t\t* I will not fight you.\n",
      "\t-Answers-\n",
      "\t\t* What is your destiny.\n",
      "\t\t* I will not\n",
      "\t\t* That is not a true statement.\n",
      "\t\t* We will not fight you. If you fight us.\n",
      "\t\t* That's why you fail.\n",
      "\t\t* You have not done well. Perhaps we should have a surprise meet.\n",
      "\t\t* The Rebellion will not fight you, Commander. We will not fight you. The Empire has not broken you. The Empire has only broken your faith. You will not destroy us.\n",
      "\t\t* I promise you my word.\n",
      "\t\t* Don't do this to me.\n",
      "\t\t* Lord Vader, I suggest you not try to keep this ship afloat. This ship has been constructed in perfect condition. And your men have only taken a few months to fix the damages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the context and 10 generated responses\n",
    "for char in ['Barney', 'Vader']:\n",
    "    print(char.upper())\n",
    "    print(\"\\t-Context-\")\n",
    "    print(\"\\t\\t* \" + test_10[char + '_context'])\n",
    "    print(\"\\t-Answers-\")\n",
    "    for elem in test_10[char + '_responses']:\n",
    "        print('\\t\\t* ' + elem)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4ba20ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing distinct for character Vader\n",
      "Computing distinct for character Barney\n"
     ]
    }
   ],
   "source": [
    "metric_filename = \"10 Sentences Ranking.json\"\n",
    "\n",
    "# Prepend some extra data to the metric file\n",
    "metric_dict = {\n",
    "    'test_additional_data' : {\n",
    "        'generated_sentences': {\n",
    "            'Barney': test_10['Barney_responses'],\n",
    "            'Vader': test_10['Vader_responses']\n",
    "        }\n",
    "    },\n",
    "    'human_ranking': {\n",
    "        'Barney': [28, 4, 20, 27, 9, 16, 21, 9, 12, 19],\n",
    "        'Vader': [19, 15, 19, 21, 30, 7, 15, 15, 19, 5]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Compute the 10 sentences ranking. This code is very similar to the function \"evaluate_round\", and is necessary since\n",
    "# the test is not computed on one of the standard datasets\n",
    "for char in ['Vader', 'Barney']:\n",
    "    for metric_name in ['distinct']:\n",
    "        print(\"Computing \" + metric_name + \" for character \" + char)\n",
    "        query_output = dict()\n",
    "        query_output['metric_name'] = metric_name\n",
    "        query_output['metric_version'] = 1\n",
    "        query_output['metric_attempt'] = 0\n",
    "        query_output['context'] = {\n",
    "            \"dialogpt_size\": \"small\",\n",
    "            \"dialogpt_context_sentences\": BBData.context_n,\n",
    "            \"dialogpt_nbeams_beams\": BBData.n_beams,\n",
    "            \"dialogpt_sample_top_p\": BBData.top_p,\n",
    "            \"dialogpt_sample_top_k\": BBData.top_k\n",
    "        }\n",
    "        query_output['metric_arity'] = get_metric_arity(metric_name)\n",
    "        query_output['metric_determinism'] = get_metric_determinism(metric_name, 1)\n",
    "        query_output['reference_set'] = [test_10[char + '_context']]\n",
    "        if metric_name in ['bartscore', 'rouge l', 'google bleu', 'meteor', 'bertscore', 'bleurt', 'translation error rate',\n",
    "                           'bleurt', 'bertscore', 'roberta crossencoding similarity']:\n",
    "            metric = get_cache_metric(metric_name)\n",
    "            metric_params = dict()\n",
    "            query_output['metric_actors'] = {\n",
    "                'predictor': (MetricActor.DIALOGPT_SAMPLE, char),\n",
    "                'reference': [test_10[char + '_label']]\n",
    "            }\n",
    "            compute_args = [{\n",
    "                'predictions': sentence,\n",
    "                'references': test_10[char + '_label']\n",
    "            } for sentence in test_10[char + '_responses']]\n",
    "        elif metric_name in ['extended edit distance', 'word mover distance', 'mpnet embedding similarity']:\n",
    "            metric = get_cache_metric(metric_name)\n",
    "            metric_params = dict()\n",
    "            query_output['metric_actors'] = {\n",
    "                'document0': (MetricActor.DIALOGPT_SAMPLE, char),\n",
    "                'document1': [test_10[char + '_label']]\n",
    "            }\n",
    "            compute_args = [{\n",
    "                'sentences_a': sentence,\n",
    "                'sentences_b': test_10[char + '_label']\n",
    "            } for sentence in test_10[char + '_responses']]\n",
    "        elif metric_name in ['frequency chatbot classifier', 'emotion classifier', 'distilbert-embedded chatbot classifier',\n",
    "                             'distinct', 'repetitiveness', 't5 grammar correction edit distance', 'flesch-kincaid index']:\n",
    "            if metric_name == 'frequency chatbot classifier':\n",
    "                metric = get_cache_metric(metric_name, mode='c-tf-idf')\n",
    "                metric_params = {'mode': 'c-tf-idf'}\n",
    "            elif metric_name == 'distilbert-embedded chatbot classifier':\n",
    "                metric = get_cache_metric(metric_name, with_barney=True)\n",
    "                metric_params = {'with_barney': True, 'count_neighbors': True}\n",
    "            else:\n",
    "                metric = get_cache_metric(metric_name)\n",
    "                metric_params = dict()\n",
    "            query_output['metric_actors'] = {\n",
    "                'document': (MetricActor.DIALOGPT_SAMPLE, char)\n",
    "            }\n",
    "            compute_args = [{\n",
    "                'sentences': sentence\n",
    "            } for sentence in test_10[char + '_responses']]\n",
    "        elif metric_name == 'perplexity':\n",
    "            print(\"Skipping Perplexity.\")\n",
    "            continue\n",
    "        elif metric_name == 'neural chatbot classifier':\n",
    "            metric = get_cache_metric(metric_name, classifier_char=char)\n",
    "            metric_params = {'classifier_char': char}\n",
    "            query_output['metric_actors'] = {\n",
    "                'document': (MetricActor.DIALOGPT_SAMPLE, char)\n",
    "            }\n",
    "            responses_n = len(test_10[char + '_responses'])\n",
    "            compute_args = [{\n",
    "                'sentences': [test_10[char + '_responses'][i],\n",
    "                              test_10[char + '_responses'][(i+1) % responses_n],\n",
    "                              test_10[char + '_responses'][(i+2) % responses_n]],\n",
    "                'load_path': os.path.join(base_folder, \"Data\", \"Characters\", char, character_dict[char]['classifier_folder']),\n",
    "                'character': char\n",
    "            } for i in range(responses_n)]\n",
    "        elif metric_name == 'comet':\n",
    "            metric = get_cache_metric(metric_name)\n",
    "            metric_params = dict()\n",
    "            query_output['metric_actors'] = {\n",
    "                'document': [test_10[char + '_context']],\n",
    "                'predictor': (MetricActor.DIALOGPT_SAMPLE, char),\n",
    "                'reference': [test_10[char + '_label']]\n",
    "            }\n",
    "            compute_args = [{\n",
    "                'sources': test_10[char + '_context'],\n",
    "                'predictions': sentence,\n",
    "                'references': test_10[char + '_label']\n",
    "            } for sentence in test_10[char + '_responses']]\n",
    "        query_output['metric_params'] = metric_params\n",
    "        query_hash = dict_hash({'metric_name': query_output['metric_name'],\n",
    "                        'metric_version': query_output['metric_version'],\n",
    "                        'reference_set': query_output['reference_set'],\n",
    "                        'metric_attempt': query_output['metric_attempt'],\n",
    "                        'metric_actors': query_output['metric_actors'],\n",
    "                        'context': query_output['context'],\n",
    "                        'metric_params': query_output['metric_params']})\n",
    "        results = [metric.compute(**args) for args in compute_args]\n",
    "        query_output['answer'] = results\n",
    "        metric_dict = {**metric_dict, **{query_hash: query_output}}\n",
    "        save_metric_by_name(os.path.join(out_folder, 'Advanced Tests'), metric_filename, metric_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f706444d",
   "metadata": {},
   "source": [
    "## Single Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bbd0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Running Query 1/26 ####\n",
      "Evaluating distinct on reference set Barney_df with:\n",
      "\tBarney_df dataset as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-d05c63f64527f593\n",
      "Found cached dataset csv (E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-d05c63f64527f593/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.71it/s]\n",
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-d05c63f64527f593/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-e57fb526fe4a3ff3.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-d05c63f64527f593/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-54c202230f70778c.arrow\n",
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-d05c63f64527f593/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-2b7ecddd83bcebad.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-d05c63f64527f593/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-f85aa8d6528292e4.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache at ['testset', 'Barney_df']\n",
      "\n",
      "#### Running Query 2/26 ####\n",
      "Evaluating distinct on reference set Sheldon_df with:\n",
      "\tSheldon_df dataset as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-b47497d241584694\n",
      "Found cached dataset csv (E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-b47497d241584694/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.19it/s]\n",
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-b47497d241584694/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-029452f8e061c873.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-b47497d241584694/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-c14841bc6fd888d0.arrow\n",
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-b47497d241584694/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-a95f39f7704e7643.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-b47497d241584694/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-3155a76a827528d3.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache at ['testset', 'Sheldon_df']\n",
      "\n",
      "#### Running Query 3/26 ####\n",
      "Evaluating distinct on reference set Harry_df with:\n",
      "\tHarry_df dataset as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-8734ab070ca4d4a4\n",
      "Found cached dataset csv (E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-8734ab070ca4d4a4/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.64it/s]\n",
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-8734ab070ca4d4a4/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-6f2c723a222e2152.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-8734ab070ca4d4a4/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-06309c8f05ebbafb.arrow\n",
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-8734ab070ca4d4a4/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-065178db47afc42d.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-8734ab070ca4d4a4/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-b63cdf0d40382d55.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache at ['testset', 'Harry_df']\n",
      "\n",
      "#### Running Query 4/26 ####\n",
      "Evaluating distinct on reference set Fry_df with:\n",
      "\tFry_df dataset as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-edae583082198a82\n",
      "Found cached dataset csv (E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-edae583082198a82/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.34it/s]\n",
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-edae583082198a82/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-3a40bd254dc1230b.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-edae583082198a82/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-76bce446c8545bcd.arrow\n",
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-edae583082198a82/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-0d49f749e9201c30.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-edae583082198a82/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-2361c2a0ed34c32d.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache at ['testset', 'Fry_df']\n",
      "\n",
      "#### Running Query 5/26 ####\n",
      "Evaluating distinct on reference set Bender_df with:\n",
      "\tBender_df dataset as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-36d673def5b55b14\n",
      "Found cached dataset csv (E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-36d673def5b55b14/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 31.91it/s]\n",
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-36d673def5b55b14/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-45e9a5cdc4703907.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-36d673def5b55b14/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-3d73977ab48375f4.arrow\n",
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-36d673def5b55b14/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-29c1b91d58842d36.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-36d673def5b55b14/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-15d3f645646c43ff.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache at ['testset', 'Bender_df']\n",
      "\n",
      "#### Running Query 6/26 ####\n",
      "Evaluating distinct on reference set Vader_df with:\n",
      "\tVader_df dataset as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-3e37c23a51e9d556\n",
      "Found cached dataset csv (E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-3e37c23a51e9d556/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.65it/s]\n",
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-3e37c23a51e9d556/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-6affe80547fc0f38.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-3e37c23a51e9d556/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-6800bd34204a2976.arrow\n",
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-3e37c23a51e9d556/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-78893b2d23cae2d7.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-3e37c23a51e9d556/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-38619cd96763b020.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache at ['testset', 'Vader_df']\n",
      "\n",
      "#### Running Query 7/26 ####\n",
      "Evaluating distinct on reference set Joey_df with:\n",
      "\tJoey_df dataset as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-bc30ecf942c9a05e\n",
      "Found cached dataset csv (E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-bc30ecf942c9a05e/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.78it/s]\n",
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-bc30ecf942c9a05e/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-ba044a5350a0b4ee.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-bc30ecf942c9a05e/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-27a2b109b2a74d44.arrow\n",
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-bc30ecf942c9a05e/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-5b9e07b7a11ce3d7.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-bc30ecf942c9a05e/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-5910ff0b0ae92adb.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache at ['testset', 'Joey_df']\n",
      "\n",
      "#### Running Query 8/26 ####\n",
      "Evaluating distinct on reference set Phoebe_df with:\n",
      "\tPhoebe_df dataset as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-437509a5e3c6484b\n",
      "Found cached dataset csv (E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-437509a5e3c6484b/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 15.99it/s]\n",
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-437509a5e3c6484b/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-f3dedb84963f27fc.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-437509a5e3c6484b/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-f69b60477b60f2fe.arrow\n",
      "Loading cached split indices for dataset at E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-437509a5e3c6484b/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-ae641b942c4f1782.arrow and E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/Src/cache/csv/default-437509a5e3c6484b/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-1b02de643a9ce81e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache at ['testset', 'Phoebe_df']\n",
      "\n",
      "#### Running Query 9/26 ####\n",
      "Evaluating distinct on reference set Common_df with:\n",
      "\tCommon_df dataset as document\n",
      "\n",
      "#### Running Query 10/26 ####\n",
      "Evaluating distinct on reference set Barney_df with:\n",
      "\tBarney dialogpt (sampling) as document\n",
      "Loading predictions from stored file\n",
      "Loaded predictions from stored file\n",
      "Loaded cache at ['predictions', 'Barney_df', 'Barney', 'sampling']\n",
      "\n",
      "#### Running Query 11/26 ####\n",
      "Evaluating distinct on reference set Sheldon_df with:\n",
      "\tSheldon dialogpt (sampling) as document\n",
      "Loading predictions from stored file\n",
      "Loaded predictions from stored file\n",
      "Loaded cache at ['predictions', 'Sheldon_df', 'Sheldon', 'sampling']\n",
      "\n",
      "#### Running Query 12/26 ####\n",
      "Evaluating distinct on reference set Harry_df with:\n",
      "\tHarry dialogpt (sampling) as document\n",
      "Loading predictions from stored file\n",
      "Loaded predictions from stored file\n",
      "Loaded cache at ['predictions', 'Harry_df', 'Harry', 'sampling']\n",
      "\n",
      "#### Running Query 13/26 ####\n",
      "Evaluating distinct on reference set Fry_df with:\n",
      "\tFry dialogpt (sampling) as document\n",
      "Loading predictions from stored file\n",
      "Loaded predictions from stored file\n",
      "Loaded cache at ['predictions', 'Fry_df', 'Fry', 'sampling']\n",
      "\n",
      "#### Running Query 14/26 ####\n",
      "Evaluating distinct on reference set Bender_df with:\n",
      "\tBender dialogpt (sampling) as document\n",
      "Loading predictions from stored file\n",
      "Loaded predictions from stored file\n",
      "Loaded cache at ['predictions', 'Bender_df', 'Bender', 'sampling']\n",
      "\n",
      "#### Running Query 15/26 ####\n",
      "Evaluating distinct on reference set Vader_df with:\n",
      "\tVader dialogpt (sampling) as document\n",
      "Loading predictions from stored file\n",
      "Loaded predictions from stored file\n",
      "Loaded cache at ['predictions', 'Vader_df', 'Vader', 'sampling']\n",
      "\n",
      "#### Running Query 16/26 ####\n",
      "Evaluating distinct on reference set Joey_df with:\n",
      "\tJoey dialogpt (sampling) as document\n",
      "Loading predictions from stored file\n",
      "Loaded predictions from stored file\n",
      "Loaded cache at ['predictions', 'Joey_df', 'Joey', 'sampling']\n",
      "\n",
      "#### Running Query 17/26 ####\n",
      "Evaluating distinct on reference set Phoebe_df with:\n",
      "\tPhoebe dialogpt (sampling) as document\n",
      "Loading predictions from stored file\n",
      "Loaded predictions from stored file\n",
      "Loaded cache at ['predictions', 'Phoebe_df', 'Phoebe', 'sampling']\n",
      "\n",
      "#### Running Query 18/26 ####\n",
      "Evaluating distinct on reference set Common_df with:\n",
      "\tBarney dialogpt (sampling) as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-9ad41ba7d956ebd3\n",
      "Found cached dataset csv (E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/cache/csv/default-9ad41ba7d956ebd3/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 64.01it/s]\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at E:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\\Data\\Characters\\Barney\\barney_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/35 [00:00<?, ?it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  3%|██▎                                                                                | 1/35 [00:17<09:54, 17.49s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  6%|████▋                                                                              | 2/35 [00:22<05:39, 10.28s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  9%|███████                                                                            | 3/35 [00:24<03:29,  6.54s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 11%|█████████▍                                                                         | 4/35 [00:27<02:31,  4.88s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 14%|███████████▊                                                                       | 5/35 [00:31<02:22,  4.76s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 17%|██████████████▏                                                                    | 6/35 [00:42<03:17,  6.82s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 20%|████████████████▌                                                                  | 7/35 [00:47<02:57,  6.33s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 23%|██████████████████▉                                                                | 8/35 [00:52<02:33,  5.70s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 26%|█████████████████████▎                                                             | 9/35 [01:02<03:06,  7.16s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 29%|███████████████████████▍                                                          | 10/35 [01:05<02:22,  5.71s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 31%|█████████████████████████▊                                                        | 11/35 [01:09<02:08,  5.34s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 34%|████████████████████████████                                                      | 12/35 [01:12<01:47,  4.67s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 37%|██████████████████████████████▍                                                   | 13/35 [01:15<01:30,  4.13s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 40%|████████████████████████████████▊                                                 | 14/35 [01:22<01:43,  4.93s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 43%|███████████████████████████████████▏                                              | 15/35 [01:23<01:14,  3.74s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 46%|█████████████████████████████████████▍                                            | 16/35 [01:25<01:01,  3.25s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 49%|███████████████████████████████████████▊                                          | 17/35 [01:28<00:57,  3.21s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 51%|██████████████████████████████████████████▏                                       | 18/35 [01:30<00:50,  2.96s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 54%|████████████████████████████████████████████▌                                     | 19/35 [01:31<00:36,  2.31s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 57%|██████████████████████████████████████████████▊                                   | 20/35 [01:34<00:34,  2.31s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 60%|█████████████████████████████████████████████████▏                                | 21/35 [01:36<00:34,  2.49s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 63%|███████████████████████████████████████████████████▌                              | 22/35 [01:39<00:33,  2.57s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 66%|█████████████████████████████████████████████████████▉                            | 23/35 [01:43<00:35,  2.97s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 69%|████████████████████████████████████████████████████████▏                         | 24/35 [01:45<00:28,  2.58s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 71%|██████████████████████████████████████████████████████████▌                       | 25/35 [01:49<00:30,  3.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 74%|████████████████████████████████████████████████████████████▉                     | 26/35 [01:51<00:23,  2.66s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 77%|███████████████████████████████████████████████████████████████▎                  | 27/35 [01:53<00:19,  2.49s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 28/35 [01:54<00:15,  2.17s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 83%|███████████████████████████████████████████████████████████████████▉              | 29/35 [01:58<00:15,  2.65s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 86%|██████████████████████████████████████████████████████████████████████▎           | 30/35 [02:02<00:14,  2.95s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 89%|████████████████████████████████████████████████████████████████████████▋         | 31/35 [02:09<00:16,  4.16s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 91%|██████████████████████████████████████████████████████████████████████████▉       | 32/35 [02:11<00:10,  3.56s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 94%|█████████████████████████████████████████████████████████████████████████████▎    | 33/35 [02:15<00:07,  3.76s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 97%|███████████████████████████████████████████████████████████████████████████████▋  | 34/35 [02:16<00:03,  3.05s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [02:17<00:00,  3.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache at ['predictions', 'Common_df', 'Barney', 'sampling']\n",
      "\n",
      "#### Running Query 19/26 ####\n",
      "Evaluating distinct on reference set Common_df with:\n",
      "\tSheldon dialogpt (sampling) as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-9ad41ba7d956ebd3\n",
      "Found cached dataset csv (E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/cache/csv/default-9ad41ba7d956ebd3/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at E:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\\Data\\Characters\\Sheldon\\sheldon_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/35 [00:00<?, ?it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  3%|██▎                                                                                | 1/35 [00:03<01:46,  3.13s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  6%|████▋                                                                              | 2/35 [00:05<01:28,  2.67s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  9%|███████                                                                            | 3/35 [00:08<01:32,  2.89s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 11%|█████████▍                                                                         | 4/35 [00:11<01:32,  2.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 14%|███████████▊                                                                       | 5/35 [00:16<01:48,  3.62s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 17%|██████████████▏                                                                    | 6/35 [00:20<01:46,  3.67s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 20%|████████████████▌                                                                  | 7/35 [00:21<01:23,  3.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 23%|██████████████████▉                                                                | 8/35 [00:25<01:23,  3.08s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 26%|█████████████████████▎                                                             | 9/35 [00:28<01:18,  3.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 29%|███████████████████████▍                                                          | 10/35 [00:35<01:53,  4.52s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 31%|█████████████████████████▊                                                        | 11/35 [00:37<01:28,  3.71s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 34%|████████████████████████████                                                      | 12/35 [00:39<01:09,  3.04s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 37%|██████████████████████████████▍                                                   | 13/35 [00:40<00:52,  2.39s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 40%|████████████████████████████████▊                                                 | 14/35 [00:43<00:55,  2.62s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 43%|███████████████████████████████████▏                                              | 15/35 [00:49<01:14,  3.75s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 46%|█████████████████████████████████████▍                                            | 16/35 [00:55<01:21,  4.27s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 49%|███████████████████████████████████████▊                                          | 17/35 [00:57<01:04,  3.57s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 51%|██████████████████████████████████████████▏                                       | 18/35 [00:58<00:51,  3.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 54%|████████████████████████████████████████████▌                                     | 19/35 [01:01<00:44,  2.75s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 57%|██████████████████████████████████████████████▊                                   | 20/35 [01:03<00:39,  2.63s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 60%|█████████████████████████████████████████████████▏                                | 21/35 [01:11<00:58,  4.16s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 63%|███████████████████████████████████████████████████▌                              | 22/35 [01:13<00:48,  3.71s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 66%|█████████████████████████████████████████████████████▉                            | 23/35 [01:17<00:44,  3.75s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 69%|████████████████████████████████████████████████████████▏                         | 24/35 [01:27<01:01,  5.58s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 71%|██████████████████████████████████████████████████████████▌                       | 25/35 [01:29<00:44,  4.46s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 74%|████████████████████████████████████████████████████████████▉                     | 26/35 [01:32<00:35,  3.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 77%|███████████████████████████████████████████████████████████████▎                  | 27/35 [01:35<00:30,  3.79s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 28/35 [01:45<00:39,  5.60s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 83%|███████████████████████████████████████████████████████████████████▉              | 29/35 [01:46<00:25,  4.29s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 86%|██████████████████████████████████████████████████████████████████████▎           | 30/35 [01:47<00:17,  3.40s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 89%|████████████████████████████████████████████████████████████████████████▋         | 31/35 [01:55<00:18,  4.60s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 91%|██████████████████████████████████████████████████████████████████████████▉       | 32/35 [01:59<00:13,  4.57s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 94%|█████████████████████████████████████████████████████████████████████████████▎    | 33/35 [02:03<00:08,  4.18s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 97%|███████████████████████████████████████████████████████████████████████████████▋  | 34/35 [02:11<00:05,  5.43s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [02:13<00:00,  3.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache at ['predictions', 'Common_df', 'Sheldon', 'sampling']\n",
      "\n",
      "#### Running Query 20/26 ####\n",
      "Evaluating distinct on reference set Common_df with:\n",
      "\tHarry dialogpt (sampling) as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-9ad41ba7d956ebd3\n",
      "Found cached dataset csv (E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/cache/csv/default-9ad41ba7d956ebd3/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 200.16it/s]\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at E:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\\Data\\Characters\\Harry\\harry_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/35 [00:00<?, ?it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  3%|██▎                                                                                | 1/35 [00:04<02:25,  4.27s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  6%|████▋                                                                              | 2/35 [00:06<01:43,  3.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  9%|███████                                                                            | 3/35 [00:08<01:27,  2.74s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 11%|█████████▍                                                                         | 4/35 [00:10<01:12,  2.35s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 14%|███████████▊                                                                       | 5/35 [00:12<01:04,  2.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 17%|██████████████▏                                                                    | 6/35 [00:15<01:11,  2.48s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 20%|████████████████▌                                                                  | 7/35 [00:17<01:08,  2.45s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 23%|██████████████████▉                                                                | 8/35 [00:21<01:15,  2.78s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 26%|█████████████████████▎                                                             | 9/35 [00:22<01:02,  2.39s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 29%|███████████████████████▍                                                          | 10/35 [00:28<01:21,  3.24s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 31%|█████████████████████████▊                                                        | 11/35 [00:31<01:15,  3.15s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 34%|████████████████████████████                                                      | 12/35 [00:33<01:08,  2.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 37%|██████████████████████████████▍                                                   | 13/35 [00:35<00:57,  2.61s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 40%|████████████████████████████████▊                                                 | 14/35 [00:39<01:02,  2.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 43%|███████████████████████████████████▏                                              | 15/35 [00:40<00:50,  2.50s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 46%|█████████████████████████████████████▍                                            | 16/35 [00:42<00:45,  2.40s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 49%|███████████████████████████████████████▊                                          | 17/35 [00:45<00:43,  2.42s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 51%|██████████████████████████████████████████▏                                       | 18/35 [00:48<00:43,  2.59s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 54%|████████████████████████████████████████████▌                                     | 19/35 [00:51<00:45,  2.87s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 57%|██████████████████████████████████████████████▊                                   | 20/35 [00:54<00:42,  2.85s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 60%|█████████████████████████████████████████████████▏                                | 21/35 [00:56<00:36,  2.64s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 63%|███████████████████████████████████████████████████▌                              | 22/35 [00:59<00:32,  2.54s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 66%|█████████████████████████████████████████████████████▉                            | 23/35 [01:01<00:30,  2.54s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 69%|████████████████████████████████████████████████████████▏                         | 24/35 [01:04<00:30,  2.73s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 71%|██████████████████████████████████████████████████████████▌                       | 25/35 [01:07<00:27,  2.74s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 74%|████████████████████████████████████████████████████████████▉                     | 26/35 [01:08<00:20,  2.31s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 77%|███████████████████████████████████████████████████████████████▎                  | 27/35 [01:11<00:19,  2.48s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 28/35 [01:14<00:17,  2.43s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 83%|███████████████████████████████████████████████████████████████████▉              | 29/35 [01:15<00:12,  2.04s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 86%|██████████████████████████████████████████████████████████████████████▎           | 30/35 [01:17<00:10,  2.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 89%|████████████████████████████████████████████████████████████████████████▋         | 31/35 [01:19<00:07,  1.97s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 91%|██████████████████████████████████████████████████████████████████████████▉       | 32/35 [01:20<00:05,  1.94s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 94%|█████████████████████████████████████████████████████████████████████████████▎    | 33/35 [01:22<00:03,  1.80s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 97%|███████████████████████████████████████████████████████████████████████████████▋  | 34/35 [01:23<00:01,  1.61s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [01:25<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache at ['predictions', 'Common_df', 'Harry', 'sampling']\n",
      "\n",
      "#### Running Query 21/26 ####\n",
      "Evaluating distinct on reference set Common_df with:\n",
      "\tFry dialogpt (sampling) as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-9ad41ba7d956ebd3\n",
      "Found cached dataset csv (E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/cache/csv/default-9ad41ba7d956ebd3/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at E:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\\Data\\Characters\\Fry\\fry_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/35 [00:00<?, ?it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  3%|██▎                                                                                | 1/35 [00:01<00:58,  1.73s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  6%|████▋                                                                              | 2/35 [00:06<01:49,  3.32s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  9%|███████                                                                            | 3/35 [00:09<01:49,  3.43s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 11%|█████████▍                                                                         | 4/35 [00:14<02:03,  3.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 14%|███████████▊                                                                       | 5/35 [00:17<01:50,  3.67s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 17%|██████████████▏                                                                    | 6/35 [00:22<01:56,  4.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 20%|████████████████▌                                                                  | 7/35 [00:24<01:33,  3.35s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 23%|██████████████████▉                                                                | 8/35 [00:35<02:39,  5.90s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 26%|█████████████████████▎                                                             | 9/35 [00:40<02:20,  5.42s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 29%|███████████████████████▍                                                          | 10/35 [00:48<02:37,  6.29s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 31%|█████████████████████████▊                                                        | 11/35 [00:50<02:02,  5.11s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 34%|████████████████████████████                                                      | 12/35 [00:53<01:43,  4.51s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 37%|██████████████████████████████▍                                                   | 13/35 [00:57<01:32,  4.19s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 40%|████████████████████████████████▊                                                 | 14/35 [00:59<01:15,  3.61s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 43%|███████████████████████████████████▏                                              | 15/35 [01:03<01:15,  3.76s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 46%|█████████████████████████████████████▍                                            | 16/35 [01:10<01:30,  4.74s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 49%|███████████████████████████████████████▊                                          | 17/35 [01:14<01:19,  4.43s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 51%|██████████████████████████████████████████▏                                       | 18/35 [01:17<01:09,  4.09s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 54%|████████████████████████████████████████████▌                                     | 19/35 [01:18<00:50,  3.15s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 57%|██████████████████████████████████████████████▊                                   | 20/35 [01:21<00:47,  3.18s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 60%|█████████████████████████████████████████████████▏                                | 21/35 [01:23<00:36,  2.62s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 63%|███████████████████████████████████████████████████▌                              | 22/35 [01:24<00:30,  2.36s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 66%|█████████████████████████████████████████████████████▉                            | 23/35 [01:28<00:31,  2.65s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 69%|████████████████████████████████████████████████████████▏                         | 24/35 [01:30<00:28,  2.59s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 71%|██████████████████████████████████████████████████████████▌                       | 25/35 [01:37<00:39,  3.96s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 74%|████████████████████████████████████████████████████████████▉                     | 26/35 [01:42<00:36,  4.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 77%|███████████████████████████████████████████████████████████████▎                  | 27/35 [01:43<00:25,  3.16s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 28/35 [01:45<00:19,  2.77s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 83%|███████████████████████████████████████████████████████████████████▉              | 29/35 [01:45<00:13,  2.20s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 86%|██████████████████████████████████████████████████████████████████████▎           | 30/35 [01:49<00:13,  2.68s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 89%|████████████████████████████████████████████████████████████████████████▋         | 31/35 [01:54<00:13,  3.45s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 91%|██████████████████████████████████████████████████████████████████████████▉       | 32/35 [01:58<00:10,  3.42s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 94%|█████████████████████████████████████████████████████████████████████████████▎    | 33/35 [02:01<00:06,  3.47s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 97%|███████████████████████████████████████████████████████████████████████████████▋  | 34/35 [02:04<00:03,  3.28s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [02:09<00:00,  3.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache at ['predictions', 'Common_df', 'Fry', 'sampling']\n",
      "\n",
      "#### Running Query 22/26 ####\n",
      "Evaluating distinct on reference set Common_df with:\n",
      "\tBender dialogpt (sampling) as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-9ad41ba7d956ebd3\n",
      "Found cached dataset csv (E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/cache/csv/default-9ad41ba7d956ebd3/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 248.10it/s]\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at E:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\\Data\\Characters\\Bender\\bender_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/35 [00:00<?, ?it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  3%|██▎                                                                                | 1/35 [00:08<04:54,  8.67s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  6%|████▋                                                                              | 2/35 [00:10<02:37,  4.76s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  9%|███████                                                                            | 3/35 [00:12<01:49,  3.41s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 11%|█████████▍                                                                         | 4/35 [00:18<02:20,  4.54s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 14%|███████████▊                                                                       | 5/35 [00:24<02:30,  5.03s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 17%|██████████████▏                                                                    | 6/35 [00:28<02:15,  4.69s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 20%|████████████████▌                                                                  | 7/35 [00:29<01:36,  3.44s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 23%|██████████████████▉                                                                | 8/35 [00:34<01:46,  3.96s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 26%|█████████████████████▎                                                             | 9/35 [00:37<01:33,  3.59s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 29%|███████████████████████▍                                                          | 10/35 [00:40<01:24,  3.38s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 31%|█████████████████████████▊                                                        | 11/35 [00:41<01:07,  2.82s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 34%|████████████████████████████                                                      | 12/35 [00:43<00:58,  2.55s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 37%|██████████████████████████████▍                                                   | 13/35 [00:46<00:59,  2.72s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 40%|████████████████████████████████▊                                                 | 14/35 [00:50<01:04,  3.05s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 43%|███████████████████████████████████▏                                              | 15/35 [00:56<01:15,  3.76s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 46%|█████████████████████████████████████▍                                            | 16/35 [01:00<01:14,  3.91s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 49%|███████████████████████████████████████▊                                          | 17/35 [01:01<00:55,  3.07s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 51%|██████████████████████████████████████████▏                                       | 18/35 [01:04<00:49,  2.93s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 54%|████████████████████████████████████████████▌                                     | 19/35 [01:04<00:36,  2.30s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 57%|██████████████████████████████████████████████▊                                   | 20/35 [01:07<00:35,  2.37s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 60%|█████████████████████████████████████████████████▏                                | 21/35 [01:08<00:29,  2.07s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 63%|███████████████████████████████████████████████████▌                              | 22/35 [01:12<00:33,  2.59s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 66%|█████████████████████████████████████████████████████▉                            | 23/35 [01:14<00:29,  2.45s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 69%|████████████████████████████████████████████████████████▏                         | 24/35 [01:16<00:25,  2.28s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 71%|██████████████████████████████████████████████████████████▌                       | 25/35 [01:17<00:18,  1.83s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 74%|████████████████████████████████████████████████████████████▉                     | 26/35 [01:21<00:21,  2.44s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 77%|███████████████████████████████████████████████████████████████▎                  | 27/35 [01:23<00:19,  2.42s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 28/35 [01:27<00:20,  2.97s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 83%|███████████████████████████████████████████████████████████████████▉              | 29/35 [01:29<00:14,  2.50s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 86%|██████████████████████████████████████████████████████████████████████▎           | 30/35 [01:42<00:28,  5.69s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 89%|████████████████████████████████████████████████████████████████████████▋         | 31/35 [01:46<00:20,  5.22s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 91%|██████████████████████████████████████████████████████████████████████████▉       | 32/35 [01:49<00:13,  4.58s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 94%|█████████████████████████████████████████████████████████████████████████████▎    | 33/35 [01:52<00:08,  4.07s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 97%|███████████████████████████████████████████████████████████████████████████████▋  | 34/35 [01:54<00:03,  3.40s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [01:56<00:00,  3.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache at ['predictions', 'Common_df', 'Bender', 'sampling']\n",
      "\n",
      "#### Running Query 23/26 ####\n",
      "Evaluating distinct on reference set Common_df with:\n",
      "\tVader dialogpt (sampling) as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-9ad41ba7d956ebd3\n",
      "Found cached dataset csv (E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/cache/csv/default-9ad41ba7d956ebd3/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at E:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\\Data\\Characters\\Vader\\vader_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/35 [00:00<?, ?it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  3%|██▎                                                                                | 1/35 [00:01<00:36,  1.07s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  6%|████▋                                                                              | 2/35 [00:03<01:04,  1.96s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  9%|███████                                                                            | 3/35 [00:06<01:16,  2.40s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 11%|█████████▍                                                                         | 4/35 [00:08<01:06,  2.15s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 14%|███████████▊                                                                       | 5/35 [00:10<01:01,  2.04s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 17%|██████████████▏                                                                    | 6/35 [00:13<01:10,  2.43s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 20%|████████████████▌                                                                  | 7/35 [00:14<00:59,  2.11s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 23%|██████████████████▉                                                                | 8/35 [00:28<02:33,  5.69s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 26%|█████████████████████▎                                                             | 9/35 [00:30<01:59,  4.59s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 29%|███████████████████████▍                                                          | 10/35 [00:34<01:52,  4.48s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 31%|█████████████████████████▊                                                        | 11/35 [00:36<01:29,  3.72s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 34%|████████████████████████████                                                      | 12/35 [00:37<01:07,  2.94s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 37%|██████████████████████████████▍                                                   | 13/35 [00:40<01:05,  2.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 40%|████████████████████████████████▊                                                 | 14/35 [00:42<00:55,  2.64s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 43%|███████████████████████████████████▏                                              | 15/35 [00:45<00:56,  2.83s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 46%|█████████████████████████████████████▍                                            | 16/35 [00:51<01:06,  3.52s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 49%|███████████████████████████████████████▊                                          | 17/35 [00:56<01:11,  3.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 51%|██████████████████████████████████████████▏                                       | 18/35 [00:59<01:06,  3.93s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 54%|████████████████████████████████████████████▌                                     | 19/35 [01:04<01:07,  4.25s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 57%|██████████████████████████████████████████████▊                                   | 20/35 [01:09<01:05,  4.35s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 60%|█████████████████████████████████████████████████▏                                | 21/35 [01:14<01:05,  4.69s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 63%|███████████████████████████████████████████████████▌                              | 22/35 [01:21<01:09,  5.37s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 66%|█████████████████████████████████████████████████████▉                            | 23/35 [01:26<01:00,  5.08s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 69%|████████████████████████████████████████████████████████▏                         | 24/35 [01:29<00:50,  4.63s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 71%|██████████████████████████████████████████████████████████▌                       | 25/35 [01:34<00:45,  4.56s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 74%|████████████████████████████████████████████████████████████▉                     | 26/35 [01:37<00:37,  4.22s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 77%|███████████████████████████████████████████████████████████████▎                  | 27/35 [01:38<00:25,  3.22s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 28/35 [01:40<00:19,  2.82s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 83%|███████████████████████████████████████████████████████████████████▉              | 29/35 [01:43<00:16,  2.81s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 86%|██████████████████████████████████████████████████████████████████████▎           | 30/35 [01:46<00:15,  3.07s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 89%|████████████████████████████████████████████████████████████████████████▋         | 31/35 [01:49<00:11,  2.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 91%|██████████████████████████████████████████████████████████████████████████▉       | 32/35 [01:51<00:07,  2.55s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 94%|█████████████████████████████████████████████████████████████████████████████▎    | 33/35 [01:52<00:04,  2.28s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 97%|███████████████████████████████████████████████████████████████████████████████▋  | 34/35 [01:54<00:02,  2.07s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [01:58<00:00,  3.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache at ['predictions', 'Common_df', 'Vader', 'sampling']\n",
      "\n",
      "#### Running Query 24/26 ####\n",
      "Evaluating distinct on reference set Common_df with:\n",
      "\tJoey dialogpt (sampling) as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-9ad41ba7d956ebd3\n",
      "Found cached dataset csv (E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/cache/csv/default-9ad41ba7d956ebd3/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at E:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\\Data\\Characters\\Joey\\joey_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/35 [00:00<?, ?it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  3%|██▎                                                                                | 1/35 [00:05<02:58,  5.24s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  6%|████▋                                                                              | 2/35 [00:12<03:27,  6.30s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  9%|███████                                                                            | 3/35 [00:15<02:29,  4.67s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 11%|█████████▍                                                                         | 4/35 [00:17<01:52,  3.64s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 14%|███████████▊                                                                       | 5/35 [00:19<01:30,  3.03s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 17%|██████████████▏                                                                    | 6/35 [00:22<01:32,  3.17s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 20%|████████████████▌                                                                  | 7/35 [00:26<01:33,  3.32s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 23%|██████████████████▉                                                                | 8/35 [00:30<01:39,  3.69s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 26%|█████████████████████▎                                                             | 9/35 [00:31<01:17,  2.96s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 29%|███████████████████████▍                                                          | 10/35 [00:35<01:14,  2.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 31%|█████████████████████████▊                                                        | 11/35 [00:36<01:02,  2.59s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 34%|████████████████████████████                                                      | 12/35 [00:38<00:57,  2.48s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 37%|██████████████████████████████▍                                                   | 13/35 [00:39<00:44,  2.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 40%|████████████████████████████████▊                                                 | 14/35 [00:44<00:57,  2.74s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 43%|███████████████████████████████████▏                                              | 15/35 [00:51<01:23,  4.18s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 46%|█████████████████████████████████████▍                                            | 16/35 [00:53<01:07,  3.57s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 49%|███████████████████████████████████████▊                                          | 17/35 [00:57<01:04,  3.59s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 51%|██████████████████████████████████████████▏                                       | 18/35 [01:00<00:58,  3.44s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 54%|████████████████████████████████████████████▌                                     | 19/35 [01:02<00:47,  2.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 57%|██████████████████████████████████████████████▊                                   | 20/35 [01:08<00:56,  3.79s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 60%|█████████████████████████████████████████████████▏                                | 21/35 [01:12<00:55,  3.95s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 63%|███████████████████████████████████████████████████▌                              | 22/35 [01:18<00:58,  4.52s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 66%|█████████████████████████████████████████████████████▉                            | 23/35 [01:21<00:48,  4.08s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 69%|████████████████████████████████████████████████████████▏                         | 24/35 [01:23<00:37,  3.38s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 71%|██████████████████████████████████████████████████████████▌                       | 25/35 [01:28<00:40,  4.03s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 74%|████████████████████████████████████████████████████████████▉                     | 26/35 [01:29<00:27,  3.08s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 77%|███████████████████████████████████████████████████████████████▎                  | 27/35 [01:35<00:31,  3.89s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 28/35 [01:38<00:24,  3.53s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 83%|███████████████████████████████████████████████████████████████████▉              | 29/35 [01:39<00:16,  2.76s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 86%|██████████████████████████████████████████████████████████████████████▎           | 30/35 [01:44<00:17,  3.50s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 89%|████████████████████████████████████████████████████████████████████████▋         | 31/35 [01:47<00:14,  3.53s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 91%|██████████████████████████████████████████████████████████████████████████▉       | 32/35 [01:49<00:08,  2.89s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 94%|█████████████████████████████████████████████████████████████████████████████▎    | 33/35 [01:50<00:05,  2.52s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 97%|███████████████████████████████████████████████████████████████████████████████▋  | 34/35 [01:53<00:02,  2.43s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [01:55<00:00,  3.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache at ['predictions', 'Common_df', 'Joey', 'sampling']\n",
      "\n",
      "#### Running Query 25/26 ####\n",
      "Evaluating distinct on reference set Common_df with:\n",
      "\tPhoebe dialogpt (sampling) as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-9ad41ba7d956ebd3\n",
      "Found cached dataset csv (E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/cache/csv/default-9ad41ba7d956ebd3/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 64.02it/s]\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at E:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\\Data\\Characters\\Phoebe\\phoebe_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/35 [00:00<?, ?it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  3%|██▎                                                                                | 1/35 [00:12<07:06, 12.53s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  6%|████▋                                                                              | 2/35 [00:20<05:17,  9.61s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  9%|███████                                                                            | 3/35 [00:22<03:15,  6.11s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 11%|█████████▍                                                                         | 4/35 [00:22<02:05,  4.06s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 14%|███████████▊                                                                       | 5/35 [00:25<01:44,  3.47s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 17%|██████████████▏                                                                    | 6/35 [00:28<01:40,  3.47s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 20%|████████████████▌                                                                  | 7/35 [00:29<01:14,  2.66s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 23%|██████████████████▉                                                                | 8/35 [00:38<02:06,  4.69s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 26%|█████████████████████▎                                                             | 9/35 [00:42<01:54,  4.39s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 29%|███████████████████████▍                                                          | 10/35 [00:43<01:25,  3.43s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 31%|█████████████████████████▊                                                        | 11/35 [00:46<01:19,  3.29s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 34%|████████████████████████████                                                      | 12/35 [00:47<00:59,  2.59s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 37%|██████████████████████████████▍                                                   | 13/35 [00:50<00:54,  2.49s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 40%|████████████████████████████████▊                                                 | 14/35 [00:51<00:47,  2.26s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 43%|███████████████████████████████████▏                                              | 15/35 [00:55<00:51,  2.57s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 46%|█████████████████████████████████████▍                                            | 16/35 [00:58<00:52,  2.78s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 49%|███████████████████████████████████████▊                                          | 17/35 [01:02<00:59,  3.28s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 51%|██████████████████████████████████████████▏                                       | 18/35 [01:06<00:57,  3.39s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 54%|████████████████████████████████████████████▌                                     | 19/35 [01:14<01:16,  4.76s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 57%|██████████████████████████████████████████████▊                                   | 20/35 [01:16<00:57,  3.83s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 60%|█████████████████████████████████████████████████▏                                | 21/35 [01:17<00:42,  3.06s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 63%|███████████████████████████████████████████████████▌                              | 22/35 [01:18<00:31,  2.39s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 66%|█████████████████████████████████████████████████████▉                            | 23/35 [01:20<00:27,  2.27s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 69%|████████████████████████████████████████████████████████▏                         | 24/35 [01:21<00:20,  1.90s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 71%|██████████████████████████████████████████████████████████▌                       | 25/35 [01:22<00:15,  1.58s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 74%|████████████████████████████████████████████████████████████▉                     | 26/35 [01:22<00:12,  1.36s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 77%|███████████████████████████████████████████████████████████████▎                  | 27/35 [01:28<00:21,  2.63s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 28/35 [01:34<00:26,  3.73s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 83%|███████████████████████████████████████████████████████████████████▉              | 29/35 [01:41<00:27,  4.60s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 86%|██████████████████████████████████████████████████████████████████████▎           | 30/35 [01:45<00:22,  4.51s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 89%|████████████████████████████████████████████████████████████████████████▋         | 31/35 [01:58<00:27,  6.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 91%|██████████████████████████████████████████████████████████████████████████▉       | 32/35 [02:06<00:21,  7.28s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 94%|█████████████████████████████████████████████████████████████████████████████▎    | 33/35 [02:10<00:12,  6.30s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 97%|███████████████████████████████████████████████████████████████████████████████▋  | 34/35 [02:11<00:04,  4.68s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [02:14<00:00,  3.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache at ['predictions', 'Common_df', 'Phoebe', 'sampling']\n",
      "\n",
      "#### Running Query 26/26 ####\n",
      "Evaluating distinct on reference set Common_df with:\n",
      "\tBase dialogpt (sampling) as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-9ad41ba7d956ebd3\n",
      "Found cached dataset csv (E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/cache/csv/default-9ad41ba7d956ebd3/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 63.74it/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████| 498M/498M [01:30<00:00, 5.49MB/s]\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at microsoft/DialoGPT-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/35 [00:00<?, ?it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  3%|██▎                                                                                | 1/35 [00:04<02:19,  4.11s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  6%|████▋                                                                              | 2/35 [00:09<02:37,  4.76s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  9%|███████                                                                            | 3/35 [00:14<02:36,  4.89s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 11%|█████████▍                                                                         | 4/35 [00:17<02:15,  4.36s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 14%|███████████▊                                                                       | 5/35 [00:20<01:52,  3.76s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 17%|██████████████▏                                                                    | 6/35 [00:23<01:45,  3.63s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 20%|████████████████▌                                                                  | 7/35 [00:24<01:14,  2.66s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 23%|██████████████████▉                                                                | 8/35 [00:31<01:48,  4.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 26%|█████████████████████▎                                                             | 9/35 [00:33<01:23,  3.22s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 29%|███████████████████████▍                                                          | 10/35 [00:34<01:06,  2.65s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 31%|█████████████████████████▊                                                        | 11/35 [00:36<00:57,  2.41s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 34%|████████████████████████████                                                      | 12/35 [00:38<00:52,  2.29s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 37%|██████████████████████████████▍                                                   | 13/35 [00:40<00:48,  2.21s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 40%|████████████████████████████████▊                                                 | 14/35 [00:42<00:46,  2.20s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 43%|███████████████████████████████████▏                                              | 15/35 [00:45<00:51,  2.56s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 46%|█████████████████████████████████████▍                                            | 16/35 [00:47<00:43,  2.27s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 49%|███████████████████████████████████████▊                                          | 17/35 [00:51<00:47,  2.67s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 51%|██████████████████████████████████████████▏                                       | 18/35 [00:53<00:43,  2.55s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 54%|████████████████████████████████████████████▌                                     | 19/35 [00:56<00:43,  2.69s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 57%|██████████████████████████████████████████████▊                                   | 20/35 [00:58<00:37,  2.48s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 60%|█████████████████████████████████████████████████▏                                | 21/35 [01:03<00:46,  3.29s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 63%|███████████████████████████████████████████████████▌                              | 22/35 [01:06<00:41,  3.22s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 66%|█████████████████████████████████████████████████████▉                            | 23/35 [01:09<00:38,  3.17s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 69%|████████████████████████████████████████████████████████▏                         | 24/35 [01:21<01:02,  5.66s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 71%|██████████████████████████████████████████████████████████▌                       | 25/35 [01:24<00:50,  5.05s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 74%|████████████████████████████████████████████████████████████▉                     | 26/35 [01:30<00:48,  5.40s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 77%|███████████████████████████████████████████████████████████████▎                  | 27/35 [01:33<00:36,  4.57s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 28/35 [01:35<00:27,  3.86s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 83%|███████████████████████████████████████████████████████████████████▉              | 29/35 [01:41<00:26,  4.35s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 86%|██████████████████████████████████████████████████████████████████████▎           | 30/35 [01:46<00:22,  4.59s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    }
   ],
   "source": [
    "# Testing on metrics with arity 1\n",
    "for metric in ['distinct', 'repetitiveness', 't5 grammar correction edit distance', 'flesch-kincaid index', \n",
    "               'frequency chatbot classifier', 'emotion classifier']:\n",
    "    metric_pretty = BBMetric.load_metric(metric).pretty_name\n",
    "    metric_params = dict()\n",
    "    if metric == \"distilbert-embedded chatbot classifier\":\n",
    "        metric_params = {'with_barney': True}\n",
    "    elif metric == \"frequency chatbot classifier\":\n",
    "        metric_params = {'mode': 'c-tf-idf'}\n",
    "    results = evaluate_round([\n",
    "        {\n",
    "            'metric_name': metric,\n",
    "            'metric_actors': {\n",
    "                'document': (MetricActor.DATASET_CHAR, char + '_df')\n",
    "            },\n",
    "            'reference_set': char + '_df',\n",
    "            'metric_params': metric_params.copy(),\n",
    "            'metric_attempt': 0\n",
    "        } for char in characters + [\"Common\"]\n",
    "    ] + [\n",
    "        {\n",
    "            'metric_name': metric,\n",
    "            'metric_actors': {\n",
    "                'document': (MetricActor.DIALOGPT_SAMPLE, char)\n",
    "            },\n",
    "            'reference_set': char + '_df',\n",
    "            'metric_params': metric_params.copy(),\n",
    "            'metric_attempt': 0\n",
    "        } for char in characters\n",
    "    ] + [\n",
    "        {\n",
    "            'metric_name': metric,\n",
    "            'metric_actors': {\n",
    "                'document': (MetricActor.DIALOGPT_SAMPLE, char)\n",
    "            },\n",
    "            'reference_set': 'Common_df',\n",
    "            'metric_params': metric_params.copy(),\n",
    "            'metric_attempt': 0\n",
    "        } for char in characters + [\"Base\"]\n",
    "    ])\n",
    "    metric_dict = load_metric_by_name(out_folder, metric_pretty)\n",
    "    metric_dict = {**metric_dict, **results}\n",
    "    save_metric_by_name(out_folder, metric_pretty, metric_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a7e1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on neural chatbot classifier\n",
    "metric = 'neural chatbot classifier'\n",
    "metric_pretty = BBMetric.load_metric(metric).pretty_name\n",
    "metric_params = dict()\n",
    "results = evaluate_round(flatten([[\n",
    "        {\n",
    "            'metric_name': metric,\n",
    "            'metric_actors': {\n",
    "                'document': (MetricActor.DATASET_CHAR, char + '_df')\n",
    "            },\n",
    "            'reference_set': char + '_df',\n",
    "            'metric_params': {'classifier_char': char},\n",
    "            'metric_attempt': 0\n",
    "        },\n",
    "        {\n",
    "            'metric_name': metric,\n",
    "            'metric_actors': {\n",
    "                'document': (MetricActor.DIALOGPT_SAMPLE, char)\n",
    "            },\n",
    "            'reference_set': char + '_df',\n",
    "            'metric_params': {'classifier_char': char},\n",
    "            'metric_attempt': 0\n",
    "        },\n",
    "        {\n",
    "            'metric_name': metric,\n",
    "            'metric_actors': {\n",
    "                'document': (MetricActor.DIALOGPT_SAMPLE, char)\n",
    "            },\n",
    "            'reference_set': 'Common_df',\n",
    "            'metric_params': {'classifier_char': char},\n",
    "            'metric_attempt': 0\n",
    "        },\n",
    "        {\n",
    "            'run': flush_cache_entries,\n",
    "            'run_args': {\n",
    "                'entries': [['trained_metric', 'neural chatbot classifier', char]]\n",
    "            }\n",
    "        }\n",
    "] for char in characters\n",
    "]))\n",
    "metric_dict = load_metric_by_name(out_folder, metric_pretty)\n",
    "metric_dict = {**metric_dict, **results}\n",
    "save_metric_by_name(out_folder, metric_pretty, metric_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22640fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Running Query 1/9 ####\n",
      "Evaluating perplexity on reference set Common_df with:\n",
      "\tBarney dialogpt (sampling) as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at E:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\\Data\\Characters\\Barney\\barney_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n",
      "WARNING:datasets.builder:Using custom data configuration default-9ad41ba7d956ebd3\n",
      "WARNING:datasets.builder:Found cached dataset csv (E:/University/Esami da Superare/Natural Language Processing/BarneyBotGit/BarneyBot/cache/csv/default-9ad41ba7d956ebd3/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c024bbf68734081ac04593dc947e85a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache at ['testset', 'Common_df']\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\tfgpt2_main_layer\n",
      "......vars\n",
      ".........0\n",
      "...layers\\tfgpt2_main_layer\\drop\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block\\attn\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block\\attn\\attn_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block\\attn\\c_attn\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block\\attn\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block\\attn\\resid_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block\\ln_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block\\ln_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block\\mlp\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block\\mlp\\c_fc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block\\mlp\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block\\mlp\\dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_1\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_10\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_10\\attn\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_10\\attn\\attn_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_10\\attn\\c_attn\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_10\\attn\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_10\\attn\\resid_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_10\\ln_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_10\\ln_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_10\\mlp\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_10\\mlp\\c_fc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_10\\mlp\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_10\\mlp\\dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_11\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_11\\attn\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_11\\attn\\attn_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_11\\attn\\c_attn\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_11\\attn\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_11\\attn\\resid_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_11\\ln_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_11\\ln_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_11\\mlp\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_11\\mlp\\c_fc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_11\\mlp\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_11\\mlp\\dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_1\\attn\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_1\\attn\\attn_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_1\\attn\\c_attn\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_1\\attn\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_1\\attn\\resid_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_1\\ln_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_1\\ln_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_1\\mlp\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_1\\mlp\\c_fc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_1\\mlp\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_1\\mlp\\dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_2\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_2\\attn\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_2\\attn\\attn_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_2\\attn\\c_attn\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_2\\attn\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_2\\attn\\resid_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_2\\ln_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_2\\ln_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_2\\mlp\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_2\\mlp\\c_fc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_2\\mlp\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_2\\mlp\\dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_3\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_3\\attn\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_3\\attn\\attn_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_3\\attn\\c_attn\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_3\\attn\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_3\\attn\\resid_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_3\\ln_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_3\\ln_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_3\\mlp\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_3\\mlp\\c_fc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_3\\mlp\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_3\\mlp\\dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_4\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_4\\attn\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_4\\attn\\attn_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_4\\attn\\c_attn\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_4\\attn\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_4\\attn\\resid_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_4\\ln_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_4\\ln_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_4\\mlp\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_4\\mlp\\c_fc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_4\\mlp\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_4\\mlp\\dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_5\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_5\\attn\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_5\\attn\\attn_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_5\\attn\\c_attn\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_5\\attn\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_5\\attn\\resid_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_5\\ln_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_5\\ln_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_5\\mlp\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_5\\mlp\\c_fc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_5\\mlp\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_5\\mlp\\dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_6\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_6\\attn\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_6\\attn\\attn_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_6\\attn\\c_attn\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_6\\attn\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_6\\attn\\resid_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_6\\ln_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_6\\ln_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_6\\mlp\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_6\\mlp\\c_fc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_6\\mlp\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_6\\mlp\\dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_7\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_7\\attn\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_7\\attn\\attn_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_7\\attn\\c_attn\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_7\\attn\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_7\\attn\\resid_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_7\\ln_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_7\\ln_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_7\\mlp\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_7\\mlp\\c_fc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_7\\mlp\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_7\\mlp\\dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_8\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_8\\attn\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_8\\attn\\attn_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_8\\attn\\c_attn\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_8\\attn\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_8\\attn\\resid_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_8\\ln_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_8\\ln_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_8\\mlp\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_8\\mlp\\c_fc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_8\\mlp\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_8\\mlp\\dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_9\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_9\\attn\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_9\\attn\\attn_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_9\\attn\\c_attn\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_9\\attn\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_9\\attn\\resid_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_9\\ln_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_9\\ln_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_9\\mlp\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_9\\mlp\\c_fc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_9\\mlp\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_9\\mlp\\dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\ln_f\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\wte\n",
      "......vars\n",
      ".........0\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2022-12-24 18:22:21         2297\n",
      "metadata.json                                  2022-12-24 18:22:21           64\n",
      "variables.h5                                   2022-12-24 18:22:24    498110488\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\tfgpt2_main_layer\n",
      "......vars\n",
      ".........0\n",
      "...layers\\tfgpt2_main_layer\\drop\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block\\attn\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block\\attn\\attn_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block\\attn\\c_attn\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block\\attn\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block\\attn\\resid_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block\\ln_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block\\ln_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block\\mlp\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block\\mlp\\c_fc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block\\mlp\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block\\mlp\\dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_1\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_10\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_10\\attn\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_10\\attn\\attn_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_10\\attn\\c_attn\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_10\\attn\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_10\\attn\\resid_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_10\\ln_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_10\\ln_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_10\\mlp\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_10\\mlp\\c_fc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_10\\mlp\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_10\\mlp\\dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_11\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_11\\attn\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_11\\attn\\attn_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_11\\attn\\c_attn\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_11\\attn\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_11\\attn\\resid_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_11\\ln_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_11\\ln_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_11\\mlp\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_11\\mlp\\c_fc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_11\\mlp\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_11\\mlp\\dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_1\\attn\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_1\\attn\\attn_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_1\\attn\\c_attn\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_1\\attn\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_1\\attn\\resid_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_1\\ln_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_1\\ln_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_1\\mlp\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_1\\mlp\\c_fc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_1\\mlp\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_1\\mlp\\dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_2\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_2\\attn\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_2\\attn\\attn_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_2\\attn\\c_attn\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_2\\attn\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_2\\attn\\resid_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_2\\ln_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_2\\ln_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_2\\mlp\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_2\\mlp\\c_fc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_2\\mlp\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_2\\mlp\\dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_3\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_3\\attn\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_3\\attn\\attn_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_3\\attn\\c_attn\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_3\\attn\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_3\\attn\\resid_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_3\\ln_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_3\\ln_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_3\\mlp\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_3\\mlp\\c_fc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_3\\mlp\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_3\\mlp\\dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_4\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_4\\attn\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_4\\attn\\attn_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_4\\attn\\c_attn\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_4\\attn\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_4\\attn\\resid_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_4\\ln_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_4\\ln_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_4\\mlp\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_4\\mlp\\c_fc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_4\\mlp\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_4\\mlp\\dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_5\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_5\\attn\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_5\\attn\\attn_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_5\\attn\\c_attn\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_5\\attn\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_5\\attn\\resid_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_5\\ln_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_5\\ln_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_5\\mlp\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_5\\mlp\\c_fc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_5\\mlp\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_5\\mlp\\dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_6\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_6\\attn\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_6\\attn\\attn_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_6\\attn\\c_attn\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_6\\attn\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_6\\attn\\resid_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_6\\ln_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_6\\ln_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_6\\mlp\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_6\\mlp\\c_fc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_6\\mlp\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_6\\mlp\\dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_7\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_7\\attn\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_7\\attn\\attn_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_7\\attn\\c_attn\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_7\\attn\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_7\\attn\\resid_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_7\\ln_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_7\\ln_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_7\\mlp\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_7\\mlp\\c_fc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_7\\mlp\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_7\\mlp\\dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_8\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_8\\attn\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_8\\attn\\attn_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_8\\attn\\c_attn\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_8\\attn\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_8\\attn\\resid_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_8\\ln_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_8\\ln_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_8\\mlp\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_8\\mlp\\c_fc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_8\\mlp\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_8\\mlp\\dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_9\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_9\\attn\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_9\\attn\\attn_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_9\\attn\\c_attn\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_9\\attn\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_9\\attn\\resid_dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_9\\ln_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_9\\ln_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_9\\mlp\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_9\\mlp\\c_fc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_9\\mlp\\c_proj\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\h\\tf_block_9\\mlp\\dropout\n",
      "......vars\n",
      "...layers\\tfgpt2_main_layer\\ln_f\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\tfgpt2_main_layer\\wte\n",
      "......vars\n",
      ".........0\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2022-12-24 18:22:30         2299\n",
      "metadata.json                                  2022-12-24 18:22:30           64\n",
      "variables.h5                                   2022-12-24 18:22:35    498110488\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7863c8a9851c4309a855f9c7614bee62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache at ['concat_and_encoded_testset', 'Common_df']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:58<00:00, 11.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### Running Query 2/9 ####\n",
      "Evaluating perplexity on reference set Common_df with:\n",
      "\tSheldon dialogpt (sampling) as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at E:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\\Data\\Characters\\Sheldon\\sheldon_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:58<00:00, 11.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### Running Query 3/9 ####\n",
      "Evaluating perplexity on reference set Common_df with:\n",
      "\tHarry dialogpt (sampling) as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at E:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\\Data\\Characters\\Harry\\harry_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:56<00:00, 11.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### Running Query 4/9 ####\n",
      "Evaluating perplexity on reference set Common_df with:\n",
      "\tFry dialogpt (sampling) as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at E:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\\Data\\Characters\\Fry\\fry_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:51<00:00, 10.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### Running Query 5/9 ####\n",
      "Evaluating perplexity on reference set Common_df with:\n",
      "\tBender dialogpt (sampling) as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at E:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\\Data\\Characters\\Bender\\bender_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:50<00:00, 10.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### Running Query 6/9 ####\n",
      "Evaluating perplexity on reference set Common_df with:\n",
      "\tVader dialogpt (sampling) as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at E:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\\Data\\Characters\\Vader\\vader_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:53<00:00, 10.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### Running Query 7/9 ####\n",
      "Evaluating perplexity on reference set Common_df with:\n",
      "\tJoey dialogpt (sampling) as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at E:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\\Data\\Characters\\Joey\\joey_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:51<00:00, 10.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### Running Query 8/9 ####\n",
      "Evaluating perplexity on reference set Common_df with:\n",
      "\tPhoebe dialogpt (sampling) as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at E:\\University\\Esami da Superare\\Natural Language Processing\\BarneyBotGit\\BarneyBot\\Data\\Characters\\Phoebe\\phoebe_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:51<00:00, 10.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### Running Query 9/9 ####\n",
      "Evaluating perplexity on reference set Common_df with:\n",
      "\tBase dialogpt (sampling) as document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at microsoft/DialoGPT-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:50<00:00, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing on perplexity\n",
    "metric = 'perplexity'\n",
    "metric_pretty = BBMetric.load_metric(metric).pretty_name\n",
    "metric_params = dict()\n",
    "results = evaluate_round([\n",
    "    {\n",
    "        'metric_name': metric,\n",
    "        'metric_actors': {\n",
    "            'predictor': (MetricActor.DIALOGPT_SAMPLE, charpair[0])\n",
    "        },\n",
    "        'reference_set': charpair[1] + '_df',\n",
    "        'metric_params': {},\n",
    "        'metric_attempt': 0\n",
    "    } for charpair in [('Joey', 'Phoebe'), ('Joey', 'Sheldon'), ('Bender', 'Fry'), ('Bender', 'Barney'),\n",
    "                       ('Barney', 'Harry')]\n",
    "] + [\n",
    "    {\n",
    "        'metric_name': metric,\n",
    "        'metric_actors': {\n",
    "            'document': (MetricActor.DIALOGPT_SAMPLE, char)\n",
    "        },\n",
    "        'reference_set': char + '_df',\n",
    "        'metric_params': metric_params.copy(),\n",
    "        'metric_attempt': 0\n",
    "    } for char in characters\n",
    "] + [\n",
    "    {\n",
    "        'metric_name': metric,\n",
    "        'metric_actors': {\n",
    "            'document': (MetricActor.DIALOGPT_SAMPLE, \"Base\")\n",
    "        },\n",
    "        'reference_set': char + '_df',\n",
    "        'metric_params': metric_params.copy(),\n",
    "        'metric_attempt': 0\n",
    "    } for char in characters\n",
    "] + [\n",
    "    {\n",
    "        'metric_name': metric,\n",
    "        'metric_actors': {\n",
    "            'document': (MetricActor.DIALOGPT_SAMPLE, char)\n",
    "        },\n",
    "        'reference_set': 'Common_df',\n",
    "        'metric_params': metric_params.copy(),\n",
    "        'metric_attempt': 0\n",
    "    } for char in characters + [\"Base\"]\n",
    "])\n",
    "metric_dict = load_metric_by_name(out_folder, metric_pretty)\n",
    "metric_dict = {**metric_dict, **results}\n",
    "save_metric_by_name(out_folder, metric_pretty, metric_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987bfcb3",
   "metadata": {},
   "source": [
    "# COMET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16f17605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d07ceae1d1b4d39a43b2e8e46d601d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eamt22-cometinho-da.tar.gz: 307MB [00:58, 5.25MB/s]                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4e4228edc14d1494ecb326fefb9f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dfbe0d8b14c458086ffa8462b4db1dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/430 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "041877e08a9f42469d9e96b8e0135c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7789026e9d4b58bf0a79bedee659a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ccffa7e13a4ad4ae286abbe1c8aaad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:comet.models.base:Path lightning_logs/cometinho_part-i/checkpoints/epoch=0-step=899999.ckpt does not exist!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Running Query 1/8 ####\n",
      "Evaluating comet on reference set Barney_df with:\n",
      "\tBarney_df dataset labels as document\n",
      "\tBarney_df dataset as reference\n",
      "\tBarney dialogpt (sampling) as predictor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:comet.models.base:Path lightning_logs/cometinho_part-i/checkpoints/epoch=0-step=899999.ckpt does not exist!\n",
      "E:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=0)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### Running Query 2/8 ####\n",
      "Evaluating comet on reference set Sheldon_df with:\n",
      "\tSheldon_df dataset labels as document\n",
      "\tSheldon_df dataset as reference\n",
      "\tSheldon dialogpt (sampling) as predictor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:comet.models.base:Path lightning_logs/cometinho_part-i/checkpoints/epoch=0-step=899999.ckpt does not exist!\n",
      "E:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=0)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### Running Query 3/8 ####\n",
      "Evaluating comet on reference set Harry_df with:\n",
      "\tHarry_df dataset labels as document\n",
      "\tHarry_df dataset as reference\n",
      "\tHarry dialogpt (sampling) as predictor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:comet.models.base:Path lightning_logs/cometinho_part-i/checkpoints/epoch=0-step=899999.ckpt does not exist!\n",
      "E:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=0)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### Running Query 4/8 ####\n",
      "Evaluating comet on reference set Fry_df with:\n",
      "\tFry_df dataset labels as document\n",
      "\tFry_df dataset as reference\n",
      "\tFry dialogpt (sampling) as predictor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:comet.models.base:Path lightning_logs/cometinho_part-i/checkpoints/epoch=0-step=899999.ckpt does not exist!\n",
      "E:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=0)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### Running Query 5/8 ####\n",
      "Evaluating comet on reference set Bender_df with:\n",
      "\tBender_df dataset labels as document\n",
      "\tBender_df dataset as reference\n",
      "\tBender dialogpt (sampling) as predictor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:comet.models.base:Path lightning_logs/cometinho_part-i/checkpoints/epoch=0-step=899999.ckpt does not exist!\n",
      "E:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=0)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### Running Query 6/8 ####\n",
      "Evaluating comet on reference set Vader_df with:\n",
      "\tVader_df dataset labels as document\n",
      "\tVader_df dataset as reference\n",
      "\tVader dialogpt (sampling) as predictor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:comet.models.base:Path lightning_logs/cometinho_part-i/checkpoints/epoch=0-step=899999.ckpt does not exist!\n",
      "E:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=0)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### Running Query 7/8 ####\n",
      "Evaluating comet on reference set Joey_df with:\n",
      "\tJoey_df dataset labels as document\n",
      "\tJoey_df dataset as reference\n",
      "\tJoey dialogpt (sampling) as predictor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:comet.models.base:Path lightning_logs/cometinho_part-i/checkpoints/epoch=0-step=899999.ckpt does not exist!\n",
      "E:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=0)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### Running Query 8/8 ####\n",
      "Evaluating comet on reference set Phoebe_df with:\n",
      "\tPhoebe_df dataset labels as document\n",
      "\tPhoebe_df dataset as reference\n",
      "\tPhoebe dialogpt (sampling) as predictor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:comet.models.base:Path lightning_logs/cometinho_part-i/checkpoints/epoch=0-step=899999.ckpt does not exist!\n",
      "E:\\Programs\\Anaconda\\envs\\barneybot\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=0)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Testing on COMET\n",
    "metric = \"comet\"\n",
    "metric_pretty = BBMetric.load_metric(metric).pretty_name\n",
    "metric_params = dict()\n",
    "results = evaluate_round([\n",
    "    {\n",
    "        'metric_name': metric,\n",
    "        'metric_actors': {\n",
    "            'document': (MetricActor.DATASET_CHARCONTEXT, char + '_df'),\n",
    "            'reference': (MetricActor.DATASET_CHAR, char + \"_df\"),\n",
    "            'predictor': (MetricActor.DIALOGPT_SAMPLE, char)\n",
    "        },\n",
    "        'reference_set': char + '_df',\n",
    "        'metric_params': {},\n",
    "        'metric_attempt': 0\n",
    "    } for char in characters\n",
    "])\n",
    "metric_dict = load_metric_by_name(out_folder, metric_pretty)\n",
    "metric_dict = {**metric_dict, **results}\n",
    "save_metric_by_name(out_folder, metric_pretty, metric_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
